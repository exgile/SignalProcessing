{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru-evaluation-byseverity-1024.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/cwru-conv1d/blob/master/cwru_evaluation_byseverity_1024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "source": [
        "# CWRU files.\n",
        "\n",
        "Associate each Matlab file name to a bearing condition in a Python dictionary.\n",
        "The dictionary keys identify the conditions.\n",
        "\n",
        "There are only four normal conditions, with loads of 0, 1, 2 and 3 hp.\n",
        "All conditions end with an underscore character followed by an algarism representing the load applied during the acquisitions.\n",
        "The remaining conditions follow the pattern:\n",
        "\n",
        "\n",
        "* First two characters represent the bearing location, i.e. drive end (DE) and fan end (FE).\n",
        "* The following two characters represent the failure location in the bearing, i.e. ball (BA), Inner Race (IR) and Outer Race (OR).\n",
        "* The next three algarisms indicate the severity of the failure, where 007 stands for 0.007 inches and 0021 for 0.021 inches.\n",
        "* For Outer Race failures, the character @ is followed by a number that indicates different load zones. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug = False\n",
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR.007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR.007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR.007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR.007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR.014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR.014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR.014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR.014_3\"] = \"172.mat\"\n",
        "# DE Inner Race 0.021 inches\n",
        "aquisitions[\"DEIR.021_0\"] = \"209.mat\"\n",
        "aquisitions[\"DEIR.021_1\"] = \"210.mat\"\n",
        "aquisitions[\"DEIR.021_2\"] = \"211.mat\"\n",
        "aquisitions[\"DEIR.021_3\"] = \"212.mat\"\n",
        "if not debug:\n",
        "  # DE Ball 0.007 inches\n",
        "  aquisitions[\"DEB.007_0\"] = \"118.mat\"\n",
        "  aquisitions[\"DEB.007_1\"] = \"119.mat\"\n",
        "  aquisitions[\"DEB.007_2\"] = \"120.mat\"\n",
        "  aquisitions[\"DEB.007_3\"] = \"121.mat\"\n",
        "  # DE Ball 0.014 inches\n",
        "  aquisitions[\"DEB.014_0\"] = \"185.mat\"\n",
        "  aquisitions[\"DEB.014_1\"] = \"186.mat\"\n",
        "  aquisitions[\"DEB.014_2\"] = \"187.mat\"\n",
        "  aquisitions[\"DEB.014_3\"] = \"188.mat\"\n",
        "  # DE Ball 0.021 inches\n",
        "  aquisitions[\"DEB.021_0\"] = \"222.mat\"\n",
        "  aquisitions[\"DEB.021_1\"] = \"223.mat\"\n",
        "  aquisitions[\"DEB.021_2\"] = \"224.mat\"\n",
        "  aquisitions[\"DEB.021_3\"] = \"225.mat\"\n",
        "  # DE Outer race 0.007 inches centered @6:00\n",
        "  aquisitions[\"DEOR.007@6_0\"] = \"130.mat\"\n",
        "  aquisitions[\"DEOR.007@6_1\"] = \"131.mat\"\n",
        "  aquisitions[\"DEOR.007@6_2\"] = \"132.mat\"\n",
        "  aquisitions[\"DEOR.007@6_3\"] = \"133.mat\"\n",
        "  # DE Outer race 0.014 inches centered @6:00\n",
        "  aquisitions[\"DEOR.014@6_0\"] = \"197.mat\"\n",
        "  aquisitions[\"DEOR.014@6_1\"] = \"198.mat\"\n",
        "  aquisitions[\"DEOR.014@6_2\"] = \"199.mat\"\n",
        "  aquisitions[\"DEOR.014@6_3\"] = \"200.mat\"\n",
        "  # DE Outer race 0.021 inches centered @6:00\n",
        "  aquisitions[\"DEOR.021@6_0\"] = \"234.mat\"\n",
        "  aquisitions[\"DEOR.021@6_1\"] = \"235.mat\"\n",
        "  aquisitions[\"DEOR.021@6_2\"] = \"236.mat\"\n",
        "  aquisitions[\"DEOR.021@6_3\"] = \"237.mat\"\n",
        "  # DE Outer race 0.007 inches centered @3:00\n",
        "  aquisitions[\"DEOR.007@3_0\"] = \"144.mat\"\n",
        "  aquisitions[\"DEOR.007@3_1\"] = \"145.mat\"\n",
        "  aquisitions[\"DEOR.007@3_2\"] = \"146.mat\"\n",
        "  aquisitions[\"DEOR.007@3_3\"] = \"147.mat\"\n",
        "  # DE Outer race 0.021 inches centered @3:00\n",
        "  aquisitions[\"DEOR.021@3_0\"] = \"246.mat\"\n",
        "  aquisitions[\"DEOR.021@3_1\"] = \"247.mat\"\n",
        "  aquisitions[\"DEOR.021@3_2\"] = \"248.mat\"\n",
        "  aquisitions[\"DEOR.021@3_3\"] = \"249.mat\"\n",
        "  # DE Outer race 0.007 inches centered @12:00\n",
        "  aquisitions[\"DEOR.007@12_0\"] = \"156.mat\"\n",
        "  aquisitions[\"DEOR.007@12_1\"] = \"158.mat\"\n",
        "  aquisitions[\"DEOR.007@12_2\"] = \"159.mat\"\n",
        "  aquisitions[\"DEOR.007@12_3\"] = \"160.mat\"\n",
        "  # DE Outer race 0.021 inches centered @12:00\n",
        "  aquisitions[\"DEOR.021@12_0\"] = \"258.mat\"\n",
        "  aquisitions[\"DEOR.021@12_1\"] = \"259.mat\"\n",
        "  aquisitions[\"DEOR.021@12_2\"] = \"260.mat\"\n",
        "  aquisitions[\"DEOR.021@12_3\"] = \"261.mat\"\n",
        "  # FE Inner Race 0.007 inches\n",
        "  aquisitions[\"FEIR.007_0\"] = \"278.mat\"\n",
        "  aquisitions[\"FEIR.007_1\"] = \"279.mat\"\n",
        "  aquisitions[\"FEIR.007_2\"] = \"280.mat\"\n",
        "  aquisitions[\"FEIR.007_3\"] = \"281.mat\"\n",
        "  # FE Inner Race 0.014 inches\n",
        "  aquisitions[\"FEIR.014_0\"] = \"274.mat\"\n",
        "  aquisitions[\"FEIR.014_1\"] = \"275.mat\"\n",
        "  aquisitions[\"FEIR.014_2\"] = \"276.mat\"\n",
        "  aquisitions[\"FEIR.014_3\"] = \"277.mat\"\n",
        "  # FE Inner Race 0.021 inches\n",
        "  aquisitions[\"FEIR.021_0\"] = \"270.mat\"\n",
        "  aquisitions[\"FEIR.021_1\"] = \"271.mat\"\n",
        "  aquisitions[\"FEIR.021_2\"] = \"272.mat\"\n",
        "  aquisitions[\"FEIR.021_3\"] = \"273.mat\"\n",
        "  # FE Ball 0.007 inches\n",
        "  aquisitions[\"FEB.007_0\"] = \"282.mat\"\n",
        "  aquisitions[\"FEB.007_1\"] = \"283.mat\"\n",
        "  aquisitions[\"FEB.007_2\"] = \"284.mat\"\n",
        "  aquisitions[\"FEB.007_3\"] = \"285.mat\"\n",
        "  # FE Ball 0.014 inches\n",
        "  aquisitions[\"FEB.014_0\"] = \"286.mat\"\n",
        "  aquisitions[\"FEB.014_1\"] = \"287.mat\"\n",
        "  aquisitions[\"FEB.014_2\"] = \"288.mat\"\n",
        "  aquisitions[\"FEB.014_3\"] = \"289.mat\"\n",
        "  # FE Ball 0.021 inches\n",
        "  aquisitions[\"FEB.021_0\"] = \"290.mat\"\n",
        "  aquisitions[\"FEB.021_1\"] = \"291.mat\"\n",
        "  aquisitions[\"FEB.021_2\"] = \"292.mat\"\n",
        "  aquisitions[\"FEB.021_3\"] = \"293.mat\"\n",
        "  # FE Outer race 0.007 inches centered @6:00\n",
        "  aquisitions[\"FEOR.007@6_0\"] = \"294.mat\"\n",
        "  aquisitions[\"FEOR.007@6_1\"] = \"295.mat\"\n",
        "  aquisitions[\"FEOR.007@6_2\"] = \"296.mat\"\n",
        "  aquisitions[\"FEOR.007@6_3\"] = \"297.mat\"\n",
        "  # FE Outer race 0.014 inches centered @6:00\n",
        "  aquisitions[\"FEOR.014@6_0\"] = \"313.mat\"\n",
        "  # FE Outer race 0.021 inches centered @6:00\n",
        "  aquisitions[\"FEOR.021@6_0\"] = \"315.mat\"\n",
        "  # FE Outer race 0.007 inches centered @3:00\n",
        "  aquisitions[\"FEOR.007@3_0\"] = \"298.mat\"\n",
        "  aquisitions[\"FEOR.007@3_1\"] = \"299.mat\"\n",
        "  aquisitions[\"FEOR.007@3_2\"] = \"300.mat\"\n",
        "  aquisitions[\"FEOR.007@3_3\"] = \"301.mat\"\n",
        "  # FE Outer race 0.014 inches centered @3:00\n",
        "  aquisitions[\"FEOR.014@3_0\"] = \"310.mat\"\n",
        "  aquisitions[\"FEOR.014@3_1\"] = \"309.mat\"\n",
        "  aquisitions[\"FEOR.014@3_2\"] = \"311.mat\"\n",
        "  aquisitions[\"FEOR.014@3_3\"] = \"312.mat\"\n",
        "  # FE Outer race 0.021 inches centered @3:00\n",
        "  aquisitions[\"FEOR.021@3_1\"] = \"316.mat\"\n",
        "  aquisitions[\"FEOR.021@3_2\"] = \"317.mat\"\n",
        "  aquisitions[\"FEOR.021@3_3\"] = \"318.mat\"\n",
        "  # FE Outer race 0.007 inches centered @12:00\n",
        "  aquisitions[\"FEOR.007@12_0\"] = \"302.mat\"\n",
        "  aquisitions[\"FEOR.007@12_1\"] = \"305.mat\"\n",
        "  aquisitions[\"FEOR.007@12_2\"] = \"306.mat\"\n",
        "  aquisitions[\"FEOR.007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "source": [
        "#Functions definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_dict(aquisitions, separator='_'):\n",
        "  \"\"\"Generate a dictionary linking the labels with values to keep consistence.\"\"\"\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    key = key.split('_')[0]\n",
        "    key = key.split(separator)\n",
        "    label = key[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "source": [
        "Convert Matlab file into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "# size of each segment\n",
        "sample_size = 1024\n",
        "def aquisition2tensor(file_name, sample_size=sample_size):\n",
        "  \"\"\"\n",
        "  Convert Matlab file into tensors.\n",
        "  The file is divided in segments of sample_size values.\n",
        "  \"\"\"\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  #signal segmentation\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "source": [
        "Extract datasets from aquisitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  \"\"\"\n",
        "  xd: destination patterns tensor\n",
        "  yd: destination labels tensor\n",
        "  xo: origin patterns tensor to be concateneted \n",
        "  yo: origin labels tensor to be concateneted \n",
        "  \"\"\"\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_substr(substr, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  \"\"\"\n",
        "  Extract samples from all files with some load.\n",
        "  \"\"\"\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if str(substr) in key:\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      for label in labels_dict.keys():\n",
        "        if key.startswith(label):\n",
        "          break\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[label]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(label)\n",
        "  return samples,labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "source": [
        "Define function to plot the confusion matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ut28C6NjT8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import files\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greys):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "source": [
        "#Downloading and Matlab files\n",
        "Extract samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "outputId": "30e1eeaf-7a4e-42fe-e993-c7aff504bc0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "labels_dict = get_labels_dict(aquisitions, '.')\n",
        "print(labels_dict)\n",
        "xn_0,yn_0 = aquisitions_from_substr('Normal_0',aquisitions,labels_dict)\n",
        "xn_1,yn_1 = aquisitions_from_substr('Normal_1',aquisitions,labels_dict)\n",
        "xn_2,yn_2 = aquisitions_from_substr('Normal_2',aquisitions,labels_dict)\n",
        "xn_3,yn_3 = aquisitions_from_substr('Normal_3',aquisitions,labels_dict)\n",
        "x007,y007 = aquisitions_from_substr('007',aquisitions,labels_dict)\n",
        "x014,y014 = aquisitions_from_substr('014',aquisitions,labels_dict)\n",
        "x021,y021 = aquisitions_from_substr('021',aquisitions,labels_dict)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Normal': 0, 'DEIR': 1, 'DEB': 2, 'DEOR': 3, 'FEIR': 4, 'FEB': 5, 'FEOR': 6}\n",
            "97.mat Normal\n",
            "98.mat Normal\n",
            "99.mat Normal\n",
            "100.mat Normal\n",
            "105.mat 106.mat 107.mat 108.mat 118.mat 119.mat 120.mat 121.mat 130.mat 131.mat 132.mat 133.mat 144.mat 145.mat 146.mat 147.mat 156.mat 158.mat 159.mat 160.mat 278.mat 279.mat 280.mat 281.mat 282.mat 283.mat 284.mat 285.mat 294.mat 295.mat 296.mat 297.mat 298.mat 299.mat 300.mat 301.mat 302.mat 305.mat 306.mat 307.mat FEOR\n",
            "169.mat 170.mat 171.mat 172.mat 185.mat 186.mat 187.mat 188.mat 197.mat 198.mat 199.mat 200.mat 274.mat 275.mat 276.mat 277.mat 286.mat 287.mat 288.mat 289.mat 313.mat 310.mat 309.mat 311.mat 312.mat FEOR\n",
            "209.mat 210.mat 211.mat 212.mat 222.mat 223.mat 224.mat 225.mat 234.mat 235.mat 236.mat 237.mat 246.mat 247.mat 248.mat 249.mat 258.mat 259.mat 260.mat 261.mat 270.mat 271.mat 272.mat 273.mat 290.mat 291.mat 292.mat 293.mat 315.mat 316.mat 317.mat 318.mat FEOR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHTas30pJh4h",
        "colab_type": "text"
      },
      "source": [
        "Count number of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFgZMLCbJg6u",
        "colab_type": "code",
        "outputId": "64394263-387c-411e-dd73-0837668819e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "print(\"Label\\t007\\t014\\t021\\ttotal\")\n",
        "for label,value in labels_dict.items():\n",
        "  print(label, end='\\t')\n",
        "  tsamples = 0\n",
        "  if label == 'Normal':\n",
        "    print(3*'\\t'+'...')\n",
        "    for load in range(4):\n",
        "      print(' '+str(load)+3*'\\t', end='\\t')\n",
        "      print(list(eval('yn_'+str(load))).count(value))\n",
        "  else:\n",
        "    for severity in ['007','014','021']:\n",
        "      tmp = eval('y'+str(severity))\n",
        "      if tmp is not None:\n",
        "        nsamples = list(tmp).count(value)\n",
        "        print(nsamples, end='\\t')\n",
        "        tsamples += nsamples\n",
        "      else:\n",
        "        print('0', end='\\t')\n",
        "    print(tsamples)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label\t007\t014\t021\ttotal\n",
            "Normal\t\t\t\t...\n",
            " 0\t\t\t\t238\n",
            " 1\t\t\t\t472\n",
            " 2\t\t\t\t472\n",
            " 3\t\t\t\t474\n",
            "DEIR\t476\t472\t474\t1422\n",
            "DEB\t473\t475\t475\t1423\n",
            "DEOR\t1425\t474\t1425\t3324\n",
            "FEIR\t472\t472\t472\t1416\n",
            "FEB\t471\t474\t471\t1416\n",
            "FEOR\t1418\t590\t469\t2477\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOmONx8MmJHw",
        "colab_type": "text"
      },
      "source": [
        "#Feature Extraction Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huvg2IdrcfuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# roor mean square\n",
        "def rms(x):\n",
        "  x = np.array(x)\n",
        "  return np.sqrt(np.mean(np.square(x)))\n",
        "# square root amplitude\n",
        "def sra(x):\n",
        "  x = np.array(x)\n",
        "  return np.mean(np.sqrt(np.absolute(x)))**2\n",
        "# peak to peak value\n",
        "def ppv(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(x)-np.min(x)\n",
        "# crest factor\n",
        "def cf(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/rms(x)\n",
        "# impact factor\n",
        "def ifa(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/np.mean(np.absolute(x))\n",
        "# margin factor\n",
        "def mf(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/sra(x)\n",
        "# shape factor\n",
        "def sf(x):\n",
        "  x = np.array(x)\n",
        "  return rms(x)/np.mean(np.absolute(x))\n",
        "# kurtosis factor\n",
        "def kf(x):\n",
        "  x = np.array(x)\n",
        "  return stats.kurtosis(x)/(np.mean(x**2)**2)\n",
        "\n",
        "class StatisticalTime(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    de = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,0]])\n",
        "    fe = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,1]])\n",
        "    return np.concatenate((de,fe),axis=1)\n",
        "  \n",
        "class StatisticalFrequency(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    de = []\n",
        "    for x in X[:,:,0]:\n",
        "      fx = np.absolute(np.fft.fft(x))\n",
        "      fc = np.mean(fx)\n",
        "      de.append([fc, rms(fx), rms(fx-fc)])\n",
        "    de = np.array(de)\n",
        "    fe = []\n",
        "    for x in X[:,:,1]:\n",
        "      fx = np.absolute(np.fft.fft(x))\n",
        "      fc = np.mean(fx)\n",
        "      fe.append([fc, rms(fx), rms(fx-fc)])\n",
        "    fe = np.array(fe)\n",
        "    return np.concatenate((de,fe),axis=1)\n",
        "\n",
        "class Statistical(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats),axis=1)\n",
        "   \n",
        "import pywt\n",
        "class WaveletPackage(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    def Energy(coeffs, k):\n",
        "      return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])\n",
        "    def getEnergy(wp):\n",
        "      coefs = np.asarray([n.data for n in wp.get_leaf_nodes(True)])\n",
        "      return np.asarray([Energy(coefs,i) for i in range(2**wp.maxlevel)])\n",
        "    de = np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', mode='symmetric', maxlevel=4)) for x in X[:,:,0]])\n",
        "    fe = np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', mode='symmetric', maxlevel=4)) for x in X[:,:,1]])\n",
        "    return np.concatenate((de,fe),axis=1)\n",
        "\n",
        "class Heterogeneous(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    wp = WaveletPackage()\n",
        "    wpfeats = wp.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats,wpfeats),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "source": [
        "Define model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zp9rCYLc3Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "svm = Pipeline([('FeatureExtraction', Heterogeneous()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('SVM', svm.LinearSVC())])\n",
        "rf = Pipeline([('FeatureExtraction', Heterogeneous()),\n",
        "               ('scaler', StandardScaler()),\n",
        "               ('RF', RandomForestClassifier())])\n",
        "knn = Pipeline([('FeatureExtraction', Heterogeneous()),\n",
        "               ('scaler', StandardScaler()),\n",
        "               ('RF', KNeighborsClassifier())])\n",
        "\n",
        "clfs = [(\"LinearSVM\", svm),\n",
        "        (\"RandomForest\", rf),\n",
        "        (\"K-NN   \", knn)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA7KLli30vu_",
        "colab_type": "text"
      },
      "source": [
        "#Perform experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTUqvMfR53OX",
        "colab_type": "text"
      },
      "source": [
        "##Permissive Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "outputId": "86810972-b6db-457c-a811-da9c930e810a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "warnings.simplefilter(action='ignore', category=UndefinedMetricWarning)\n",
        "\n",
        "nrounds = 1 if debug else 5\n",
        "results = {}\n",
        "models = {}\n",
        "severities = ['007','014','021']\n",
        "X,y = None,None\n",
        "for load in range(4):\n",
        "  X,y = concatenate_datasets(X,y,eval('xn_'+str(load)),eval('yn_'+str(load)))\n",
        "for severity in severities: \n",
        "  X,y = concatenate_datasets(X,y,eval('x'+str(severity)),eval('y'+str(severity)))\n",
        "rskf = RepeatedStratifiedKFold(n_splits=3, n_repeats=nrounds, random_state=36851234)\n",
        "fold = 0\n",
        "count_round = 0\n",
        "\n",
        "results['permissive'] = {}\n",
        "models['permissive'] = {}\n",
        "\n",
        "print(\"Permissive Method\")\n",
        "for train_index, test_index in rskf.split(X, y):\n",
        "  print(\"{}/{}\".format(fold+1,rskf.get_n_splits()//nrounds), end=\" x \")\n",
        "  x_train, x_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  j = count_round//(rskf.get_n_splits()//nrounds)\n",
        "  count_round += 1\n",
        "  print(\"{}/{}\".format(j+1,nrounds))\n",
        "  for clfname,model in clfs:\n",
        "    print(clfname, end=\":\\t\")\n",
        "    if not clfname in results['permissive']:\n",
        "      results['permissive'][clfname] = []\n",
        "    history = model.fit(x_train ,y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    if not clfname+str(fold) in models['permissive']:\n",
        "      models['permissive'][clfname+str(fold)] = model\n",
        "    results['permissive'][clfname].append([accuracy_score(y_test,y_pred),f1_score(y_test,y_pred,average='macro')])\n",
        "    print(results['permissive'][clfname][-1])\n",
        "  if fold >= (rskf.get_n_splits()//nrounds)-1:\n",
        "    fold = 0\n",
        "  else:\n",
        "    fold += 1\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Permissive Method\n",
            "1/3 x 1/5\n",
            "LinearSVM:\t[0.9936058460835807, 0.993276612585998]\n",
            "RandomForest:\t[0.9958894724823019, 0.9952760797890884]\n",
            "K-NN   :\t[0.9947476592829413, 0.9938906791586221]\n",
            "2/3 x 1/5\n",
            "LinearSVM:\t[0.9897213339424394, 0.9893791572941459]\n",
            "RandomForest:\t[0.994289629968022, 0.9940563775932987]\n",
            "K-NN   :\t[0.9956601187756967, 0.9950826297726982]\n",
            "3/3 x 1/5\n",
            "LinearSVM:\t[0.9904043865661412, 0.9898137544973421]\n",
            "RandomForest:\t[0.9977153301347955, 0.9975144311515469]\n",
            "K-NN   :\t[0.995430660269591, 0.9949487798406945]\n",
            "1/3 x 2/5\n",
            "LinearSVM:\t[0.9910938570449874, 0.9903447704437712]\n",
            "RandomForest:\t[0.9949760219228134, 0.9944727823069168]\n",
            "K-NN   :\t[0.9942909340031971, 0.9935653293220961]\n",
            "2/3 x 2/5\n",
            "LinearSVM:\t[0.9915486523526724, 0.9911013820795326]\n",
            "RandomForest:\t[0.9952032891731384, 0.9946297727638754]\n",
            "K-NN   :\t[0.9940612151667428, 0.9931021313386027]\n",
            "3/3 x 2/5\n",
            "LinearSVM:\t[0.9917751884852639, 0.991435382376511]\n",
            "RandomForest:\t[0.995887594242632, 0.9955744920457376]\n",
            "K-NN   :\t[0.9947452593100297, 0.9938453709166825]\n",
            "1/3 x 3/5\n",
            "LinearSVM:\t[0.9906371317652432, 0.9901678209067591]\n",
            "RandomForest:\t[0.9963461977620461, 0.9961818897376366]\n",
            "K-NN   :\t[0.9956611098424297, 0.9950388900333913]\n",
            "2/3 x 3/5\n",
            "LinearSVM:\t[0.9897213339424394, 0.989105148297183]\n",
            "RandomForest:\t[0.9947464595705802, 0.9942968447433155]\n",
            "K-NN   :\t[0.9949748743718593, 0.9940700023101302]\n",
            "3/3 x 3/5\n",
            "LinearSVM:\t[0.9931459904043866, 0.9928662447360252]\n",
            "RandomForest:\t[0.9963445282156729, 0.9958312629061403]\n",
            "K-NN   :\t[0.9956591272561115, 0.9948090635154953]\n",
            "1/3 x 4/5\n",
            "LinearSVM:\t[0.9908654944051153, 0.9903331903708393]\n",
            "RandomForest:\t[0.9977163736012788, 0.9972856834202043]\n",
            "K-NN   :\t[0.9945192966430692, 0.9938562539337988]\n",
            "2/3 x 4/5\n",
            "LinearSVM:\t[0.992462311557789, 0.9919075185181835]\n",
            "RandomForest:\t[0.9933759707629054, 0.9926398552702276]\n",
            "K-NN   :\t[0.9952032891731384, 0.9943209563073079]\n",
            "3/3 x 4/5\n",
            "LinearSVM:\t[0.9890335846470185, 0.988334613606366]\n",
            "RandomForest:\t[0.9952021932830706, 0.9949066595224813]\n",
            "K-NN   :\t[0.9940598583504684, 0.9931587931476183]\n",
            "1/3 x 5/5\n",
            "LinearSVM:\t[0.9892669559260105, 0.988810146485578]\n",
            "RandomForest:\t[0.9956611098424297, 0.9951618096414764]\n",
            "K-NN   :\t[0.9938342087234528, 0.9929062683998765]\n",
            "2/3 x 5/5\n",
            "LinearSVM:\t[0.9929191411603472, 0.9923518290076739]\n",
            "RandomForest:\t[0.9956601187756967, 0.9950405875308539]\n",
            "K-NN   :\t[0.9936043855641845, 0.9925872913148515]\n",
            "3/3 x 5/5\n",
            "LinearSVM:\t[0.9926890564313456, 0.9922613652041808]\n",
            "RandomForest:\t[0.9968014621887137, 0.9966544481150164]\n",
            "K-NN   :\t[0.9963445282156729, 0.9958378913863078]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzqFADC9JoN",
        "colab_type": "text"
      },
      "source": [
        "##Restritive Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUiqjOvP9Myl",
        "colab_type": "code",
        "outputId": "61230701-2c3a-41ac-88a1-d823f17b1e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "results['restritive'] = {}\n",
        "models['restritive'] = {}\n",
        "\n",
        "print(\"Restritive Method\")\n",
        "for i,fold in enumerate(severities):\n",
        "  print(\"{}\".format(fold), end=\" x \")\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  for load in range(4):\n",
        "    step = len(eval('yn_'+str(load)))//len(severities)\n",
        "    xn = eval('xn_'+str(load)+'['+str(i*step)+':'+str((i+1)*step)+']')\n",
        "    yn = eval('yn_'+str(load)+'['+str(i*step)+':'+str((i+1)*step)+']')\n",
        "    x_test = np.concatenate((x_test,xn))\n",
        "    y_test = np.concatenate((y_test,yn))\n",
        "  x_train,y_train = None,None #xnormal,ynormal\n",
        "  for tfold in severities[:i]+severities[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "    for load in range(4):\n",
        "      step = len(eval('yn_'+str(load)))//len(severities)\n",
        "      xn = eval('xn_'+str(load)+'[:'+str(i*step)+']')\n",
        "      yn = eval('yn_'+str(load)+'[:'+str(i*step)+']')\n",
        "      x_train = np.concatenate((x_train,xn))\n",
        "      y_train = np.concatenate((y_train,yn))\n",
        "      xn = eval('xn_'+str(load)+'['+str(i*step)+':]')\n",
        "      yn = eval('yn_'+str(load)+'['+str(i*step)+':]')\n",
        "      x_train = np.concatenate((x_train,xn))\n",
        "      y_train = np.concatenate((y_train,yn))\n",
        "  for j in range(nrounds):\n",
        "    print(\"{}/{}\".format(j+1,nrounds))\n",
        "    for clfname,model in clfs:\n",
        "      print(clfname, end=\":\\t\")\n",
        "      if not clfname in results['restritive']:\n",
        "        results['restritive'][clfname] = []\n",
        "      history = model.fit(x_train ,y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      if not clfname+str(fold) in models['restritive']:\n",
        "        models['restritive'][clfname+str(fold)] = model\n",
        "      results['restritive'][clfname].append([accuracy_score(y_test,y_pred),f1_score(y_test,y_pred,average='macro')])\n",
        "      print(results['restritive'][clfname][-1])\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restritive Method\n",
            "007 x 1/5\n",
            "LinearSVM:\t[0.41732879303821413, 0.40035132882952645]\n",
            "RandomForest:\t[0.3261445327279606, 0.3891061960498902]\n",
            "K-NN   :\t[0.3583049564888384, 0.3685778023886729]\n",
            "2/5\n",
            "LinearSVM:\t[0.4175179720015134, 0.4005046371884849]\n",
            "RandomForest:\t[0.3618993567915248, 0.386351839766558]\n",
            "K-NN   :\t[0.3583049564888384, 0.3685778023886729]\n",
            "3/5\n",
            "LinearSVM:\t[0.41732879303821413, 0.40035132882952645]\n",
            "RandomForest:\t[0.3384411653424139, 0.38501814793668393]\n",
            "K-NN   :\t[0.3583049564888384, 0.3685778023886729]\n",
            "4/5\n",
            "LinearSVM:\t[0.4175179720015134, 0.4005046371884849]\n",
            "RandomForest:\t[0.29701097237987134, 0.3429377705631724]\n",
            "K-NN   :\t[0.3583049564888384, 0.3685778023886729]\n",
            "5/5\n",
            "LinearSVM:\t[0.41732879303821413, 0.40035132882952645]\n",
            "RandomForest:\t[0.27695800227014755, 0.32381754592206197]\n",
            "K-NN   :\t[0.3583049564888384, 0.3685778023886729]\n",
            "014 x 1/5\n",
            "LinearSVM:\t[0.5324971493728621, 0.48540122457712354]\n",
            "RandomForest:\t[0.47377423033067273, 0.4169530470039563]\n",
            "K-NN   :\t[0.3982326111744584, 0.32994899384524856]\n",
            "2/5\n",
            "LinearSVM:\t[0.5327822120866591, 0.4856319000566834]\n",
            "RandomForest:\t[0.4492588369441277, 0.3840406885266799]\n",
            "K-NN   :\t[0.3982326111744584, 0.32994899384524856]\n",
            "3/5\n",
            "LinearSVM:\t[0.5333523375142531, 0.4860787170594348]\n",
            "RandomForest:\t[0.4167616875712657, 0.37416111212565745]\n",
            "K-NN   :\t[0.3982326111744584, 0.32994899384524856]\n",
            "4/5\n",
            "LinearSVM:\t[0.5299315849486887, 0.4837680330858852]\n",
            "RandomForest:\t[0.46322690992018245, 0.3968526581663509]\n",
            "K-NN   :\t[0.3982326111744584, 0.32994899384524856]\n",
            "5/5\n",
            "LinearSVM:\t[0.5324971493728621, 0.48539836467041436]\n",
            "RandomForest:\t[0.4258836944127708, 0.3711867248861761]\n",
            "K-NN   :\t[0.3982326111744584, 0.32994899384524856]\n",
            "021 x 1/5\n",
            "LinearSVM:\t[0.329029282914457, 0.3316695303022236]\n",
            "RandomForest:\t[0.4915840442702329, 0.49626699815742886]\n",
            "K-NN   :\t[0.394973483975098, 0.3991479116963679]\n",
            "2/5\n",
            "LinearSVM:\t[0.329029282914457, 0.33165605374897494]\n",
            "RandomForest:\t[0.5715932672354161, 0.574270404008213]\n",
            "K-NN   :\t[0.394973483975098, 0.3991479116963679]\n",
            "3/5\n",
            "LinearSVM:\t[0.329029282914457, 0.3316695303022236]\n",
            "RandomForest:\t[0.4643762969794789, 0.4698520746027245]\n",
            "K-NN   :\t[0.394973483975098, 0.3991479116963679]\n",
            "4/5\n",
            "LinearSVM:\t[0.3287987087848743, 0.3314388722268867]\n",
            "RandomForest:\t[0.5086465298593498, 0.5104573167182862]\n",
            "K-NN   :\t[0.394973483975098, 0.3991479116963679]\n",
            "5/5\n",
            "LinearSVM:\t[0.329029282914457, 0.33168041197570414]\n",
            "RandomForest:\t[0.5729767120129121, 0.5729365775476376]\n",
            "K-NN   :\t[0.394973483975098, 0.3991479116963679]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dpUZ9Q0S4Nl",
        "colab_type": "text"
      },
      "source": [
        "#Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-05LJK0S4wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4abcc2f0-e84d-4d11-a04d-b6549c0a8240"
      },
      "source": [
        "for evaluation in results.keys():\n",
        "  print(\"\\n\"+30*\"#\"+\"\\n\"+evaluation+\"\\n\"+30*\"#\")\n",
        "  for clfname,model in clfs:\n",
        "    print(\"\\n\\t\"+clfname+\" Results\\nFold\\tAccuracy\\tF1-Score\")\n",
        "    for i,r in enumerate(results[evaluation][clfname]):\n",
        "      print(\"{}\\t\".format(i+1),end=\"\")\n",
        "      print(r)\n",
        "    print(\"Average\\tAccuracy\\tF1-Score\\n\\t\",end=\"\")\n",
        "    print(np.mean(results[evaluation][clfname],axis=0))\n",
        "    print(\"StdDev\\tAccuracy\\tF1-Score\\n\\t\",end=\"\")\n",
        "    print(np.std(results[evaluation][clfname],axis=0))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "##############################\n",
            "permissive\n",
            "##############################\n",
            "\n",
            "\tLinearSVM Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.9936058460835807, 0.993276612585998]\n",
            "2\t[0.9897213339424394, 0.9893791572941459]\n",
            "3\t[0.9904043865661412, 0.9898137544973421]\n",
            "4\t[0.9910938570449874, 0.9903447704437712]\n",
            "5\t[0.9915486523526724, 0.9911013820795326]\n",
            "6\t[0.9917751884852639, 0.991435382376511]\n",
            "7\t[0.9906371317652432, 0.9901678209067591]\n",
            "8\t[0.9897213339424394, 0.989105148297183]\n",
            "9\t[0.9931459904043866, 0.9928662447360252]\n",
            "10\t[0.9908654944051153, 0.9903331903708393]\n",
            "11\t[0.992462311557789, 0.9919075185181835]\n",
            "12\t[0.9890335846470185, 0.988334613606366]\n",
            "13\t[0.9892669559260105, 0.988810146485578]\n",
            "14\t[0.9929191411603472, 0.9923518290076739]\n",
            "15\t[0.9926890564313456, 0.9922613652041808]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.99125935 0.99076593]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.00142867 0.00149169]\n",
            "\n",
            "\tRandomForest Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.9958894724823019, 0.9952760797890884]\n",
            "2\t[0.994289629968022, 0.9940563775932987]\n",
            "3\t[0.9977153301347955, 0.9975144311515469]\n",
            "4\t[0.9949760219228134, 0.9944727823069168]\n",
            "5\t[0.9952032891731384, 0.9946297727638754]\n",
            "6\t[0.995887594242632, 0.9955744920457376]\n",
            "7\t[0.9963461977620461, 0.9961818897376366]\n",
            "8\t[0.9947464595705802, 0.9942968447433155]\n",
            "9\t[0.9963445282156729, 0.9958312629061403]\n",
            "10\t[0.9977163736012788, 0.9972856834202043]\n",
            "11\t[0.9933759707629054, 0.9926398552702276]\n",
            "12\t[0.9952021932830706, 0.9949066595224813]\n",
            "13\t[0.9956611098424297, 0.9951618096414764]\n",
            "14\t[0.9956601187756967, 0.9950405875308539]\n",
            "15\t[0.9968014621887137, 0.9966544481150164]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.99572105 0.99530153]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.00114191 0.00123345]\n",
            "\n",
            "\tK-NN    Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.9947476592829413, 0.9938906791586221]\n",
            "2\t[0.9956601187756967, 0.9950826297726982]\n",
            "3\t[0.995430660269591, 0.9949487798406945]\n",
            "4\t[0.9942909340031971, 0.9935653293220961]\n",
            "5\t[0.9940612151667428, 0.9931021313386027]\n",
            "6\t[0.9947452593100297, 0.9938453709166825]\n",
            "7\t[0.9956611098424297, 0.9950388900333913]\n",
            "8\t[0.9949748743718593, 0.9940700023101302]\n",
            "9\t[0.9956591272561115, 0.9948090635154953]\n",
            "10\t[0.9945192966430692, 0.9938562539337988]\n",
            "11\t[0.9952032891731384, 0.9943209563073079]\n",
            "12\t[0.9940598583504684, 0.9931587931476183]\n",
            "13\t[0.9938342087234528, 0.9929062683998765]\n",
            "14\t[0.9936043855641845, 0.9925872913148515]\n",
            "15\t[0.9963445282156729, 0.9958378913863078]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.9948531  0.99406802]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.00077258 0.00090088]\n",
            "\n",
            "##############################\n",
            "restritive\n",
            "##############################\n",
            "\n",
            "\tLinearSVM Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.41732879303821413, 0.40035132882952645]\n",
            "2\t[0.4175179720015134, 0.4005046371884849]\n",
            "3\t[0.41732879303821413, 0.40035132882952645]\n",
            "4\t[0.4175179720015134, 0.4005046371884849]\n",
            "5\t[0.41732879303821413, 0.40035132882952645]\n",
            "6\t[0.5324971493728621, 0.48540122457712354]\n",
            "7\t[0.5327822120866591, 0.4856319000566834]\n",
            "8\t[0.5333523375142531, 0.4860787170594348]\n",
            "9\t[0.5299315849486887, 0.4837680330858852]\n",
            "10\t[0.5324971493728621, 0.48539836467041436]\n",
            "11\t[0.329029282914457, 0.3316695303022236]\n",
            "12\t[0.329029282914457, 0.33165605374897494]\n",
            "13\t[0.329029282914457, 0.3316695303022236]\n",
            "14\t[0.3287987087848743, 0.3314388722268867]\n",
            "15\t[0.329029282914457, 0.33168041197570414]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.42619991 0.40576373]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.08320347 0.06283601]\n",
            "\n",
            "\tRandomForest Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.3261445327279606, 0.3891061960498902]\n",
            "2\t[0.3618993567915248, 0.386351839766558]\n",
            "3\t[0.3384411653424139, 0.38501814793668393]\n",
            "4\t[0.29701097237987134, 0.3429377705631724]\n",
            "5\t[0.27695800227014755, 0.32381754592206197]\n",
            "6\t[0.47377423033067273, 0.4169530470039563]\n",
            "7\t[0.4492588369441277, 0.3840406885266799]\n",
            "8\t[0.4167616875712657, 0.37416111212565745]\n",
            "9\t[0.46322690992018245, 0.3968526581663509]\n",
            "10\t[0.4258836944127708, 0.3711867248861761]\n",
            "11\t[0.4915840442702329, 0.49626699815742886]\n",
            "12\t[0.5715932672354161, 0.574270404008213]\n",
            "13\t[0.4643762969794789, 0.4698520746027245]\n",
            "14\t[0.5086465298593498, 0.5104573167182862]\n",
            "15\t[0.5729767120129121, 0.5729365775476376]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.42923575 0.42628061]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.08949479 0.07655228]\n",
            "\n",
            "\tK-NN    Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.3583049564888384, 0.3685778023886729]\n",
            "2\t[0.3583049564888384, 0.3685778023886729]\n",
            "3\t[0.3583049564888384, 0.3685778023886729]\n",
            "4\t[0.3583049564888384, 0.3685778023886729]\n",
            "5\t[0.3583049564888384, 0.3685778023886729]\n",
            "6\t[0.3982326111744584, 0.32994899384524856]\n",
            "7\t[0.3982326111744584, 0.32994899384524856]\n",
            "8\t[0.3982326111744584, 0.32994899384524856]\n",
            "9\t[0.3982326111744584, 0.32994899384524856]\n",
            "10\t[0.3982326111744584, 0.32994899384524856]\n",
            "11\t[0.394973483975098, 0.3991479116963679]\n",
            "12\t[0.394973483975098, 0.3991479116963679]\n",
            "13\t[0.394973483975098, 0.3991479116963679]\n",
            "14\t[0.394973483975098, 0.3991479116963679]\n",
            "15\t[0.394973483975098, 0.3991479116963679]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.38383702 0.36589157]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.01810286 0.02831412]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}