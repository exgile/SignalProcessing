{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CWRU-EvaluationFramework-bkp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/SignalProcessing/blob/master/CWRU_EvaluationFramework_DE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSSOMru17Z6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMQoq6dvStey",
        "colab_type": "text"
      },
      "source": [
        "# CWRU files.\n",
        "\n",
        "Associate each Matlab file name to a bearing condition in a Python dictionary.\n",
        "The dictionary keys identify the conditions.\n",
        "\n",
        "There are only four normal conditions, with loads of 0, 1, 2 and 3 hp.\n",
        "All conditions end with an underscore character followed by an algarism representing the load applied during the acquisitions.\n",
        "The remaining conditions follow the pattern:\n",
        "\n",
        "\n",
        "* First two characters represent the bearing location, i.e. drive end (DE) and fan end (FE).\n",
        "* The following two characters represent the failure location in the bearing, i.e. ball (BA), Inner Race (IR) and Outer Race (OR).\n",
        "* The next three algarisms indicate the severity of the failure, where 007 stands for 0.007 inches and 0021 for 0.021 inches.\n",
        "* For Outer Race failures, the character @ is followed by a number that indicates different load zones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6mp2QrP1lmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cwru_12khz():\n",
        "  '''\n",
        "  Retuns a dictionary with the names of all Matlab files read in 12kHz located in\n",
        "  http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/.\n",
        "  The dictionary keys represent the bearing condition.\n",
        "  '''\n",
        "  matlab_files_name = {}\n",
        "  # Normal\n",
        "  matlab_files_name[\"Normal_0\"] = \"97.mat\"\n",
        "  matlab_files_name[\"Normal_1\"] = \"98.mat\"\n",
        "  matlab_files_name[\"Normal_2\"] = \"99.mat\"\n",
        "  matlab_files_name[\"Normal_3\"] = \"100.mat\"\n",
        "  # DE Inner Race 0.007 inches\n",
        "  matlab_files_name[\"DEIR.007_0\"] = \"105.mat\"\n",
        "  matlab_files_name[\"DEIR.007_1\"] = \"106.mat\"\n",
        "  matlab_files_name[\"DEIR.007_2\"] = \"107.mat\"\n",
        "  matlab_files_name[\"DEIR.007_3\"] = \"108.mat\"\n",
        "  # DE Ball 0.007 inches\n",
        "  matlab_files_name[\"DEB.007_0\"] = \"118.mat\"\n",
        "  matlab_files_name[\"DEB.007_1\"] = \"119.mat\"\n",
        "  matlab_files_name[\"DEB.007_2\"] = \"120.mat\"\n",
        "  matlab_files_name[\"DEB.007_3\"] = \"121.mat\"\n",
        "  # DE Outer race 0.007 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.007@6_0\"] = \"130.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_1\"] = \"131.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_2\"] = \"132.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_3\"] = \"133.mat\"\n",
        "  # DE Outer race 0.007 inches centered @3:00\n",
        "  matlab_files_name[\"DEOR.007@3_0\"] = \"144.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_1\"] = \"145.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_2\"] = \"146.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_3\"] = \"147.mat\"\n",
        "  # DE Outer race 0.007 inches centered @12:00\n",
        "  matlab_files_name[\"DEOR.007@12_0\"] = \"156.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_1\"] = \"158.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_2\"] = \"159.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_3\"] = \"160.mat\"\n",
        "  # DE Inner Race 0.014 inches\n",
        "  matlab_files_name[\"DEIR.014_0\"] = \"169.mat\"\n",
        "  matlab_files_name[\"DEIR.014_1\"] = \"170.mat\"\n",
        "  matlab_files_name[\"DEIR.014_2\"] = \"171.mat\"\n",
        "  matlab_files_name[\"DEIR.014_3\"] = \"172.mat\"\n",
        "  # DE Ball 0.014 inches\n",
        "  matlab_files_name[\"DEB.014_0\"] = \"185.mat\"\n",
        "  matlab_files_name[\"DEB.014_1\"] = \"186.mat\"\n",
        "  matlab_files_name[\"DEB.014_2\"] = \"187.mat\"\n",
        "  matlab_files_name[\"DEB.014_3\"] = \"188.mat\"\n",
        "  # DE Outer race 0.014 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.014@6_0\"] = \"197.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_1\"] = \"198.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_2\"] = \"199.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_3\"] = \"200.mat\"\n",
        "  # DE Ball 0.021 inches\n",
        "  matlab_files_name[\"DEB.021_0\"] = \"222.mat\"\n",
        "  matlab_files_name[\"DEB.021_1\"] = \"223.mat\"\n",
        "  matlab_files_name[\"DEB.021_2\"] = \"224.mat\"\n",
        "  matlab_files_name[\"DEB.021_3\"] = \"225.mat\"\n",
        "  # FE Inner Race 0.021 inches\n",
        "  matlab_files_name[\"FEIR.021_0\"] = \"270.mat\"\n",
        "  matlab_files_name[\"FEIR.021_1\"] = \"271.mat\"\n",
        "  matlab_files_name[\"FEIR.021_2\"] = \"272.mat\"\n",
        "  matlab_files_name[\"FEIR.021_3\"] = \"273.mat\"\n",
        "  # FE Inner Race 0.014 inches\n",
        "  matlab_files_name[\"FEIR.014_0\"] = \"274.mat\"\n",
        "  matlab_files_name[\"FEIR.014_1\"] = \"275.mat\"\n",
        "  matlab_files_name[\"FEIR.014_2\"] = \"276.mat\"\n",
        "  matlab_files_name[\"FEIR.014_3\"] = \"277.mat\"\n",
        "  # FE Ball 0.007 inches\n",
        "  matlab_files_name[\"FEB.007_0\"] = \"282.mat\"\n",
        "  matlab_files_name[\"FEB.007_1\"] = \"283.mat\"\n",
        "  matlab_files_name[\"FEB.007_2\"] = \"284.mat\"\n",
        "  matlab_files_name[\"FEB.007_3\"] = \"285.mat\"\n",
        "  # DE Inner Race 0.021 inches\n",
        "  matlab_files_name[\"DEIR.021_0\"] = \"209.mat\"\n",
        "  matlab_files_name[\"DEIR.021_1\"] = \"210.mat\"\n",
        "  matlab_files_name[\"DEIR.021_2\"] = \"211.mat\"\n",
        "  matlab_files_name[\"DEIR.021_3\"] = \"212.mat\"\n",
        "  # DE Outer race 0.021 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.021@6_0\"] = \"234.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_1\"] = \"235.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_2\"] = \"236.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_3\"] = \"237.mat\"\n",
        "  # DE Outer race 0.021 inches centered @3:00\n",
        "  matlab_files_name[\"DEOR.021@3_0\"] = \"246.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_1\"] = \"247.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_2\"] = \"248.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_3\"] = \"249.mat\"\n",
        "  # DE Outer race 0.021 inches centered @12:00\n",
        "  matlab_files_name[\"DEOR.021@12_0\"] = \"258.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_1\"] = \"259.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_2\"] = \"260.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_3\"] = \"261.mat\"\n",
        "  # FE Inner Race 0.007 inches\n",
        "  matlab_files_name[\"FEIR.007_0\"] = \"278.mat\"\n",
        "  matlab_files_name[\"FEIR.007_1\"] = \"279.mat\"\n",
        "  matlab_files_name[\"FEIR.007_2\"] = \"280.mat\"\n",
        "  matlab_files_name[\"FEIR.007_3\"] = \"281.mat\"\n",
        "  # FE Ball 0.014 inches\n",
        "  matlab_files_name[\"FEB.014_0\"] = \"286.mat\"\n",
        "  matlab_files_name[\"FEB.014_1\"] = \"287.mat\"\n",
        "  matlab_files_name[\"FEB.014_2\"] = \"288.mat\"\n",
        "  matlab_files_name[\"FEB.014_3\"] = \"289.mat\"\n",
        "  # FE Ball 0.021 inches\n",
        "  matlab_files_name[\"FEB.021_0\"] = \"290.mat\"\n",
        "  matlab_files_name[\"FEB.021_1\"] = \"291.mat\"\n",
        "  matlab_files_name[\"FEB.021_2\"] = \"292.mat\"\n",
        "  matlab_files_name[\"FEB.021_3\"] = \"293.mat\"\n",
        "  # FE Outer race 0.007 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.007@6_0\"] = \"294.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_1\"] = \"295.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_2\"] = \"296.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_3\"] = \"297.mat\"\n",
        "  # FE Outer race 0.007 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.007@3_0\"] = \"298.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_1\"] = \"299.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_2\"] = \"300.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_3\"] = \"301.mat\"\n",
        "  # FE Outer race 0.007 inches centered @12:00\n",
        "  matlab_files_name[\"FEOR.007@12_0\"] = \"302.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_1\"] = \"305.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_2\"] = \"306.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_3\"] = \"307.mat\"\n",
        "  # FE Outer race 0.014 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.014@3_0\"] = \"310.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_1\"] = \"309.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_2\"] = \"311.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_3\"] = \"312.mat\"\n",
        "  # FE Outer race 0.014 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.014@6_0\"] = \"313.mat\"\n",
        "  # FE Outer race 0.021 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.021@6_0\"] = \"315.mat\"\n",
        "  # FE Outer race 0.021 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.021@3_1\"] = \"316.mat\"\n",
        "  matlab_files_name[\"FEOR.021@3_2\"] = \"317.mat\"\n",
        "  matlab_files_name[\"FEOR.021@3_3\"] = \"318.mat\"\n",
        "  # DE Inner Race 0.028 inches\n",
        "  matlab_files_name[\"DEIR.028_0\"] = \"3001.mat\"\n",
        "  matlab_files_name[\"DEIR.028_1\"] = \"3002.mat\"\n",
        "  matlab_files_name[\"DEIR.028_2\"] = \"3003.mat\"\n",
        "  matlab_files_name[\"DEIR.028_3\"] = \"3004.mat\"\n",
        "  # DE Ball 0.028 inches\n",
        "  matlab_files_name[\"DEB.028_0\"] = \"3005.mat\"\n",
        "  matlab_files_name[\"DEB.028_1\"] = \"3006.mat\"\n",
        "  matlab_files_name[\"DEB.028_2\"] = \"3007.mat\"\n",
        "  matlab_files_name[\"DEB.028_3\"] = \"3008.mat\"\n",
        "  return matlab_files_name"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9y9byVeSz_u",
        "colab_type": "text"
      },
      "source": [
        "##Download Matlab files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPSGH1401-W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import os.path\n",
        "\n",
        "def download_cwrufiles(matlab_files_name):\n",
        "  '''\n",
        "  Downloads the Matlab files in the dictionary matlab_files_name.\n",
        "  '''\n",
        "  url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "  n = len(matlab_files_name)\n",
        "  for i,key in enumerate(matlab_files_name):\n",
        "    file_name = matlab_files_name[key]\n",
        "    if not os.path.exists(file_name):\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "    print(\"{}/{}\\t{}\\t{}\".format(i+1, n, key, file_name))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRijKbOjS-JZ",
        "colab_type": "text"
      },
      "source": [
        "##Extract data from Matlab files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbpFkSI12CUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def get_tensors_from_matlab(matlab_files_name):\n",
        "  '''\n",
        "  Extracts the acquisitions of each Matlab file in the dictionary matlab_files_name.\n",
        "  '''\n",
        "  acquisitions = {}\n",
        "  for key in matlab_files_name:\n",
        "    file_name = matlab_files_name[key]\n",
        "    matlab_file = scipy.io.loadmat(file_name)\n",
        "    for position in ['DE','FE', 'BA']:\n",
        "      keys = [key for key in matlab_file if key.endswith(position+\"_time\")]\n",
        "      if len(keys)>0:\n",
        "        array_key = keys[0]\n",
        "        acquisitions[key+position.lower()] = matlab_file[array_key].reshape(1,-1)[0]\n",
        "  return acquisitions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2lcukz5Nyk",
        "colab_type": "text"
      },
      "source": [
        "##Downloading pickle file\n",
        "Following, some auxiliary functions to download a pickle file in a google drive account.\n",
        "The pickle file already has the acquisitions propertly extracted.\n",
        "Therefore, these functions might speed up the whole process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkpaFxn1xtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "file_id = \"1qJezMiROz9NAYafPUDPh9BFkxYF4nOi2\"\n",
        "destination = 'cwru.pickle'\n",
        "\n",
        "try:\n",
        "  download_file_from_google_drive(file_id, destination)\n",
        "except:\n",
        "  print(\"Download failed!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEzRboCpgtlx",
        "colab_type": "text"
      },
      "source": [
        "##Save/Load data\n",
        "If the cwru pickle file is already download, it will not be downloaded again, and the dictionary with the acquisitions will be loaded.\n",
        "Otherwise, the desired files are downloaded and the acquisitions are extrated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1m5Q3OUbvqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "pickle_file = 'cwru.pickle'\n",
        "if os.path.isfile(pickle_file):\n",
        "  with open(pickle_file, 'rb') as handle:\n",
        "    acquisitions = pickle.load(handle)\n",
        "else:\n",
        "  matlab_files_name = cwru_12khz()\n",
        "  download_cwrufiles(matlab_files_name)\n",
        "  acquisitions = get_tensors_from_matlab(matlab_files_name)\n",
        "  with open(pickle_file, 'wb') as handle:\n",
        "    pickle.dump(acquisitions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT7hgDnzTcNP",
        "colab_type": "text"
      },
      "source": [
        "##Segment data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BKfioJFzAKA",
        "colab_type": "code",
        "outputId": "4151c14e-c533-48ac-9e68-1f72c376d868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "def cwru_segmentation(acquisitions, sample_size=512, max_samples=None):\n",
        "  '''\n",
        "  Segments the acquisitions.\n",
        "  sample_size is the size of each segment.\n",
        "  max_samples is used for debug purpouses and \n",
        "  reduces the number of samples from each acquisition.\n",
        "  '''\n",
        "  origin = []\n",
        "  data = np.empty((0,sample_size,1))\n",
        "  n = len(acquisitions)\n",
        "  for i,key in enumerate(acquisitions):\n",
        "    acquisition_size = len(acquisitions[key])\n",
        "    n_samples = acquisition_size//sample_size\n",
        "    if max_samples is not None and max_samples > 0 and n_samples > max_samples:\n",
        "      n_samples = max_samples\n",
        "    print('\\r{}/{} --- {}:\\t{}'.format(i+1, n, key, n_samples), end='')\n",
        "    origin.extend([key for _ in range(n_samples)])\n",
        "    data = np.concatenate((data,\n",
        "           acquisitions[key][:(n_samples*sample_size)].reshape(\n",
        "               (n_samples,sample_size,1))))\n",
        "  return data,origin\n",
        "\n",
        "if True: #not debug:\n",
        "  signal_data,signal_origin = cwru_segmentation(acquisitions, 512)\n",
        "else:\n",
        "  signal_data,signal_origin = cwru_segmentation(acquisitions, 512, 2) #debug mode\n",
        "\n",
        "signal_data.shape\n"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "307/307 --- DEB.028_3de:\t236"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77527, 512, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 240
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpVAzW73-buw",
        "colab_type": "text"
      },
      "source": [
        "#Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLeArq-uThHW",
        "colab_type": "text"
      },
      "source": [
        "##Feature Extraction Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSNj6YIEhu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm95T4CsDxaN",
        "colab_type": "text"
      },
      "source": [
        "###Statistical functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWCPUON8D1A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def rms(x):\n",
        "  '''\n",
        "  root mean square\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.sqrt(np.mean(np.square(x)))\n",
        "\n",
        "def sra(x):\n",
        "  '''\n",
        "  square root amplitude\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.mean(np.sqrt(np.absolute(x)))**2\n",
        "\n",
        "def ppv(x):\n",
        "  '''\n",
        "  peak to peak value\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(x)-np.min(x)\n",
        "\n",
        "def cf(x):\n",
        "  '''\n",
        "  crest factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/rms(x)\n",
        "\n",
        "def ifa(x):\n",
        "  '''\n",
        "  impact factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/np.mean(np.absolute(x))\n",
        "\n",
        "def mf(x):\n",
        "  '''\n",
        "  margin factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/sra(x)\n",
        "\n",
        "def sf(x):\n",
        "  '''\n",
        "  shape factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return rms(x)/np.mean(np.absolute(x))\n",
        "\n",
        "def kf(x):\n",
        "  '''\n",
        "  kurtosis factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return stats.kurtosis(x)/(np.mean(x**2)**2)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njMb9HtUEBrI",
        "colab_type": "text"
      },
      "source": [
        "### Statistical Features from Time Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSN2_c28D_Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StatisticalTime(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from the time domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    return np.array([\n",
        "                     [\n",
        "                      rms(x), # root mean square\n",
        "                      sra(x), # square root amplitude\n",
        "                      stats.kurtosis(x), # kurtosis\n",
        "                      stats.skew(x), # skewness\n",
        "                      ppv(x), # peak to peak value\n",
        "                      cf(x), # crest factor\n",
        "                      ifa(x), # impact factor\n",
        "                      mf(x), # margin factor\n",
        "                      sf(x), # shape factor\n",
        "                      kf(x), # kurtosis factor\n",
        "                      ] for x in X[:,:,0]\n",
        "                     ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXDWD3JZEnep",
        "colab_type": "text"
      },
      "source": [
        "### Statistical Features from Frequency Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj3XTpVTEvAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StatisticalFrequency(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from the frequency domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    sig = []\n",
        "    for x in X[:,:,0]:\n",
        "      fx = np.absolute(np.fft.fft(x)) # transform x from time to frequency domain\n",
        "      fc = np.mean(fx) # frequency center\n",
        "      sig.append([\n",
        "                  fc, # frequency center\n",
        "                  rms(fx), # RMS from the frequency domain\n",
        "                  rms(fx-fc), # Root Variance Frequency\n",
        "                  ])\n",
        "    return np.array(sig)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0YBmzTb6ARb",
        "colab_type": "text"
      },
      "source": [
        "###Statistical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kep4ubkR6DR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Statistical(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from both time and frequency domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuiVsHNzFORr",
        "colab_type": "text"
      },
      "source": [
        "###Wavelet Package Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPd92xtJhaH3",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "class WaveletPackage(TransformerMixin):\n",
        "  '''\n",
        "  Extracts Wavelet Package features.\n",
        "  The features are calculated by the energy of the recomposed signal\n",
        "  of the leaf nodes coeficients.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    def Energy(coeffs, k):\n",
        "      return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])\n",
        "    def getEnergy(wp):\n",
        "      coefs = np.asarray([n.data for n in wp.get_leaf_nodes(True)])\n",
        "      return np.asarray([Energy(coefs,i) for i in range(2**wp.maxlevel)])\n",
        "    return np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', \n",
        "                                                  mode='symmetric', maxlevel=4)\n",
        "                                                  ) for x in X[:,:,0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_sonHkjFYbB",
        "colab_type": "text"
      },
      "source": [
        "###Heterogeneus Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZsZhuVfFZsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Heterogeneous(TransformerMixin):\n",
        "  '''\n",
        "  Mixes Statistical and Wavelet Package features.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    wp = WaveletPackage()\n",
        "    wpfeats = wp.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats,wpfeats),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jCN8XZ5dOF3",
        "colab_type": "text"
      },
      "source": [
        "## Clean dataset functions\n",
        "The functions below help to select samples from acquisitions and form groups according to these acquisitions, using regular expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOOP9H2c3AaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def select_samples(regex, X, y):\n",
        "  '''\n",
        "  Selects samples wich has some regex pattern in its name.\n",
        "  '''\n",
        "  mask = [re.search(regex,label) is not None for label in y]\n",
        "  return X[mask],y[mask]\n",
        "\n",
        "def join_labels(regex, y):\n",
        "  '''\n",
        "  Excludes some regex patterns from the labels, \n",
        "  making some samples to have the same label.\n",
        "  '''\n",
        "  return np.array([re.sub(regex, '', label) for label in y])\n",
        "\n",
        "def get_groups(regex, y):\n",
        "  '''\n",
        "  Generates a list of groups of samples with \n",
        "  the same regex patten in its label.\n",
        "  '''\n",
        "  groups = list(range(len(y)))\n",
        "  for i,label in enumerate(y):\n",
        "    match = re.search(regex,label)\n",
        "    groups[i] = match.group(0) if match else None\n",
        "  return groups"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFA-8l02RplD",
        "colab_type": "text"
      },
      "source": [
        "##Selecting samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r89dYOJm8gzW",
        "colab_type": "code",
        "outputId": "0804d5c3-9c0e-4d9a-8901-5bc54a6b3a53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#samples = '^(DE).*(de)|^(FE).*(fe)|(Normal).*' #DE from de, FE from fe and Normal\n",
        "samples = '^(DE).*(de)|(Normal).*(de)' #Only acquisitions from de with failures in DE\n",
        "X,y = select_samples(samples, signal_data, np.array(signal_origin))\n",
        "print(len(set(y)),set(y))"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "64 {'DEIR.021_3de', 'DEIR.021_1de', 'DEB.007_2de', 'DEIR.021_0de', 'DEOR.021@12_0de', 'DEIR.014_2de', 'Normal_3de', 'DEIR.007_2de', 'DEOR.021@6_0de', 'Normal_1de', 'DEB.014_2de', 'DEOR.021@6_2de', 'DEOR.021@6_3de', 'DEB.028_0de', 'DEOR.021@3_3de', 'DEB.028_3de', 'DEIR.007_1de', 'Normal_0de', 'DEOR.014@6_3de', 'DEOR.014@6_1de', 'DEIR.021_2de', 'DEOR.021@3_1de', 'DEOR.021@3_2de', 'DEB.028_1de', 'DEB.021_1de', 'DEB.021_3de', 'DEOR.007@12_3de', 'DEOR.014@6_2de', 'DEOR.021@12_1de', 'DEB.021_2de', 'DEIR.014_1de', 'DEOR.014@6_0de', 'DEIR.028_1de', 'DEIR.014_3de', 'DEIR.028_2de', 'DEB.007_1de', 'DEB.028_2de', 'DEOR.007@12_2de', 'DEB.014_1de', 'Normal_2de', 'DEOR.021@12_3de', 'DEOR.007@6_2de', 'DEB.007_0de', 'DEIR.028_3de', 'DEOR.007@3_1de', 'DEOR.007@6_3de', 'DEOR.021@6_1de', 'DEOR.007@12_1de', 'DEB.014_3de', 'DEB.021_0de', 'DEOR.007@6_1de', 'DEOR.007@6_0de', 'DEOR.007@3_2de', 'DEIR.014_0de', 'DEB.007_3de', 'DEOR.021@3_0de', 'DEIR.007_3de', 'DEOR.007@3_0de', 'DEOR.021@12_2de', 'DEIR.028_0de', 'DEIR.007_0de', 'DEOR.007@12_0de', 'DEOR.007@3_3de', 'DEB.014_0de'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWYfuxcxFjt8",
        "colab_type": "text"
      },
      "source": [
        "## Customized Splitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRdfG-uzhPm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils.validation import check_array\n",
        "import numpy as np\n",
        "\n",
        "class GroupShuffleKFold(KFold):\n",
        "  '''\n",
        "  Neither GroupShuffleSplit nor GroupKFold are good splitters for this case.\n",
        "  A custom splitter must be made.\n",
        "  '''\n",
        "  def __init__(self, n_splits=4, shuffle=True, random_state=None):\n",
        "    super().__init__(n_splits, shuffle=shuffle, random_state=random_state)\n",
        "  def get_n_splits(self, X, y, groups=None):\n",
        "    return self.n_splits\n",
        "  def _iter_test_indices(self, X=None, y=None, groups=None):\n",
        "    if groups is None:\n",
        "      raise ValueError(\"The 'groups' parameter should not be None.\")\n",
        "    groups = check_array(groups, ensure_2d=False, dtype=None)\n",
        "    unique_groups, groups = np.unique(groups, return_inverse=True)\n",
        "    n_groups = len(unique_groups)\n",
        "    if self.n_splits > n_groups:\n",
        "      raise ValueError(\"Cannot have number of splits n_splits=%d greater\"\n",
        "                        \" than the number of groups: %d.\"\n",
        "                        % (self.n_splits, n_groups))\n",
        "    # Distribute groups\n",
        "    indices = np.arange(n_groups)\n",
        "    if self.shuffle:\n",
        "      for i in range(n_groups//self.n_splits):\n",
        "        if self.random_state is None:\n",
        "          indices[self.n_splits*i:self.n_splits*(i+1)] = shuffle(\n",
        "              indices[self.n_splits*i:self.n_splits*(i+1)])\n",
        "        else:\n",
        "          indices[self.n_splits*i:self.n_splits*(i+1)] = shuffle(\n",
        "              indices[self.n_splits*i:self.n_splits*(i+1)],\n",
        "              random_state=self.random_state+i)\n",
        "      #print(unique_groups[indices]) #Debug purpose\n",
        "    # Total weight of each fold\n",
        "    n_samples_per_fold = np.zeros(self.n_splits)\n",
        "    # Mapping from group index to fold index\n",
        "    group_to_fold = np.zeros(len(unique_groups))\n",
        "    # Distribute samples \n",
        "    for group_index in indices:\n",
        "      group_to_fold[indices[group_index]] = group_index%(self.n_splits)\n",
        "    indices = group_to_fold[groups]\n",
        "    for f in range(self.n_splits):\n",
        "      yield np.where(indices == f)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRQQK0Mhm1_",
        "colab_type": "text"
      },
      "source": [
        "##Experimenter definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE4TTG1-hmH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate, KFold, PredefinedSplit\n",
        "\n",
        "def experimenter(model, X, y, \n",
        "                 groups=None, \n",
        "                 scoring=None,\n",
        "                 cv=KFold(4, True), \n",
        "                 verbose=0):\n",
        "  '''\n",
        "  Performs a experiment with some estimator (model) and validation.\n",
        "  It works like a cross_validate function from sklearn, however, \n",
        "  when a estimator has an internal validation with groups, \n",
        "  it maintains the groups from the external validation.\n",
        "  '''\n",
        "  if hasattr(model,'cv') or (hasattr(model,'steps') and any(['gs' in step[0] for step in model.steps])):\n",
        "    scores = {}\n",
        "    lstval = list(validation.split(X,y,groups))\n",
        "    for tr,te in lstval:\n",
        "      if groups is not None:\n",
        "        innercv = list(GroupShuffleKFold(validation.n_splits-1).split(X[tr],y[tr],np.array(groups)[tr]))\n",
        "      else:\n",
        "        innercv = list(KFold(validation.n_splits-1, True).split(X[tr],y[tr]))\n",
        "      if hasattr(model,'cv'):\n",
        "        model.cv = innercv\n",
        "      else:\n",
        "        for step in model.steps:\n",
        "          if 'gs' in step[0]:\n",
        "            step[1].cv = innercv\n",
        "      test_fold = np.zeros((len(y),), dtype=int)\n",
        "      test_fold[tr] = -1\n",
        "      score = cross_validate(model, X, y, groups, scoring, PredefinedSplit(test_fold), verbose=verbose)\n",
        "      for k in score.keys():\n",
        "        if k not in scores:\n",
        "          scores[k] = []\n",
        "        scores[k].extend(score[k])\n",
        "    return scores\n",
        "  return cross_validate(model, X, y, groups, scoring, cv, verbose=verbose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e48W6KkIhesw",
        "colab_type": "text"
      },
      "source": [
        "##Experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dImVH3hh_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "ExperimentSetup = namedtuple('ExperimentSetup', 'groups, splitter_name')\n",
        "\n",
        "validations = {\n",
        "    # Validation usually seen in publications with CWRU bearing dataset.\n",
        "    \"Usual K-Fold\": ExperimentSetup(groups = None, splitter_name = 'KFold'), \n",
        "    # Samples from the same original Matlab file cannot be in the \n",
        "    # trainning folds and the test fold simultaneously.\n",
        "    \"By Acquisition\": ExperimentSetup(groups = join_labels('(de)|(fe)|(ba)',y), \n",
        "                                      splitter_name = 'GroupShuffleKFold'),\n",
        "    # Samples with the same severity cannot be in the trainning folds and\n",
        "    # the test folds simultaneously.\n",
        "    \"By Severity\": ExperimentSetup(groups = get_groups('(\\.\\d{3})|(Normal_\\d)',y),\n",
        "                                   splitter_name = 'GroupShuffleKFold'),\n",
        "}\n",
        "if debug:\n",
        "  validations = {\n",
        "      \"By Severity\": ExperimentSetup(groups = get_groups('(\\.\\d{3})|(Normal_\\d)',y),\n",
        "                                     splitter_name = 'GroupShuffleKFold')}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9yn44VAoRFo",
        "colab_type": "text"
      },
      "source": [
        "##Common Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpdDde4oTsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only four conditions are considered: Normal, Ball, Inner Race and Outer Race.\n",
        "selected_y = join_labels('_\\d|@\\d{1,3}|(de)|(fe)|\\.\\d{3}|(DE)|(FE)',y)\n",
        "rounds = 4 if not debug else 1\n",
        "verbose = 0\n",
        "random_state = 42\n",
        "scoring = ['accuracy', 'f1_macro']#, 'precision_macro', 'recall_macro']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq30RtWYToeu",
        "colab_type": "text"
      },
      "source": [
        "##Classification Models Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstS2gTeY7pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnyL67EUcxV",
        "colab_type": "text"
      },
      "source": [
        "###K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F--sjKZRUh5G",
        "colab_type": "code",
        "outputId": "def285ca-d979-4e52-92f1-e8fdb22638d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "knn = Pipeline([\n",
        "                ('FeatureExtraction', WaveletPackage()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('knn', KNeighborsClassifier()),\n",
        "                ])\n",
        "knn"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('FeatureExtraction',\n",
              "                 <__main__.WaveletPackage object at 0x7f923e3a0358>),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('knn',\n",
              "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
              "                                      metric='minkowski', metric_params=None,\n",
              "                                      n_jobs=None, n_neighbors=5, p=2,\n",
              "                                      weights='uniform'))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7DfMTS_ujeE",
        "colab_type": "text"
      },
      "source": [
        "###SVM with GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v_wXxiDupvF",
        "colab_type": "code",
        "outputId": "243d3878-22f8-4b39-8055-9521cc3c528a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "parameters = {'C':[10**c for c in range(5)]}\n",
        "svm = Pipeline([\n",
        "                ('FeatureExtraction', WaveletPackage()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('svc_gs', GridSearchCV(SVC(), parameters)),\n",
        "                ])\n",
        "svm"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('FeatureExtraction',\n",
              "                 <__main__.WaveletPackage object at 0x7f923e3a0a20>),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc_gs',\n",
              "                 GridSearchCV(cv=None, error_score=nan,\n",
              "                              estimator=SVC(C=1.0, break_ties=False,\n",
              "                                            cache_size=200, class_weight=None,\n",
              "                                            coef0=0.0,\n",
              "                                            decision_function_shape='ovr',\n",
              "                                            degree=3, gamma='scale',\n",
              "                                            kernel='rbf', max_iter=-1,\n",
              "                                            probability=False,\n",
              "                                            random_state=None, shrinking=True,\n",
              "                                            tol=0.001, verbose=False),\n",
              "                              iid='deprecated', n_jobs=None,\n",
              "                              param_grid={'C': [1, 10, 100, 1000, 10000]},\n",
              "                              pre_dispatch='2*n_jobs', refit=True,\n",
              "                              return_train_score=False, scoring=None,\n",
              "                              verbose=0))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU36xsi4JGZv",
        "colab_type": "text"
      },
      "source": [
        "###Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXABo6HpJJY_",
        "colab_type": "code",
        "outputId": "99a5847b-dcc1-4dac-c745-16ae8148ac5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "rf = Pipeline([\n",
        "               ('FeatureExtraction', WaveletPackage()),\n",
        "               ('scaler', StandardScaler()),\n",
        "               ('rf', RandomForestClassifier()),\n",
        "               ])\n",
        "rf"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('FeatureExtraction',\n",
              "                 <__main__.WaveletPackage object at 0x7f923e3a06a0>),\n",
              "                ('scaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('rf',\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=None, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy6ykvWSbJc",
        "colab_type": "text"
      },
      "source": [
        "###Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpHSjvNcEx5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF1hCxJ9b5h0",
        "colab_type": "text"
      },
      "source": [
        "####F1-score macro averaged implemented for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJErrQIcIZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeLXSU7-cLfk",
        "colab_type": "text"
      },
      "source": [
        "####ANN wrapped in a scikit-learn estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7otiW6Siz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "class ANN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, \n",
        "               dense_layer_sizes=[64], \n",
        "               kernel_size=32, \n",
        "               filters=32, \n",
        "               n_conv_layers=2,\n",
        "               pool_size=8,\n",
        "               dropout=0.25,\n",
        "               epochs=50,\n",
        "               validation_split=0.05,\n",
        "               optimizer='sgd'#'nadam'#'rmsprop'#\n",
        "               ):\n",
        "    self.dense_layer_sizes = dense_layer_sizes\n",
        "    self.kernel_size = kernel_size\n",
        "    self.filters = filters\n",
        "    self.n_conv_layers = n_conv_layers\n",
        "    self.pool_size = pool_size\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.validation_split = validation_split\n",
        "    self.optimizer = optimizer\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    dense_layer_sizes = self.dense_layer_sizes\n",
        "    kernel_size = self.kernel_size\n",
        "    filters = self.filters\n",
        "    n_conv_layers = self.n_conv_layers\n",
        "    pool_size = self.pool_size\n",
        "    dropout = self.dropout\n",
        "    epochs = self.epochs\n",
        "    optimizer = self.optimizer\n",
        "    validation_split = self.validation_split\n",
        "\n",
        "    self.labels, ids = np.unique(y, return_inverse=True)\n",
        "    y_cat = to_categorical(ids)\n",
        "    num_classes = y_cat.shape[1]\n",
        "    \n",
        "    self.model = Sequential()\n",
        "    self.model.add(layers.InputLayer(input_shape=(X.shape[1],X.shape[-1])))\n",
        "    for _ in range(n_conv_layers):\n",
        "      self.model.add(layers.Conv1D(filters, kernel_size))#, padding='valid'))\n",
        "      self.model.add(layers.Activation('relu'))\n",
        "      if pool_size>1:\n",
        "        self.model.add(layers.MaxPooling1D(pool_size=pool_size))\n",
        "    #self.model.add(layers.Dropout(0.25))\n",
        "    self.model.add(layers.Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        self.model.add(layers.Dense(layer_size))\n",
        "        self.model.add(layers.Activation('relu'))\n",
        "    if dropout>0 and dropout<1:\n",
        "      self.model.add(layers.Dropout(dropout))\n",
        "    self.model.add(layers.Dense(num_classes))\n",
        "    self.model.add(layers.Activation('softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer=optimizer,\n",
        "                       metrics=[f1_score_macro])\n",
        "    if validation_split>0 and validation_split<1:\n",
        "      prop = int(1/validation_split)\n",
        "      mask = np.array([i%prop==0 for i in range(len(y))])\n",
        "      self.history = self.model.fit(X[~mask], y_cat[~mask], epochs=epochs, \n",
        "                                    validation_data=(X[mask],y_cat[mask]),\n",
        "                                    callbacks=[EarlyStopping(patience=3), ReduceLROnPlateau()],\n",
        "                                    verbose=False\n",
        "                                    )  \n",
        "    else:\n",
        "      self.history = self.model.fit(X, y_cat, epochs=epochs, verbose=False)  \n",
        "  \n",
        "  def predict_proba(self, X, y=None):\n",
        "    return self.model.predict(X)\n",
        "\n",
        "  def predict(self, X, y=None):\n",
        "    predictions = self.model.predict(X)\n",
        "    return self.labels[np.argmax(predictions,axis=1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL5Zv2-xcgEG",
        "colab_type": "text"
      },
      "source": [
        "####ANN instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmQe7jeRcb6F",
        "colab_type": "code",
        "outputId": "bf06238e-5bf9-44b9-af3a-a963b4108d5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "ann = ANN()\n",
        "ann"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ANN(dense_layer_sizes=[64], dropout=0.25, epochs=50, filters=32, kernel_size=32,\n",
              "    n_conv_layers=2, optimizer='sgd', pool_size=8, validation_split=0.05)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SQenKxoSkME",
        "colab_type": "text"
      },
      "source": [
        "###List of Estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6AGKFJJqvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clfs = [\n",
        "        ('KNN - KNeighborsClassifier', knn),\n",
        "        ('SVM - SVC with GridSearchCV', svm),\n",
        "        ('RF - RandomForestClassifier', rf),\n",
        "        ('ANN - Convolutional Layers', ann),\n",
        "        ]\n",
        "if debug:\n",
        "  clfs = [('ANN - Convolutional Layers', ann)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dEl_vSYaq-s2"
      },
      "source": [
        "##Performing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4LVC3Zj3jC",
        "colab_type": "code",
        "outputId": "4e93054f-9629-4185-e15f-e890a55ac4d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "scores = {}\n",
        "trtime = {}\n",
        "tetime = {}\n",
        "# Number of repetitions\n",
        "for r in range(rounds):\n",
        "  round_str = \"Round {}\".format(r+1)\n",
        "  print(\"@\"*(len(round_str)+8),'\\n@@@',round_str,'@@@\\n'+\"@\"*(len(round_str)+8))\n",
        "  # Estimators\n",
        "  for clf_name, estimator in clfs:\n",
        "    if clf_name not in scores:\n",
        "      scores[clf_name] = {}\n",
        "      trtime[clf_name] = {}\n",
        "      tetime[clf_name] = {}\n",
        "    print(\"*\"*(len(clf_name)+8),'\\n***',clf_name,'***\\n'+\"*\"*(len(clf_name)+8))\n",
        "    # Validation forms\n",
        "    for val_name in validations.keys():\n",
        "      print(\"#\"*(len(val_name)+8),'\\n###',val_name,'###\\n'+\"#\"*(len(val_name)+8))\n",
        "      groups = validations[val_name].groups\n",
        "      if val_name not in scores[clf_name]:\n",
        "        scores[clf_name][val_name] = {}\n",
        "      validation = eval(validations[val_name].splitter_name\n",
        "                        +'(4,shuffle=True,random_state='\n",
        "                        +str(random_state+r)+')')\n",
        "      score = experimenter(estimator, X, selected_y, groups, \n",
        "                           scoring, validation, verbose)\n",
        "      for metric,s in score.items():\n",
        "        print(metric, ' \\t', s)\n",
        "        if metric not in scores[clf_name][val_name]:\n",
        "          scores[clf_name][val_name][metric] = []\n",
        "        scores[clf_name][val_name][metric].append(s)"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 1 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "********************************** \n",
            "*** KNN - KNeighborsClassifier ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [7.3245039  7.77022791 7.45543742 7.41583681]\n",
            "score_time  \t [2.92294478 2.85009789 2.95585728 3.00658798]\n",
            "test_accuracy  \t [0.98132969 0.98383424 0.98269581 0.98474152]\n",
            "test_f1_macro  \t [0.98271227 0.98476938 0.9835539  0.98528629]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [8.43344092 8.36202717 7.17392468 7.22651124]\n",
            "score_time  \t [2.93316627 2.96407676 2.92852592 2.90356755]\n",
            "test_accuracy  \t [0.96135744 0.95139814 0.97252382 0.93371758]\n",
            "test_f1_macro  \t [0.96483569 0.95292091 0.97159579 0.92957374]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [7.58721757 7.70569801 6.42010689 7.44451952]\n",
            "score_time  \t [2.27661967 2.0538609  3.97748995 3.55925274]\n",
            "test_accuracy  \t [0.44491302 0.33368607 0.59228747 0.3497038 ]\n",
            "test_f1_macro  \t [0.37886062 0.25052798 0.62872652 0.46349296]\n",
            "*********************************** \n",
            "*** SVM - SVC with GridSearchCV ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [19.994742155075073, 19.85019087791443, 20.457500219345093, 19.90899920463562]\n",
            "score_time  \t [2.5596060752868652, 2.4824955463409424, 2.6774775981903076, 2.5800788402557373]\n",
            "test_accuracy  \t [0.9842896174863388, 0.9867941712204007, 0.9877049180327869, 0.9847415167387839]\n",
            "test_f1_macro  \t [0.9854838394407729, 0.9876760467628855, 0.9883849486399726, 0.9853136020490524]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [19.594305992126465, 19.326322317123413, 18.958588123321533, 19.277965307235718]\n",
            "score_time  \t [2.4327797889709473, 2.51678466796875, 2.71537446975708, 2.6660337448120117]\n",
            "test_accuracy  \t [0.9734951696804558, 0.9829116733244563, 0.9780633724795037, 0.97251163821769]\n",
            "test_f1_macro  \t [0.976858416946694, 0.9835580577060097, 0.9776931023587536, 0.9721119164504329]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [12.453691959381104, 16.324783086776733, 11.726444959640503, 12.092777729034424]\n",
            "score_time  \t [2.2399401664733887, 1.6088571548461914, 3.6347174644470215, 3.1187779903411865]\n",
            "test_accuracy  \t [0.5071164997364259, 0.3333333333333333, 0.5177914110429448, 0.43626982610357345]\n",
            "test_f1_macro  \t [0.4353144040274436, 0.25, 0.5967175448345157, 0.49589598650693223]\n",
            "*********************************** \n",
            "*** RF - RandomForestClassifier ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [10.50702095 10.39010954 10.5258615  10.69215393]\n",
            "score_time  \t [2.36112642 2.35864496 2.3171196  2.60548401]\n",
            "test_accuracy  \t [0.98588342 0.98884335 0.98907104 0.98610795]\n",
            "test_f1_macro  \t [0.98700832 0.9896653  0.98960034 0.9868356 ]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [11.06583214 10.70239806 10.54217863 10.48058772]\n",
            "score_time  \t [2.33086109 2.6757555  2.57460976 2.50441241]\n",
            "test_accuracy  \t [0.97077037 0.9873502  0.97052958 0.93482598]\n",
            "test_f1_macro  \t [0.97489487 0.98788971 0.97031567 0.93293216]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [11.59657001 11.91939855  9.70096159  9.6287353 ]\n",
            "score_time  \t [2.06921029 1.62476182 3.09937906 2.99023056]\n",
            "test_accuracy  \t [0.43199789 0.33544974 0.62997371 0.51213453]\n",
            "test_f1_macro  \t [0.38000346 0.25315126 0.64502238 0.57749991]\n",
            "********************************** \n",
            "*** ANN - Convolutional Layers ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [24.15791512 38.80671716 57.07147145 37.02953219]\n",
            "score_time  \t [0.28071547 0.29240489 0.24401665 0.28297114]\n",
            "test_accuracy  \t [0.93351548 0.99430783 0.99681239 0.99590071]\n",
            "test_f1_macro  \t [0.94137472 0.99478775 0.99695729 0.99626914]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [18.5324192  35.4609468  21.69827628 37.27756262]\n",
            "score_time  \t [0.25750256 0.28676701 0.25203919 0.29622126]\n",
            "test_accuracy  \t [0.9799356  0.96981802 0.98736982 0.99157615]\n",
            "test_f1_macro  \t [0.98284078 0.97219341 0.98804686 0.99082701]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [44.0867362  74.66411805 25.14348674 31.85565972]\n",
            "score_time  \t [0.24089551 0.19461489 0.34162545 0.29567337]\n",
            "test_accuracy  \t [0.66631523 0.38659612 0.80736196 0.56086375]\n",
            "test_f1_macro  \t [0.58519461 0.31894977 0.84225609 0.59022724]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 2 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "********************************** \n",
            "*** KNN - KNeighborsClassifier ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [6.74547529 7.33138275 6.9889462  7.11015272]\n",
            "score_time  \t [2.7566607  2.67893839 2.88710332 2.7776835 ]\n",
            "test_accuracy  \t [0.98816029 0.97996357 0.98178506 0.98223639]\n",
            "test_f1_macro  \t [0.98891536 0.98106058 0.98281653 0.98321669]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [7.60175681 6.84476066 7.37081504 7.13797212]\n",
            "score_time  \t [2.79434514 2.95569777 2.59766102 2.75889134]\n",
            "test_accuracy  \t [0.97159343 0.93984462 0.94951745 0.9641196 ]\n",
            "test_f1_macro  \t [0.97055871 0.93494208 0.95597614 0.96388501]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [6.38719606 7.26009154 8.30787253 6.39034128]\n",
            "score_time  \t [3.86299062 2.43005657 1.70710516 3.53779507]\n",
            "test_accuracy  \t [0.4035057  0.44491302 0.33368607 0.55455762]\n",
            "test_f1_macro  \t [0.46342948 0.37886062 0.25052798 0.62811191]\n",
            "*********************************** \n",
            "*** SVM - SVC with GridSearchCV ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [19.724173069000244, 19.745147943496704, 19.873310327529907, 19.93139123916626]\n",
            "score_time  \t [2.5572855472564697, 2.4192516803741455, 2.5142109394073486, 2.5450191497802734]\n",
            "test_accuracy  \t [0.9888433515482696, 0.9847449908925319, 0.9842896174863388, 0.9886130721931223]\n",
            "test_f1_macro  \t [0.9894045941109493, 0.9857217535870164, 0.9853516908688675, 0.9893416987274131]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [18.95182466506958, 18.980645656585693, 18.83344292640686, 19.036104679107666]\n",
            "score_time  \t [2.414243459701538, 2.6076626777648926, 2.332960367202759, 2.543945074081421]\n",
            "test_accuracy  \t [0.9731469152241455, 0.9718091009988902, 0.9819351645632269, 0.9718715393133998]\n",
            "test_f1_macro  \t [0.973038296824626, 0.9716621059136256, 0.9842450077949008, 0.9727993254399118]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [11.033088445663452, 11.847302198410034, 16.41715431213379, 12.386778116226196]\n",
            "score_time  \t [3.145768404006958, 2.163776397705078, 1.8239169120788574, 3.433562994003296]\n",
            "test_accuracy  \t [0.48255915863277826, 0.5071164997364259, 0.3333333333333333, 0.4750621058666157]\n",
            "test_f1_macro  \t [0.49597490715437265, 0.4353144040274436, 0.25, 0.5966747860549317]\n",
            "*********************************** \n",
            "*** RF - RandomForestClassifier ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [10.44487453 10.59957457 10.42241383 10.69838881]\n",
            "score_time  \t [2.35236216 2.39362836 2.48229885 2.45215535]\n",
            "test_accuracy  \t [0.98861566 0.9879326  0.98770492 0.98656343]\n",
            "test_f1_macro  \t [0.98905118 0.98857401 0.9885108  0.98764181]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [10.59389687 10.46544337 10.41703629 10.5358088 ]\n",
            "score_time  \t [2.51146913 2.39405012 2.18060732 2.73209858]\n",
            "test_accuracy  \t [0.97492233 0.94605993 0.98663697 0.96256921]\n",
            "test_f1_macro  \t [0.97484002 0.94414127 0.98853825 0.96386836]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [ 9.03128004 10.79873133 11.67754769  9.37620449]\n",
            "score_time  \t [3.00855851 2.03731585 1.45516348 2.93091846]\n",
            "test_accuracy  \t [0.55740578 0.43384291 0.33368607 0.59889165]\n",
            "test_f1_macro  \t [0.5833592  0.38408874 0.25052798 0.64727801]\n",
            "********************************** \n",
            "*** ANN - Convolutional Layers ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [18.51238251 38.71945739 34.63079643 15.25693583]\n",
            "score_time  \t [0.26096463 0.27576256 0.26916194 0.24006557]\n",
            "test_accuracy  \t [0.98998179 0.99408015 0.99544627 0.98588021]\n",
            "test_f1_macro  \t [0.99040384 0.99462804 0.99576567 0.9860312 ]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [60.96851325 28.83005214 48.82531905 22.15704131]\n",
            "score_time  \t [0.24486303 0.29043531 0.25695372 0.305897  ]\n",
            "test_accuracy  \t [0.98956946 0.97602664 0.98737936 0.96943522]\n",
            "test_f1_macro  \t [0.99003041 0.97660823 0.98929215 0.97055929]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [45.4839859  47.39291573 44.47006106 42.55098677]\n",
            "score_time  \t [0.31366587 0.28757834 0.19485497 0.28546786]\n",
            "test_accuracy  \t [0.5964943  0.71402214 0.40070547 0.79629276]\n",
            "test_f1_macro  \t [0.63582133 0.638561   0.33414097 0.83572249]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 3 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "********************************** \n",
            "*** KNN - KNeighborsClassifier ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [6.78158879 7.24524999 7.16766906 6.97739434]\n",
            "score_time  \t [2.80046415 2.78269243 2.78030491 2.89765549]\n",
            "test_accuracy  \t [0.98542805 0.98201275 0.98064663 0.98747438]\n",
            "test_f1_macro  \t [0.98671034 0.98245946 0.98173025 0.98822911]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [7.31945705 6.84883904 7.04814601 7.12005329]\n",
            "score_time  \t [2.73347282 2.85485291 2.54963541 2.60869932]\n",
            "test_accuracy  \t [0.91494559 0.95856415 0.97327394 0.97050998]\n",
            "test_f1_macro  \t [0.91379771 0.96057775 0.97510474 0.96973573]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [7.95710611 6.05790138 7.73230648 6.2113421 ]\n",
            "score_time  \t [1.48542976 3.87246108 2.30525112 3.90099192]\n",
            "test_accuracy  \t [0.20160609 0.40319186 0.44491302 0.59228747]\n",
            "test_f1_macro  \t [0.25052798 0.46323317 0.37886062 0.62872652]\n",
            "*********************************** \n",
            "*** SVM - SVC with GridSearchCV ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [19.78970241546631, 20.034347772598267, 18.8914213180542, 19.659440517425537]\n",
            "score_time  \t [2.5892982482910156, 2.7418341636657715, 2.492760181427002, 2.530878782272339]\n",
            "test_accuracy  \t [0.985655737704918, 0.9854280510018215, 0.9831511839708561, 0.989296287861535]\n",
            "test_f1_macro  \t [0.9866728190171588, 0.9862340473534927, 0.9843512312779796, 0.9900168204996117]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [19.65701723098755, 17.885798692703247, 19.174787044525146, 18.710833072662354]\n",
            "score_time  \t [2.474280595779419, 2.664071559906006, 2.2238361835479736, 2.491318702697754]\n",
            "test_accuracy  \t [0.9715745058849656, 0.95989364059384, 0.9755011135857461, 0.9809312638580931]\n",
            "test_f1_macro  \t [0.9705238821018404, 0.9612368138045917, 0.9776007988451276, 0.9808835530107685]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [16.430733919143677, 10.869746685028076, 11.728529214859009, 11.905654907226562]\n",
            "score_time  \t [1.3907830715179443, 3.1103897094726562, 2.5582427978515625, 3.69344425201416]\n",
            "test_accuracy  \t [0.20118343195266272, 0.48228691687127323, 0.5071164997364259, 0.5177914110429448]\n",
            "test_f1_macro  \t [0.25, 0.49593706609267424, 0.4353144040274436, 0.5967175448345157]\n",
            "*********************************** \n",
            "*** RF - RandomForestClassifier ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [10.53787589 10.2915628  10.51413083 10.52403307]\n",
            "score_time  \t [2.34554863 2.51538396 2.38000703 2.48478985]\n",
            "test_accuracy  \t [0.98884335 0.98770492 0.98315118 0.98952403]\n",
            "test_f1_macro  \t [0.98951368 0.98830651 0.98414733 0.9902686 ]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [10.13828254 10.56666279 10.40775037 10.29485846]\n",
            "score_time  \t [2.49524665 2.41962385 2.23708034 2.41174793]\n",
            "test_accuracy  \t [0.94603598 0.95413251 0.98267756 0.96430155]\n",
            "test_f1_macro  \t [0.94438752 0.95593309 0.9850004  0.96383986]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [12.50928974  8.8536787  10.62946248  9.24698877]\n",
            "score_time  \t [1.23483443 3.08676791 2.0546658  3.11678696]\n",
            "test_accuracy  \t [0.20245139 0.53998597 0.42698998 0.6312007 ]\n",
            "test_f1_macro  \t [0.25158061 0.56366944 0.37801829 0.64596422]\n",
            "********************************** \n",
            "*** ANN - Convolutional Layers ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [28.18626499 28.47523022 12.85678458 32.59321523]\n",
            "score_time  \t [0.25498891 0.2511642  0.33200359 0.25324249]\n",
            "test_accuracy  \t [0.99248634 0.99385246 0.93715847 0.99316784]\n",
            "test_f1_macro  \t [0.9932205  0.99409611 0.93403695 0.99367418]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [27.29787254 46.76934981 26.48193836 39.39669919]\n",
            "score_time  \t [0.2738874  0.2835393  0.24724627 0.27070951]\n",
            "test_accuracy  \t [0.9862314  0.95922889 0.95421925 0.98514412]\n",
            "test_f1_macro  \t [0.98634371 0.96265069 0.96120691 0.98445983]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [37.14484739 22.21058679 34.79163575 28.47509933]\n",
            "score_time  \t [0.63821244 0.32159853 0.25547314 0.30236888]\n",
            "test_accuracy  \t [0.33431953 0.49508944 0.68502899 0.82979842]\n",
            "test_f1_macro  \t [0.37509929 0.53362145 0.60254297 0.86029085]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 4 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "********************************** \n",
            "*** KNN - KNeighborsClassifier ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [7.33682466 7.82628226 8.24803853 8.0868969 ]\n",
            "score_time  \t [3.09780622 3.13119817 3.04925036 3.29486322]\n",
            "test_accuracy  \t [0.98315118 0.98019126 0.98497268 0.98428604]\n",
            "test_f1_macro  \t [0.9842249  0.98173285 0.98593065 0.98452977]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [8.42992783 8.95111179 7.82080698 7.99395847]\n",
            "score_time  \t [3.36267686 3.11097527 3.34500456 3.29506826]\n",
            "test_accuracy  \t [0.97317668 0.96682347 0.91905079 0.95363798]\n",
            "test_f1_macro  \t [0.97240717 0.96991399 0.91785393 0.95397016]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [6.89547205 9.04102612 7.35568476 9.10485649]\n",
            "score_time  \t [4.11352658 2.37339211 4.37783432 2.04778314]\n",
            "test_accuracy  \t [0.59154683 0.36631579 0.4035057  0.33368607]\n",
            "test_f1_macro  \t [0.62843038 0.3757482  0.46342948 0.25052798]\n",
            "*********************************** \n",
            "*** SVM - SVC with GridSearchCV ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [23.347135543823242, 22.43061351776123, 22.15123987197876, 22.907995223999023]\n",
            "score_time  \t [2.816004514694214, 2.8565492630004883, 2.770206928253174, 3.04343318939209]\n",
            "test_accuracy  \t [0.9877049180327869, 0.9861111111111112, 0.9865664845173042, 0.9849692552949214]\n",
            "test_f1_macro  \t [0.9887125445867451, 0.9872882515313055, 0.987242023020228, 0.9855826041520989]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [20.628316402435303, 20.755019187927246, 22.277571201324463, 21.142418384552002]\n",
            "score_time  \t [2.8379127979278564, 2.792255401611328, 3.4283406734466553, 2.702456474304199]\n",
            "test_accuracy  \t [0.9778319663045888, 0.9796979450359, 0.9773785761809713, 0.9660603371783496]\n",
            "test_f1_macro  \t [0.9779191989920553, 0.9825195830106137, 0.9761171817465767, 0.967098736717328]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [13.05809497833252, 13.786409854888916, 12.301506042480469, 18.482519388198853]\n",
            "score_time  \t [4.19962477684021, 2.222336530685425, 3.6370270252227783, 1.8126635551452637]\n",
            "test_accuracy  \t [0.5175377060680463, 0.4378947368421053, 0.48255915863277826, 0.3333333333333333]\n",
            "test_f1_macro  \t [0.5967175448345157, 0.4342974114125963, 0.49597490715437265, 0.25]\n",
            "*********************************** \n",
            "*** RF - RandomForestClassifier ***\n",
            "***********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [12.2456286  12.25842261 11.98340058 12.06807566]\n",
            "score_time  \t [2.94996428 2.70877385 2.85489178 2.9848876 ]\n",
            "test_accuracy  \t [0.98952641 0.98611111 0.98611111 0.98929629]\n",
            "test_f1_macro  \t [0.99028957 0.98709689 0.98699236 0.98962434]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [12.61375833 12.56573796 11.90711355 11.94932938]\n",
            "score_time  \t [2.99247122 2.58260298 2.7625227  3.24548745]\n",
            "test_accuracy  \t [0.95012192 0.97301312 0.95076514 0.96983141]\n",
            "test_f1_macro  \t [0.95053768 0.97694082 0.94878309 0.97110356]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [10.4012599  12.43954158  9.98400068 13.11084819]\n",
            "score_time  \t [3.6818769  2.0685308  3.49031782 1.81863332]\n",
            "test_accuracy  \t [0.62627148 0.34345865 0.55530237 0.3340388 ]\n",
            "test_f1_macro  \t [0.64359854 0.37516027 0.5891077  0.25105485]\n",
            "********************************** \n",
            "*** ANN - Convolutional Layers ***\n",
            "**********************************\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "fit_time  \t [20.75646663 19.90564919 19.69050145 19.89894247]\n",
            "score_time  \t [0.2843616  0.28579712 0.28508973 0.28671575]\n",
            "test_accuracy  \t [0.99066485 0.98816029 0.98019126 0.9740378 ]\n",
            "test_f1_macro  \t [0.99133974 0.98931809 0.98222924 0.97482592]\n",
            "###################### \n",
            "### By Acquisition ###\n",
            "######################\n",
            "fit_time  \t [32.8947382  56.9355247  27.15734267 25.78575087]\n",
            "score_time  \t [0.29065132 0.25645137 0.2865026  0.28651834]\n",
            "test_accuracy  \t [0.98293061 0.99083932 0.98935462 0.9784827 ]\n",
            "test_f1_macro  \t [0.98399107 0.99227822 0.98875738 0.97939376]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "fit_time  \t [24.2693305  20.64741468 52.46021819 34.91594076]\n",
            "score_time  \t [0.38094687 0.2325995  0.36206555 0.21522617]\n",
            "test_accuracy  \t [0.82427219 0.60240602 0.5363716  0.37707231]\n",
            "test_f1_macro  \t [0.85629104 0.57016226 0.57061501 0.30805243]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ-qe0MIhM-z",
        "colab_type": "text"
      },
      "source": [
        "##Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrp8uvOonKpd",
        "colab_type": "code",
        "outputId": "9846470e-ddf5-4480-84ed-695d505a461f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "clf = {}\n",
        "val = {}\n",
        "src = {}\n",
        "for c, clf_name in enumerate(scores.keys()):\n",
        "  if c not in clf:\n",
        "    clf[c] = clf_name\n",
        "  for v, val_name in enumerate(scores[clf_name].keys()):\n",
        "    if v not in val:\n",
        "      val[v] = val_name\n",
        "    for s, scr_name in enumerate(scores[clf_name][val_name].keys()):\n",
        "      scores[clf_name][val_name][scr_name] = np.array(scores[clf_name][val_name][scr_name])\n",
        "      if s not in src:\n",
        "        src[s] = scr_name\n",
        "      np.savetxt('{}-{}-{}.txt'.format(clf_name,val_name,scr_name), \n",
        "                 scores[clf_name][val_name][scr_name], delimiter=',')\n",
        "clf, val, src"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({0: 'KNN - KNeighborsClassifier',\n",
              "  1: 'SVM - SVC with GridSearchCV',\n",
              "  2: 'RF - RandomForestClassifier',\n",
              "  3: 'ANN - Convolutional Layers'},\n",
              " {0: 'Usual K-Fold', 1: 'By Acquisition', 2: 'By Severity'},\n",
              " {0: 'fit_time', 1: 'score_time', 2: 'test_accuracy', 3: 'test_f1_macro'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkb8XMN-Ht58",
        "colab_type": "text"
      },
      "source": [
        "##Average & Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxdjboqtuNb",
        "colab_type": "code",
        "outputId": "def599b3-d563-45ce-fba6-652d417aac23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "c,v,s = len(clf),len(val),len(src)\n",
        "for i in range(s):\n",
        "  print(src[i])\n",
        "  for k in range(v):\n",
        "    print('\\t'+val[k]+' ', end='')\n",
        "  print()\n",
        "  for j in range(c):\n",
        "    print(clf[j].split('-')[0], end='\\t')\n",
        "    for k in range(v):\n",
        "      print(\"{0:.3f} ({1:.3f})\".format(\n",
        "          scores[clf[j]][val[k]][src[i]].mean(),\n",
        "          scores[clf[j]][val[k]][src[i]].std()), end='\\t')\n",
        "    print()\n",
        "  print()"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit_time\n",
            "\tUsual K-Fold \tBy Acquisition \tBy Severity \n",
            "KNN \t7.363 (0.420)\t7.605 (0.629)\t7.366 (0.917)\t\n",
            "SVM \t20.544 (1.305)\t19.574 (1.065)\t13.303 (2.234)\t\n",
            "RF \t10.919 (0.713)\t10.953 (0.795)\t10.682 (1.327)\t\n",
            "ANN \t27.909 (11.104)\t34.779 (12.357)\t38.160 (13.346)\t\n",
            "\n",
            "score_time\n",
            "\tUsual K-Fold \tBy Acquisition \tBy Severity \n",
            "KNN \t2.917 (0.159)\t2.919 (0.247)\t2.993 (0.952)\t\n",
            "SVM \t2.636 (0.162)\t2.615 (0.265)\t2.737 (0.839)\t\n",
            "RF \t2.534 (0.216)\t2.566 (0.265)\t2.485 (0.744)\t\n",
            "ANN \t0.274 (0.022)\t0.274 (0.019)\t0.304 (0.102)\t\n",
            "\n",
            "test_accuracy\n",
            "\tUsual K-Fold \tBy Acquisition \tBy Severity \n",
            "KNN \t0.983 (0.002)\t0.955 (0.018)\t0.425 (0.108)\t\n",
            "SVM \t0.986 (0.002)\t0.975 (0.006)\t0.442 (0.090)\t\n",
            "RF \t0.988 (0.002)\t0.964 (0.015)\t0.468 (0.128)\t\n",
            "ANN \t0.983 (0.019)\t0.980 (0.011)\t0.601 (0.164)\t\n",
            "\n",
            "test_f1_macro\n",
            "\tUsual K-Fold \tBy Acquisition \tBy Severity \n",
            "KNN \t0.984 (0.002)\t0.955 (0.019)\t0.430 (0.137)\t\n",
            "SVM \t0.987 (0.002)\t0.975 (0.006)\t0.444 (0.126)\t\n",
            "RF \t0.988 (0.002)\t0.965 (0.016)\t0.464 (0.157)\t\n",
            "ANN \t0.984 (0.019)\t0.981 (0.010)\t0.591 (0.184)\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKh0QQncJpzF",
        "colab_type": "text"
      },
      "source": [
        "##Average of diferences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Pejb-yt_7aW",
        "colab_type": "code",
        "outputId": "9f59da4c-8620-426a-eb02-e6f7f918bfb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "c,v,s = len(clf),len(val),len(src)\n",
        "compclf = np.zeros((s,v,c,c))\n",
        "for i in range(s):\n",
        "  print('*'*3, src[i], '*'*3)\n",
        "  for j in range(v):\n",
        "    print(val[j])\n",
        "    for k in range(c):\n",
        "      print('       '+clf[k].split('-')[0],end=' ')\n",
        "    print()\n",
        "    for k in range(c):\n",
        "      for l in range(k):\n",
        "        diff = scores[clf[k]][val[j]][src[i]]-scores[clf[l]][val[j]][src[i]]\n",
        "        compclf[i][j][l][k] = diff.mean()\n",
        "        compclf[i][j][k][l] = diff.std()\n",
        "    print(compclf[i][j])"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*** fit_time ***\n",
            "Usual K-Fold\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.         13.18034023  3.55572626 20.54602221]\n",
            " [ 1.0788785   0.         -9.62461397  7.36568198]\n",
            " [ 0.53641173  0.66331547  0.         16.99029595]\n",
            " [11.12176592 11.50298509 11.41326661  0.        ]]\n",
            "By Acquisition\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.         11.96921574  3.34769788 27.17411487]\n",
            " [ 0.83696112  0.         -8.62151785 15.20489913]\n",
            " [ 0.49760762  0.64829297  0.         23.82641698]\n",
            " [12.28457824 12.6105018  12.31768712  0.        ]]\n",
            "By Severity\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.          5.93665481  3.31536001 30.79401779]\n",
            " [ 1.66633661  0.         -2.6212948  24.85736299]\n",
            " [ 0.62381463  1.31881945  0.         27.47865778]\n",
            " [13.28103369 12.88261266 13.14789378  0.        ]]\n",
            "*** score_time ***\n",
            "Usual K-Fold\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.         -0.28085738 -0.38269013 -2.64316766]\n",
            " [ 0.0881125   0.         -0.10183275 -2.36231028]\n",
            " [ 0.12266843  0.12437923  0.         -2.26047753]\n",
            " [ 0.15559155  0.16260064  0.21143513  0.        ]]\n",
            "By Acquisition\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.         -0.30325378 -0.35285439 -2.64438325]\n",
            " [ 0.16228367  0.         -0.0496006  -2.34112947]\n",
            " [ 0.16754303  0.25355818  0.         -2.29152887]\n",
            " [ 0.24034233  0.25769257  0.25571127  0.        ]]\n",
            "By Severity\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.         -0.25550072 -0.50711805 -2.68868583]\n",
            " [ 0.29657587  0.         -0.25161733 -2.43318512]\n",
            " [ 0.25009033  0.20421526  0.         -2.18156779]\n",
            " [ 0.94661453  0.83494238  0.74165047  0.        ]]\n",
            "*** test_accuracy ***\n",
            "Usual K-Fold\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.          0.00287467  0.00425508  0.00017091]\n",
            " [ 0.00194861  0.          0.00138041 -0.00270376]\n",
            " [ 0.0021324   0.0016528   0.         -0.00408417]\n",
            " [ 0.01851219  0.01831394  0.01805251  0.        ]]\n",
            "By Acquisition\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.          0.02003495  0.00940557  0.02521791]\n",
            " [ 0.01846429  0.         -0.01062938  0.00518295]\n",
            " [ 0.01649239  0.01373783  0.          0.01581234]\n",
            " [ 0.02379938  0.01027753  0.02076568  0.        ]]\n",
            "By Severity\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[0.         0.01737374 0.0436735  0.17616904]\n",
            " [0.06176932 0.         0.02629977 0.1587953 ]\n",
            " [0.06545448 0.07410789 0.         0.13249554]\n",
            " [0.07426634 0.10014654 0.10242866 0.        ]]\n",
            "*** test_f1_macro ***\n",
            "Usual K-Fold\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.00000000e+00  2.80626148e-03  4.07801969e-03  6.75036343e-05]\n",
            " [ 1.89606647e-03  0.00000000e+00  1.27175821e-03 -2.73875784e-03]\n",
            " [ 2.06854552e-03  1.51490424e-03  0.00000000e+00 -4.01051605e-03]\n",
            " [ 1.79745829e-02  1.78024950e-02  1.75102946e-02  0.00000000e+00]]\n",
            "By Acquisition\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[ 0.          0.02051354  0.00976857  0.0263644 ]\n",
            " [ 0.01859959  0.         -0.01074498  0.00585086]\n",
            " [ 0.01549432  0.01419552  0.          0.01659584]\n",
            " [ 0.02352099  0.00933817  0.02048926  0.        ]]\n",
            "By Severity\n",
            "       KNN         SVM         RF         ANN  \n",
            "[[0.         0.01430178 0.0335664  0.1609704 ]\n",
            " [0.03353973 0.         0.01926462 0.14666862]\n",
            " [0.04771923 0.05220928 0.         0.127404  ]\n",
            " [0.0662515  0.07356697 0.09191026 0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}