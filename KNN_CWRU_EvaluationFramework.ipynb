{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN CWRU-EvaluationFramework.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/SignalProcessing/blob/master/KNN_CWRU_EvaluationFramework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llMoY5AQGXQY",
        "colab_type": "text"
      },
      "source": [
        "The code is separated into four sections.\n",
        "\n",
        "* In section \"CWRU dataset\" the CWRU Matlab files are downloaded, the acquisitions are extracted from the Matlab files into Numpy arrays. Then, the data is segmented and the samples are selected. The samples are selected by their labels using regular expressions. \n",
        "\n",
        "* Section \"Experimenter\" defines the splitters mentioned in this work, i.e. GroupShuffleKFold and BySeverityKFold, and the setup of each experiment. The samples are grouped by their original labels also using regular expressions. For instance, to group samples by load, the regular expression '_\\d' may be used. A list of evaluation methods is defined in this section. \n",
        "\n",
        "* Section \"Classification Models\" defines the estimators and their feature extraction methods. To instantiate a classification method with feature extraction, a Pipeline must be made. A list of classification methods is defined in this section. \n",
        "\n",
        "* Finally, section \"Performing Experiments\" executes the experiments as they were defined in the previous sections, showing and saving  their results. It iterates one list of classification methods and one list of evaluation methods in $r$ rounds. In this work, four classification methods were tested by three evaluation methods in four rounds, resulting in $4\\times 3\\times 4 = 48$  experiments. New classification or evaluation methods can be tested by adding them in their respective list.\n",
        "\n",
        "The code can be executed direct in the Colab environment when few samples and simple classifier methods are tested. For the experiments presented in this work, it must be run in a local GPU, with enough memory and processing capacity.\n",
        "The results are presented for each round of each experiment of each classification method. The average and standard deviation of the rounds is also presented, as well, the average of the differences among the classification methods.\n",
        "\n",
        "New feature extraction methods must receive a 3-D Numpy array and returns a 2-D Numpy array. This is necessary because the same raw dataset is used for methods that need feature extraction of the signal acquisitions, like K-NN, SVM and Random Forest, and convolutional neural networks that deal with 3-D arrays. The experiments presented here used just one channel of each acquisition, but newer experiments may use more channels.\n",
        "\n",
        "New classifications methods that need feature extraction may be easily added. It is only required a Pipeline with the feature extraction method and the classifier, like those presented in the code. A new neural network base architecture must be wrapped in a scikit-learn estimator, and its definition must be in the method *fit*. It cannot be defined in the method *\\_\\_init\\_\\_* due to the implementation of the Keras library. If the network architecture is defined in the method *\\_\\_init\\_\\_*, it will remember the samples across the folds and the rounds, giving outstanding results, that will be never replicated in a real scenario. It is worth to highlight that some parameters of the network, like kernel size and number of filters, should be selected by a GridSearchCV method to provide fairer results when compared with other methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sm5t8TYBqkDu",
        "colab_type": "text"
      },
      "source": [
        "#CWRU database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSSOMru17Z6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug = False"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMQoq6dvStey",
        "colab_type": "text"
      },
      "source": [
        "## CWRU files.\n",
        "\n",
        "Associate each Matlab file name to a bearing condition in a Python dictionary.\n",
        "The dictionary keys identify the conditions.\n",
        "\n",
        "There are only four normal conditions, with loads of 0, 1, 2 and 3 hp.\n",
        "All conditions end with an underscore character followed by an algarism representing the load applied during the acquisitions.\n",
        "The remaining conditions follow the pattern:\n",
        "\n",
        "\n",
        "* First two characters represent the bearing location, i.e. drive end (DE) and fan end (FE).\n",
        "* The following two characters represent the failure location in the bearing, i.e. ball (BA), Inner Race (IR) and Outer Race (OR).\n",
        "* The next three algarisms indicate the severity of the failure, where 007 stands for 0.007 inches and 0021 for 0.021 inches.\n",
        "* For Outer Race failures, the character @ is followed by a number that indicates different load zones. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6mp2QrP1lmR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cwru_12khz():\n",
        "  '''\n",
        "  Retuns a dictionary with the names of all Matlab files read in 12kHz located in\n",
        "  http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/.\n",
        "  The dictionary keys represent the bearing condition.\n",
        "  '''\n",
        "  matlab_files_name = {}\n",
        "  # Normal\n",
        "  matlab_files_name[\"Normal_0\"] = \"97.mat\"\n",
        "  matlab_files_name[\"Normal_1\"] = \"98.mat\"\n",
        "  matlab_files_name[\"Normal_2\"] = \"99.mat\"\n",
        "  matlab_files_name[\"Normal_3\"] = \"100.mat\"\n",
        "  # DE Inner Race 0.007 inches\n",
        "  matlab_files_name[\"DEIR.007_0\"] = \"105.mat\"\n",
        "  matlab_files_name[\"DEIR.007_1\"] = \"106.mat\"\n",
        "  matlab_files_name[\"DEIR.007_2\"] = \"107.mat\"\n",
        "  matlab_files_name[\"DEIR.007_3\"] = \"108.mat\"\n",
        "  # DE Ball 0.007 inches\n",
        "  matlab_files_name[\"DEB.007_0\"] = \"118.mat\"\n",
        "  matlab_files_name[\"DEB.007_1\"] = \"119.mat\"\n",
        "  matlab_files_name[\"DEB.007_2\"] = \"120.mat\"\n",
        "  matlab_files_name[\"DEB.007_3\"] = \"121.mat\"\n",
        "  # DE Outer race 0.007 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.007@6_0\"] = \"130.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_1\"] = \"131.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_2\"] = \"132.mat\"\n",
        "  matlab_files_name[\"DEOR.007@6_3\"] = \"133.mat\"\n",
        "  # DE Outer race 0.007 inches centered @3:00\n",
        "  matlab_files_name[\"DEOR.007@3_0\"] = \"144.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_1\"] = \"145.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_2\"] = \"146.mat\"\n",
        "  matlab_files_name[\"DEOR.007@3_3\"] = \"147.mat\"\n",
        "  # DE Outer race 0.007 inches centered @12:00\n",
        "  matlab_files_name[\"DEOR.007@12_0\"] = \"156.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_1\"] = \"158.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_2\"] = \"159.mat\"\n",
        "  matlab_files_name[\"DEOR.007@12_3\"] = \"160.mat\"\n",
        "  # DE Inner Race 0.014 inches\n",
        "  matlab_files_name[\"DEIR.014_0\"] = \"169.mat\"\n",
        "  matlab_files_name[\"DEIR.014_1\"] = \"170.mat\"\n",
        "  matlab_files_name[\"DEIR.014_2\"] = \"171.mat\"\n",
        "  matlab_files_name[\"DEIR.014_3\"] = \"172.mat\"\n",
        "  # DE Ball 0.014 inches\n",
        "  matlab_files_name[\"DEB.014_0\"] = \"185.mat\"\n",
        "  matlab_files_name[\"DEB.014_1\"] = \"186.mat\"\n",
        "  matlab_files_name[\"DEB.014_2\"] = \"187.mat\"\n",
        "  matlab_files_name[\"DEB.014_3\"] = \"188.mat\"\n",
        "  # DE Outer race 0.014 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.014@6_0\"] = \"197.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_1\"] = \"198.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_2\"] = \"199.mat\"\n",
        "  matlab_files_name[\"DEOR.014@6_3\"] = \"200.mat\"\n",
        "  # DE Ball 0.021 inches\n",
        "  matlab_files_name[\"DEB.021_0\"] = \"222.mat\"\n",
        "  matlab_files_name[\"DEB.021_1\"] = \"223.mat\"\n",
        "  matlab_files_name[\"DEB.021_2\"] = \"224.mat\"\n",
        "  matlab_files_name[\"DEB.021_3\"] = \"225.mat\"\n",
        "  # FE Inner Race 0.021 inches\n",
        "  matlab_files_name[\"FEIR.021_0\"] = \"270.mat\"\n",
        "  matlab_files_name[\"FEIR.021_1\"] = \"271.mat\"\n",
        "  matlab_files_name[\"FEIR.021_2\"] = \"272.mat\"\n",
        "  matlab_files_name[\"FEIR.021_3\"] = \"273.mat\"\n",
        "  # FE Inner Race 0.014 inches\n",
        "  matlab_files_name[\"FEIR.014_0\"] = \"274.mat\"\n",
        "  matlab_files_name[\"FEIR.014_1\"] = \"275.mat\"\n",
        "  matlab_files_name[\"FEIR.014_2\"] = \"276.mat\"\n",
        "  matlab_files_name[\"FEIR.014_3\"] = \"277.mat\"\n",
        "  # FE Ball 0.007 inches\n",
        "  matlab_files_name[\"FEB.007_0\"] = \"282.mat\"\n",
        "  matlab_files_name[\"FEB.007_1\"] = \"283.mat\"\n",
        "  matlab_files_name[\"FEB.007_2\"] = \"284.mat\"\n",
        "  matlab_files_name[\"FEB.007_3\"] = \"285.mat\"\n",
        "  # DE Inner Race 0.021 inches\n",
        "  matlab_files_name[\"DEIR.021_0\"] = \"209.mat\"\n",
        "  matlab_files_name[\"DEIR.021_1\"] = \"210.mat\"\n",
        "  matlab_files_name[\"DEIR.021_2\"] = \"211.mat\"\n",
        "  matlab_files_name[\"DEIR.021_3\"] = \"212.mat\"\n",
        "  # DE Outer race 0.021 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.021@6_0\"] = \"234.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_1\"] = \"235.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_2\"] = \"236.mat\"\n",
        "  matlab_files_name[\"DEOR.021@6_3\"] = \"237.mat\"\n",
        "  # DE Outer race 0.021 inches centered @3:00\n",
        "  matlab_files_name[\"DEOR.021@3_0\"] = \"246.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_1\"] = \"247.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_2\"] = \"248.mat\"\n",
        "  matlab_files_name[\"DEOR.021@3_3\"] = \"249.mat\"\n",
        "  # DE Outer race 0.021 inches centered @12:00\n",
        "  matlab_files_name[\"DEOR.021@12_0\"] = \"258.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_1\"] = \"259.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_2\"] = \"260.mat\"\n",
        "  matlab_files_name[\"DEOR.021@12_3\"] = \"261.mat\"\n",
        "  # FE Inner Race 0.007 inches\n",
        "  matlab_files_name[\"FEIR.007_0\"] = \"278.mat\"\n",
        "  matlab_files_name[\"FEIR.007_1\"] = \"279.mat\"\n",
        "  matlab_files_name[\"FEIR.007_2\"] = \"280.mat\"\n",
        "  matlab_files_name[\"FEIR.007_3\"] = \"281.mat\"\n",
        "  # FE Ball 0.014 inches\n",
        "  matlab_files_name[\"FEB.014_0\"] = \"286.mat\"\n",
        "  matlab_files_name[\"FEB.014_1\"] = \"287.mat\"\n",
        "  matlab_files_name[\"FEB.014_2\"] = \"288.mat\"\n",
        "  matlab_files_name[\"FEB.014_3\"] = \"289.mat\"\n",
        "  # FE Ball 0.021 inches\n",
        "  matlab_files_name[\"FEB.021_0\"] = \"290.mat\"\n",
        "  matlab_files_name[\"FEB.021_1\"] = \"291.mat\"\n",
        "  matlab_files_name[\"FEB.021_2\"] = \"292.mat\"\n",
        "  matlab_files_name[\"FEB.021_3\"] = \"293.mat\"\n",
        "  # FE Outer race 0.007 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.007@6_0\"] = \"294.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_1\"] = \"295.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_2\"] = \"296.mat\"\n",
        "  matlab_files_name[\"FEOR.007@6_3\"] = \"297.mat\"\n",
        "  # FE Outer race 0.007 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.007@3_0\"] = \"298.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_1\"] = \"299.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_2\"] = \"300.mat\"\n",
        "  matlab_files_name[\"FEOR.007@3_3\"] = \"301.mat\"\n",
        "  # FE Outer race 0.007 inches centered @12:00\n",
        "  matlab_files_name[\"FEOR.007@12_0\"] = \"302.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_1\"] = \"305.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_2\"] = \"306.mat\"\n",
        "  matlab_files_name[\"FEOR.007@12_3\"] = \"307.mat\"\n",
        "  # FE Outer race 0.014 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.014@3_0\"] = \"310.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_1\"] = \"309.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_2\"] = \"311.mat\"\n",
        "  matlab_files_name[\"FEOR.014@3_3\"] = \"312.mat\"\n",
        "  # FE Outer race 0.014 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.014@6_0\"] = \"313.mat\"\n",
        "  # FE Outer race 0.021 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.021@6_0\"] = \"315.mat\"\n",
        "  # FE Outer race 0.021 inches centered @3:00\n",
        "  matlab_files_name[\"FEOR.021@3_1\"] = \"316.mat\"\n",
        "  matlab_files_name[\"FEOR.021@3_2\"] = \"317.mat\"\n",
        "  matlab_files_name[\"FEOR.021@3_3\"] = \"318.mat\"\n",
        "  # DE Inner Race 0.028 inches\n",
        "  matlab_files_name[\"DEIR.028_0\"] = \"3001.mat\"\n",
        "  matlab_files_name[\"DEIR.028_1\"] = \"3002.mat\"\n",
        "  matlab_files_name[\"DEIR.028_2\"] = \"3003.mat\"\n",
        "  matlab_files_name[\"DEIR.028_3\"] = \"3004.mat\"\n",
        "  # DE Ball 0.028 inches\n",
        "  matlab_files_name[\"DEB.028_0\"] = \"3005.mat\"\n",
        "  matlab_files_name[\"DEB.028_1\"] = \"3006.mat\"\n",
        "  matlab_files_name[\"DEB.028_2\"] = \"3007.mat\"\n",
        "  matlab_files_name[\"DEB.028_3\"] = \"3008.mat\"\n",
        "  return matlab_files_name\n",
        "\n",
        "def files_debug():\n",
        "  \"\"\"\n",
        "  Associate each Matlab file name to a bearing condition in a Python dictionary. \n",
        "  The dictionary keys identify the conditions.\n",
        "  \n",
        "  NOTE: Used only for debug.\n",
        "  \"\"\"\n",
        "  matlab_files_name = {}\n",
        "  # Normal\n",
        "  matlab_files_name[\"Normal_0\"] = \"97.mat\"\n",
        "  matlab_files_name[\"Normal_1\"] = \"98.mat\"\n",
        "  matlab_files_name[\"Normal_2\"] = \"99.mat\"\n",
        "  matlab_files_name[\"Normal_3\"] = \"100.mat\"\n",
        "  # FE Inner Race 0.007 inches\n",
        "  matlab_files_name[\"FEIR.007_2\"] = \"280.mat\"\n",
        "  # DE Outer race 0.014 inches centered @6:00\n",
        "  matlab_files_name[\"DEOR.014@6_1\"] = \"198.mat\"\n",
        "  # FE Outer race 0.021 inches centered @6:00\n",
        "  matlab_files_name[\"FEOR.021@6_0\"] = \"315.mat\"\n",
        "  # DE Ball 0.028 inches\n",
        "  matlab_files_name[\"DEB.028_3\"] = \"3008.mat\"\n",
        "  return matlab_files_name"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9y9byVeSz_u",
        "colab_type": "text"
      },
      "source": [
        "##Download Matlab files\n",
        "Downloads the Matlab files in the dictionary matlab_files_name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPSGH1401-W2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "import os.path\n",
        "\n",
        "def download_cwrufiles(matlab_files_name):\n",
        "  '''\n",
        "  Downloads the Matlab files in the dictionary matlab_files_name.\n",
        "  '''\n",
        "  url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "  n = len(matlab_files_name)\n",
        "  for i,key in enumerate(matlab_files_name):\n",
        "    file_name = matlab_files_name[key]\n",
        "    if not os.path.exists(file_name):\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "    print(\"{}/{}\\t{}\\t{}\".format(i+1, n, key, file_name))\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRijKbOjS-JZ",
        "colab_type": "text"
      },
      "source": [
        "##Extract data from Matlab files\n",
        "Extracts the acquisitions of each Matlab file in the dictionary matlab_files_name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbpFkSI12CUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "def get_tensors_from_matlab(matlab_files_name):\n",
        "  '''\n",
        "  Extracts the acquisitions of each Matlab file in the dictionary matlab_files_name.\n",
        "  '''\n",
        "  acquisitions = {}\n",
        "  for key in matlab_files_name:\n",
        "    file_name = matlab_files_name[key]\n",
        "    matlab_file = scipy.io.loadmat(file_name)\n",
        "    for position in ['DE','FE', 'BA']:\n",
        "      keys = [key for key in matlab_file if key.endswith(position+\"_time\")]\n",
        "      if len(keys)>0:\n",
        "        array_key = keys[0]\n",
        "        acquisitions[key+position.lower()] = matlab_file[array_key].reshape(1,-1)[0]\n",
        "  return acquisitions\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-2lcukz5Nyk",
        "colab_type": "text"
      },
      "source": [
        "##Downloading pickle file\n",
        "Following, some auxiliary functions to download a pickle file in a google drive account.\n",
        "The pickle file already has the acquisitions propertly extracted.\n",
        "Therefore, these functions might speed up the whole process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJkpaFxn1xtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import os.path\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "    session = requests.Session()\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "# https://drive.google.com/file/d/1qJezMiROz9NAYafPUDPh9BFkxYF4nOi2/view?usp=sharing\n",
        "file_id = \"1qJezMiROz9NAYafPUDPh9BFkxYF4nOi2\"\n",
        "if not debug:\n",
        "  pickle_file = 'cwru.pickle'\n",
        "else:\n",
        "  pickle_file = 'debug.pickle'\n",
        "\n",
        "if not os.path.isfile(pickle_file) and not debug:\n",
        "  try:\n",
        "    download_file_from_google_drive(file_id, destination)\n",
        "  except:\n",
        "    print(\"Download failed!\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEzRboCpgtlx",
        "colab_type": "text"
      },
      "source": [
        "##Save/Load data\n",
        "If the cwru pickle file is already download, it will not be downloaded again, and the dictionary with the acquisitions will be loaded.\n",
        "Otherwise, the desired files are downloaded and the acquisitions are extrated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1m5Q3OUbvqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "\n",
        "if not debug:\n",
        "  matlab_files_name = cwru_12khz()\n",
        "else:\n",
        "  matlab_files_name = files_debug()\n",
        "\n",
        "if os.path.isfile(pickle_file) and  not debug:\n",
        "  with open(pickle_file, 'rb') as handle:\n",
        "    acquisitions = pickle.load(handle)\n",
        "else:\n",
        "  download_cwrufiles(matlab_files_name)\n",
        "  acquisitions = get_tensors_from_matlab(matlab_files_name)\n",
        "  with open(pickle_file, 'wb') as handle:\n",
        "    pickle.dump(acquisitions, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT7hgDnzTcNP",
        "colab_type": "text"
      },
      "source": [
        "##Segment data\n",
        "Segments the acquisitions.\n",
        "  sample_size is the size of each segment.\n",
        "  max_samples is used for debug purpouses and \n",
        "  reduces the number of samples from each acquisition.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BKfioJFzAKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdceb46e-f635-414e-81e9-3d2f108d41fd"
      },
      "source": [
        "import numpy as np\n",
        "def cwru_segmentation(acquisitions, sample_size=512, max_samples=None):\n",
        "  '''\n",
        "  Segments the acquisitions.\n",
        "  sample_size is the size of each segment.\n",
        "  max_samples is used for debug purpouses and \n",
        "  reduces the number of samples from each acquisition.\n",
        "  '''\n",
        "  origin = []\n",
        "  data = np.empty((0,sample_size,1))\n",
        "  n = len(acquisitions)\n",
        "  for i,key in enumerate(acquisitions):\n",
        "    acquisition_size = len(acquisitions[key])\n",
        "    n_samples = acquisition_size//sample_size\n",
        "    if max_samples is not None and max_samples > 0 and n_samples > max_samples:\n",
        "      n_samples = max_samples\n",
        "    print('{}/{} --- {}: {}'.format(i+1, n, key, n_samples))\n",
        "    origin.extend([key for _ in range(n_samples)])\n",
        "    data = np.concatenate((data,\n",
        "           acquisitions[key][:(n_samples*sample_size)].reshape(\n",
        "               (n_samples,sample_size,1))))\n",
        "  return data,origin\n",
        "\n",
        "if not debug:\n",
        "  signal_data,signal_origin = cwru_segmentation(acquisitions, 512)\n",
        "else:\n",
        "  signal_data,signal_origin = cwru_segmentation(acquisitions, 512, 15)\n",
        "signal_data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/307 --- Normal_0de: 476\n",
            "2/307 --- Normal_0fe: 476\n",
            "3/307 --- Normal_1de: 945\n",
            "4/307 --- Normal_1fe: 945\n",
            "5/307 --- Normal_2de: 945\n",
            "6/307 --- Normal_2fe: 945\n",
            "7/307 --- Normal_3de: 948\n",
            "8/307 --- Normal_3fe: 948\n",
            "9/307 --- DEIR.007_0de: 236\n",
            "10/307 --- DEIR.007_0fe: 236\n",
            "11/307 --- DEIR.007_0ba: 236\n",
            "12/307 --- DEIR.007_1de: 238\n",
            "13/307 --- DEIR.007_1fe: 238\n",
            "14/307 --- DEIR.007_1ba: 238\n",
            "15/307 --- DEIR.007_2de: 238\n",
            "16/307 --- DEIR.007_2fe: 238\n",
            "17/307 --- DEIR.007_2ba: 238\n",
            "18/307 --- DEIR.007_3de: 240\n",
            "19/307 --- DEIR.007_3fe: 240\n",
            "20/307 --- DEIR.007_3ba: 240\n",
            "21/307 --- DEB.007_0de: 239\n",
            "22/307 --- DEB.007_0fe: 239\n",
            "23/307 --- DEB.007_0ba: 239\n",
            "24/307 --- DEB.007_1de: 237\n",
            "25/307 --- DEB.007_1fe: 237\n",
            "26/307 --- DEB.007_1ba: 237\n",
            "27/307 --- DEB.007_2de: 237\n",
            "28/307 --- DEB.007_2fe: 237\n",
            "29/307 --- DEB.007_2ba: 237\n",
            "30/307 --- DEB.007_3de: 237\n",
            "31/307 --- DEB.007_3fe: 237\n",
            "32/307 --- DEB.007_3ba: 237\n",
            "33/307 --- DEOR.007@6_0de: 238\n",
            "34/307 --- DEOR.007@6_0fe: 238\n",
            "35/307 --- DEOR.007@6_0ba: 238\n",
            "36/307 --- DEOR.007@6_1de: 239\n",
            "37/307 --- DEOR.007@6_1fe: 239\n",
            "38/307 --- DEOR.007@6_1ba: 239\n",
            "39/307 --- DEOR.007@6_2de: 237\n",
            "40/307 --- DEOR.007@6_2fe: 237\n",
            "41/307 --- DEOR.007@6_2ba: 237\n",
            "42/307 --- DEOR.007@6_3de: 239\n",
            "43/307 --- DEOR.007@6_3fe: 239\n",
            "44/307 --- DEOR.007@6_3ba: 239\n",
            "45/307 --- DEOR.007@3_0de: 238\n",
            "46/307 --- DEOR.007@3_0fe: 238\n",
            "47/307 --- DEOR.007@3_0ba: 238\n",
            "48/307 --- DEOR.007@3_1de: 237\n",
            "49/307 --- DEOR.007@3_1fe: 237\n",
            "50/307 --- DEOR.007@3_1ba: 237\n",
            "51/307 --- DEOR.007@3_2de: 237\n",
            "52/307 --- DEOR.007@3_2fe: 237\n",
            "53/307 --- DEOR.007@3_2ba: 237\n",
            "54/307 --- DEOR.007@3_3de: 238\n",
            "55/307 --- DEOR.007@3_3fe: 238\n",
            "56/307 --- DEOR.007@3_3ba: 238\n",
            "57/307 --- DEOR.007@12_0de: 238\n",
            "58/307 --- DEOR.007@12_0fe: 238\n",
            "59/307 --- DEOR.007@12_0ba: 238\n",
            "60/307 --- DEOR.007@12_1de: 238\n",
            "61/307 --- DEOR.007@12_1fe: 238\n",
            "62/307 --- DEOR.007@12_1ba: 238\n",
            "63/307 --- DEOR.007@12_2de: 238\n",
            "64/307 --- DEOR.007@12_2fe: 238\n",
            "65/307 --- DEOR.007@12_2ba: 238\n",
            "66/307 --- DEOR.007@12_3de: 238\n",
            "67/307 --- DEOR.007@12_3fe: 238\n",
            "68/307 --- DEOR.007@12_3ba: 238\n",
            "69/307 --- DEIR.014_0de: 237\n",
            "70/307 --- DEIR.014_0fe: 237\n",
            "71/307 --- DEIR.014_0ba: 237\n",
            "72/307 --- DEIR.014_1de: 237\n",
            "73/307 --- DEIR.014_1fe: 237\n",
            "74/307 --- DEIR.014_1ba: 237\n",
            "75/307 --- DEIR.014_2de: 237\n",
            "76/307 --- DEIR.014_2fe: 237\n",
            "77/307 --- DEIR.014_2ba: 237\n",
            "78/307 --- DEIR.014_3de: 237\n",
            "79/307 --- DEIR.014_3fe: 237\n",
            "80/307 --- DEIR.014_3ba: 237\n",
            "81/307 --- DEB.014_0de: 237\n",
            "82/307 --- DEB.014_0fe: 237\n",
            "83/307 --- DEB.014_0ba: 237\n",
            "84/307 --- DEB.014_1de: 238\n",
            "85/307 --- DEB.014_1fe: 238\n",
            "86/307 --- DEB.014_1ba: 238\n",
            "87/307 --- DEB.014_2de: 238\n",
            "88/307 --- DEB.014_2fe: 238\n",
            "89/307 --- DEB.014_2ba: 238\n",
            "90/307 --- DEB.014_3de: 238\n",
            "91/307 --- DEB.014_3fe: 238\n",
            "92/307 --- DEB.014_3ba: 238\n",
            "93/307 --- DEOR.014@6_0de: 237\n",
            "94/307 --- DEOR.014@6_0fe: 237\n",
            "95/307 --- DEOR.014@6_0ba: 237\n",
            "96/307 --- DEOR.014@6_1de: 238\n",
            "97/307 --- DEOR.014@6_1fe: 238\n",
            "98/307 --- DEOR.014@6_1ba: 238\n",
            "99/307 --- DEOR.014@6_2de: 237\n",
            "100/307 --- DEOR.014@6_2fe: 237\n",
            "101/307 --- DEOR.014@6_2ba: 237\n",
            "102/307 --- DEOR.014@6_3de: 238\n",
            "103/307 --- DEOR.014@6_3fe: 238\n",
            "104/307 --- DEOR.014@6_3ba: 238\n",
            "105/307 --- DEB.021_0de: 238\n",
            "106/307 --- DEB.021_0fe: 238\n",
            "107/307 --- DEB.021_0ba: 238\n",
            "108/307 --- DEB.021_1de: 237\n",
            "109/307 --- DEB.021_1fe: 237\n",
            "110/307 --- DEB.021_1ba: 237\n",
            "111/307 --- DEB.021_2de: 238\n",
            "112/307 --- DEB.021_2fe: 238\n",
            "113/307 --- DEB.021_2ba: 238\n",
            "114/307 --- DEB.021_3de: 238\n",
            "115/307 --- DEB.021_3fe: 238\n",
            "116/307 --- DEB.021_3ba: 238\n",
            "117/307 --- FEIR.021_0de: 236\n",
            "118/307 --- FEIR.021_0fe: 236\n",
            "119/307 --- FEIR.021_0ba: 236\n",
            "120/307 --- FEIR.021_1de: 236\n",
            "121/307 --- FEIR.021_1fe: 236\n",
            "122/307 --- FEIR.021_1ba: 236\n",
            "123/307 --- FEIR.021_2de: 236\n",
            "124/307 --- FEIR.021_2fe: 236\n",
            "125/307 --- FEIR.021_2ba: 236\n",
            "126/307 --- FEIR.021_3de: 236\n",
            "127/307 --- FEIR.021_3fe: 236\n",
            "128/307 --- FEIR.021_3ba: 236\n",
            "129/307 --- FEIR.014_0de: 237\n",
            "130/307 --- FEIR.014_0fe: 237\n",
            "131/307 --- FEIR.014_0ba: 237\n",
            "132/307 --- FEIR.014_1de: 237\n",
            "133/307 --- FEIR.014_1fe: 237\n",
            "134/307 --- FEIR.014_1ba: 237\n",
            "135/307 --- FEIR.014_2de: 237\n",
            "136/307 --- FEIR.014_2fe: 237\n",
            "137/307 --- FEIR.014_2ba: 237\n",
            "138/307 --- FEIR.014_3de: 236\n",
            "139/307 --- FEIR.014_3fe: 236\n",
            "140/307 --- FEIR.014_3ba: 236\n",
            "141/307 --- FEB.007_0de: 236\n",
            "142/307 --- FEB.007_0fe: 236\n",
            "143/307 --- FEB.007_0ba: 236\n",
            "144/307 --- FEB.007_1de: 235\n",
            "145/307 --- FEB.007_1fe: 235\n",
            "146/307 --- FEB.007_1ba: 235\n",
            "147/307 --- FEB.007_2de: 237\n",
            "148/307 --- FEB.007_2fe: 237\n",
            "149/307 --- FEB.007_2ba: 237\n",
            "150/307 --- FEB.007_3de: 236\n",
            "151/307 --- FEB.007_3fe: 236\n",
            "152/307 --- FEB.007_3ba: 236\n",
            "153/307 --- DEIR.021_0de: 238\n",
            "154/307 --- DEIR.021_0fe: 238\n",
            "155/307 --- DEIR.021_0ba: 238\n",
            "156/307 --- DEIR.021_1de: 237\n",
            "157/307 --- DEIR.021_1fe: 237\n",
            "158/307 --- DEIR.021_1ba: 237\n",
            "159/307 --- DEIR.021_2de: 237\n",
            "160/307 --- DEIR.021_2fe: 237\n",
            "161/307 --- DEIR.021_2ba: 237\n",
            "162/307 --- DEIR.021_3de: 238\n",
            "163/307 --- DEIR.021_3fe: 238\n",
            "164/307 --- DEIR.021_3ba: 238\n",
            "165/307 --- DEOR.021@6_0de: 239\n",
            "166/307 --- DEOR.021@6_0fe: 239\n",
            "167/307 --- DEOR.021@6_0ba: 239\n",
            "168/307 --- DEOR.021@6_1de: 238\n",
            "169/307 --- DEOR.021@6_1fe: 238\n",
            "170/307 --- DEOR.021@6_1ba: 238\n",
            "171/307 --- DEOR.021@6_2de: 238\n",
            "172/307 --- DEOR.021@6_2fe: 238\n",
            "173/307 --- DEOR.021@6_2ba: 238\n",
            "174/307 --- DEOR.021@6_3de: 238\n",
            "175/307 --- DEOR.021@6_3fe: 238\n",
            "176/307 --- DEOR.021@6_3ba: 238\n",
            "177/307 --- DEOR.021@3_0de: 237\n",
            "178/307 --- DEOR.021@3_0fe: 237\n",
            "179/307 --- DEOR.021@3_0ba: 237\n",
            "180/307 --- DEOR.021@3_1de: 238\n",
            "181/307 --- DEOR.021@3_1fe: 238\n",
            "182/307 --- DEOR.021@3_1ba: 238\n",
            "183/307 --- DEOR.021@3_2de: 238\n",
            "184/307 --- DEOR.021@3_2fe: 238\n",
            "185/307 --- DEOR.021@3_2ba: 238\n",
            "186/307 --- DEOR.021@3_3de: 238\n",
            "187/307 --- DEOR.021@3_3fe: 238\n",
            "188/307 --- DEOR.021@3_3ba: 238\n",
            "189/307 --- DEOR.021@12_0de: 237\n",
            "190/307 --- DEOR.021@12_0fe: 237\n",
            "191/307 --- DEOR.021@12_0ba: 237\n",
            "192/307 --- DEOR.021@12_1de: 239\n",
            "193/307 --- DEOR.021@12_1fe: 239\n",
            "194/307 --- DEOR.021@12_1ba: 239\n",
            "195/307 --- DEOR.021@12_2de: 239\n",
            "196/307 --- DEOR.021@12_2fe: 239\n",
            "197/307 --- DEOR.021@12_2ba: 239\n",
            "198/307 --- DEOR.021@12_3de: 237\n",
            "199/307 --- DEOR.021@12_3fe: 237\n",
            "200/307 --- DEOR.021@12_3ba: 237\n",
            "201/307 --- FEIR.007_0de: 237\n",
            "202/307 --- FEIR.007_0fe: 237\n",
            "203/307 --- FEIR.007_0ba: 237\n",
            "204/307 --- FEIR.007_1de: 237\n",
            "205/307 --- FEIR.007_1fe: 237\n",
            "206/307 --- FEIR.007_1ba: 237\n",
            "207/307 --- FEIR.007_2de: 237\n",
            "208/307 --- FEIR.007_2fe: 237\n",
            "209/307 --- FEIR.007_2ba: 237\n",
            "210/307 --- FEIR.007_3de: 237\n",
            "211/307 --- FEIR.007_3fe: 237\n",
            "212/307 --- FEIR.007_3ba: 237\n",
            "213/307 --- FEB.014_0de: 238\n",
            "214/307 --- FEB.014_0fe: 238\n",
            "215/307 --- FEB.014_0ba: 238\n",
            "216/307 --- FEB.014_1de: 237\n",
            "217/307 --- FEB.014_1fe: 237\n",
            "218/307 --- FEB.014_1ba: 237\n",
            "219/307 --- FEB.014_2de: 238\n",
            "220/307 --- FEB.014_2fe: 238\n",
            "221/307 --- FEB.014_2ba: 238\n",
            "222/307 --- FEB.014_3de: 236\n",
            "223/307 --- FEB.014_3fe: 236\n",
            "224/307 --- FEB.014_3ba: 236\n",
            "225/307 --- FEB.021_0de: 237\n",
            "226/307 --- FEB.021_0fe: 237\n",
            "227/307 --- FEB.021_0ba: 237\n",
            "228/307 --- FEB.021_1de: 237\n",
            "229/307 --- FEB.021_1fe: 237\n",
            "230/307 --- FEB.021_1ba: 237\n",
            "231/307 --- FEB.021_2de: 237\n",
            "232/307 --- FEB.021_2fe: 237\n",
            "233/307 --- FEB.021_2ba: 237\n",
            "234/307 --- FEB.021_3de: 235\n",
            "235/307 --- FEB.021_3fe: 235\n",
            "236/307 --- FEB.021_3ba: 235\n",
            "237/307 --- FEOR.007@6_0de: 236\n",
            "238/307 --- FEOR.007@6_0fe: 236\n",
            "239/307 --- FEOR.007@6_0ba: 236\n",
            "240/307 --- FEOR.007@6_1de: 237\n",
            "241/307 --- FEOR.007@6_1fe: 237\n",
            "242/307 --- FEOR.007@6_1ba: 237\n",
            "243/307 --- FEOR.007@6_2de: 236\n",
            "244/307 --- FEOR.007@6_2fe: 236\n",
            "245/307 --- FEOR.007@6_2ba: 236\n",
            "246/307 --- FEOR.007@6_3de: 238\n",
            "247/307 --- FEOR.007@6_3fe: 238\n",
            "248/307 --- FEOR.007@6_3ba: 238\n",
            "249/307 --- FEOR.007@3_0de: 236\n",
            "250/307 --- FEOR.007@3_0fe: 236\n",
            "251/307 --- FEOR.007@3_0ba: 236\n",
            "252/307 --- FEOR.007@3_1de: 236\n",
            "253/307 --- FEOR.007@3_1fe: 236\n",
            "254/307 --- FEOR.007@3_1ba: 236\n",
            "255/307 --- FEOR.007@3_2de: 238\n",
            "256/307 --- FEOR.007@3_2fe: 238\n",
            "257/307 --- FEOR.007@3_2ba: 238\n",
            "258/307 --- FEOR.007@3_3de: 237\n",
            "259/307 --- FEOR.007@3_3fe: 237\n",
            "260/307 --- FEOR.007@3_3ba: 237\n",
            "261/307 --- FEOR.007@12_0de: 236\n",
            "262/307 --- FEOR.007@12_0fe: 236\n",
            "263/307 --- FEOR.007@12_0ba: 236\n",
            "264/307 --- FEOR.007@12_1de: 236\n",
            "265/307 --- FEOR.007@12_1fe: 236\n",
            "266/307 --- FEOR.007@12_1ba: 236\n",
            "267/307 --- FEOR.007@12_2de: 237\n",
            "268/307 --- FEOR.007@12_2fe: 237\n",
            "269/307 --- FEOR.007@12_2ba: 237\n",
            "270/307 --- FEOR.007@12_3de: 236\n",
            "271/307 --- FEOR.007@12_3fe: 236\n",
            "272/307 --- FEOR.007@12_3ba: 236\n",
            "273/307 --- FEOR.014@3_0de: 237\n",
            "274/307 --- FEOR.014@3_0fe: 237\n",
            "275/307 --- FEOR.014@3_0ba: 237\n",
            "276/307 --- FEOR.014@3_1de: 236\n",
            "277/307 --- FEOR.014@3_1fe: 236\n",
            "278/307 --- FEOR.014@3_1ba: 236\n",
            "279/307 --- FEOR.014@3_2de: 236\n",
            "280/307 --- FEOR.014@3_2fe: 236\n",
            "281/307 --- FEOR.014@3_2ba: 236\n",
            "282/307 --- FEOR.014@3_3de: 236\n",
            "283/307 --- FEOR.014@3_3fe: 236\n",
            "284/307 --- FEOR.014@3_3ba: 236\n",
            "285/307 --- FEOR.014@6_0de: 236\n",
            "286/307 --- FEOR.014@6_0fe: 236\n",
            "287/307 --- FEOR.014@6_0ba: 236\n",
            "288/307 --- FEOR.021@6_0de: 235\n",
            "289/307 --- FEOR.021@6_0fe: 235\n",
            "290/307 --- FEOR.021@6_0ba: 235\n",
            "291/307 --- FEOR.021@3_1de: 235\n",
            "292/307 --- FEOR.021@3_1fe: 235\n",
            "293/307 --- FEOR.021@3_1ba: 235\n",
            "294/307 --- FEOR.021@3_2de: 235\n",
            "295/307 --- FEOR.021@3_2fe: 235\n",
            "296/307 --- FEOR.021@3_2ba: 235\n",
            "297/307 --- FEOR.021@3_3de: 237\n",
            "298/307 --- FEOR.021@3_3fe: 237\n",
            "299/307 --- FEOR.021@3_3ba: 237\n",
            "300/307 --- DEIR.028_0de: 235\n",
            "301/307 --- DEIR.028_1de: 237\n",
            "302/307 --- DEIR.028_2de: 237\n",
            "303/307 --- DEIR.028_3de: 237\n",
            "304/307 --- DEB.028_0de: 235\n",
            "305/307 --- DEB.028_1de: 237\n",
            "306/307 --- DEB.028_2de: 236\n",
            "307/307 --- DEB.028_3de: 236\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(77527, 512, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jCN8XZ5dOF3",
        "colab_type": "text"
      },
      "source": [
        "## Clean dataset functions\n",
        "The functions below help to select samples from acquisitions and form groups according to these acquisitions, using regular expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOOP9H2c3AaZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def select_samples(regex, X, y):\n",
        "  '''\n",
        "  Selects samples wich has some regex pattern in its name.\n",
        "  '''\n",
        "  mask = [re.search(regex,label) is not None for label in y]\n",
        "  return X[mask],y[mask]\n",
        "\n",
        "def join_labels(regex, y):\n",
        "  '''\n",
        "  Excludes some regex patterns from the labels, \n",
        "  making some samples to have the same label.\n",
        "  '''\n",
        "  return np.array([re.sub(regex, '', label) for label in y])\n",
        "\n",
        "def get_groups(regex, y):\n",
        "  '''\n",
        "  Generates a list of groups of samples with \n",
        "  the same regex patten in its label.\n",
        "  '''\n",
        "  groups = list(range(len(y)))\n",
        "  for i,label in enumerate(y):\n",
        "    match = re.search(regex,label)\n",
        "    groups[i] = match.group(0) if match else None\n",
        "  return groups"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFA-8l02RplD",
        "colab_type": "text"
      },
      "source": [
        "##Selecting samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r89dYOJm8gzW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2549dd74-9a75-428b-c936-b1de7639bb1c"
      },
      "source": [
        "#DE from 'de', FE from 'fe', Normal from 'de' and 'fe'\n",
        "samples = '^(DE).*(de)|^(FE).*(fe)|(Normal).*'\n",
        "X,y = select_samples(samples, signal_data, np.array(signal_origin))\n",
        "print(len(set(y)),set(y))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113 {'DEIR.007_1de', 'DEIR.007_2de', 'FEB.007_3fe', 'FEIR.021_3fe', 'DEIR.028_0de', 'Normal_3fe', 'DEB.028_3de', 'DEB.028_0de', 'DEIR.014_3de', 'FEB.021_3fe', 'FEIR.021_0fe', 'FEOR.007@12_1fe', 'FEB.014_3fe', 'DEIR.028_3de', 'FEIR.014_2fe', 'DEIR.014_0de', 'FEOR.007@6_3fe', 'DEIR.021_2de', 'DEB.028_1de', 'FEOR.007@6_1fe', 'FEOR.007@3_2fe', 'DEB.007_3de', 'DEIR.028_1de', 'FEB.007_1fe', 'FEOR.014@3_1fe', 'DEOR.007@3_0de', 'DEOR.021@3_2de', 'Normal_2fe', 'DEOR.021@6_2de', 'DEOR.007@3_2de', 'DEB.014_0de', 'DEOR.007@12_2de', 'DEB.014_3de', 'DEOR.021@6_3de', 'FEIR.007_2fe', 'DEOR.021@3_1de', 'DEB.028_2de', 'FEIR.007_0fe', 'DEB.007_1de', 'FEB.021_2fe', 'FEIR.007_1fe', 'FEIR.014_1fe', 'FEB.014_1fe', 'FEOR.007@12_0fe', 'DEIR.021_0de', 'DEIR.021_1de', 'DEOR.014@6_1de', 'FEOR.007@12_3fe', 'DEIR.007_0de', 'DEB.021_0de', 'Normal_3de', 'DEIR.021_3de', 'FEOR.014@3_0fe', 'DEOR.014@6_2de', 'FEOR.014@3_3fe', 'DEOR.021@12_1de', 'DEIR.014_2de', 'FEOR.014@6_0fe', 'FEOR.021@6_0fe', 'Normal_0de', 'Normal_1de', 'DEOR.021@12_3de', 'DEOR.007@6_2de', 'DEOR.007@6_0de', 'Normal_2de', 'FEOR.014@3_2fe', 'DEB.007_2de', 'FEOR.007@3_3fe', 'DEOR.021@12_0de', 'DEOR.021@3_3de', 'FEOR.007@6_0fe', 'DEIR.014_1de', 'FEB.014_2fe', 'DEOR.014@6_3de', 'FEOR.007@12_2fe', 'DEOR.007@12_0de', 'FEIR.007_3fe', 'FEOR.021@3_3fe', 'DEOR.007@12_1de', 'FEB.021_1fe', 'FEOR.021@3_1fe', 'DEOR.007@12_3de', 'DEB.007_0de', 'FEIR.014_0fe', 'DEIR.007_3de', 'FEIR.021_2fe', 'DEOR.021@6_0de', 'DEOR.021@3_0de', 'DEOR.021@12_2de', 'DEB.021_2de', 'FEB.014_0fe', 'DEB.014_2de', 'FEB.007_2fe', 'Normal_0fe', 'DEOR.007@3_1de', 'Normal_1fe', 'DEOR.014@6_0de', 'DEOR.007@6_1de', 'DEOR.007@3_3de', 'DEOR.007@6_3de', 'FEOR.007@6_2fe', 'FEIR.021_1fe', 'DEIR.028_2de', 'FEOR.007@3_1fe', 'FEOR.007@3_0fe', 'DEB.014_1de', 'DEB.021_3de', 'FEIR.014_3fe', 'DEB.021_1de', 'FEOR.021@3_2fe', 'FEB.021_0fe', 'FEB.007_0fe', 'DEOR.021@6_1de'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pRQQK0Mhm1_",
        "colab_type": "text"
      },
      "source": [
        "#Experimenter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GE4TTG1-hmH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "51d6bbb2-e27c-4853-9ff9-0a8447a1e975"
      },
      "source": [
        "from sklearn.model_selection import cross_validate, KFold, PredefinedSplit\n",
        "\n",
        "def experimenter(model, X, y, groups=None, scoring=None, cv=KFold(4, True), verbose=0):\n",
        "  '''\n",
        "  Performs a experiment with some estimator (model) and validation.\n",
        "  It works like a cross_validate function from sklearn, however, \n",
        "  when a estimator has an internal validation with groups, \n",
        "  it maintains the groups from the external validation.\n",
        "  '''\n",
        "  if hasattr(model,'cv') or (hasattr(model,'steps') and any(['gs' in step[0] for step in model.steps])):\n",
        "    scores = {}\n",
        "    lstval = list(validation.split(X,y,groups))\n",
        "    for tr,te in lstval:\n",
        "      if groups is not None:\n",
        "        innercv = list(GroupShuffleKFold(validation.n_splits-1).split(X[tr],y[tr],np.array(groups)[tr]))\n",
        "      else:\n",
        "        innercv = list(KFold(validation.n_splits-1, True).split(X[tr],y[tr]))\n",
        "      if hasattr(model,'cv'):\n",
        "        model.cv = innercv\n",
        "      else:\n",
        "        for step in model.steps:\n",
        "          if 'gs' in step[0]:\n",
        "            step[1].cv = innercv\n",
        "      test_fold = np.zeros((len(y),), dtype=int)\n",
        "      test_fold[tr] = -1\n",
        "      score = cross_validate(model, X, y, groups, scoring, \n",
        "                             PredefinedSplit(test_fold), verbose=verbose)\n",
        "      for k in score.keys():\n",
        "        if k not in scores:\n",
        "          scores[k] = []\n",
        "        scores[k].extend(score[k])\n",
        "    return scores\n",
        "  return cross_validate(model, X, y, groups, scoring, cv, verbose=verbose)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/francisco/Jupyter/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:68: FutureWarning: Pass shuffle=True as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
            "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWYfuxcxFjt8",
        "colab_type": "text"
      },
      "source": [
        "## Custom Splitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRdfG-uzhPm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils.validation import check_array\n",
        "import numpy as np\n",
        "\n",
        "class GroupShuffleKFold(KFold):\n",
        "  '''\n",
        "  Neither GroupShuffleSplit nor GroupKFold are good splitters for this case.\n",
        "  A custom splitter must be made.\n",
        "  '''\n",
        "  def __init__(self, n_splits=4, shuffle=False, random_state=None):\n",
        "    super().__init__(n_splits, shuffle=shuffle, random_state=random_state)\n",
        "  def get_n_splits(self, X, y, groups=None):\n",
        "    return self.n_splits\n",
        "  def _iter_test_indices(self, X=None, y=None, groups=None):\n",
        "    if groups is None:\n",
        "      raise ValueError(\"The 'groups' parameter should not be None.\")\n",
        "    groups = check_array(groups, ensure_2d=False, dtype=None)\n",
        "    unique_groups, groups = np.unique(groups, return_inverse=True)\n",
        "    n_groups = len(unique_groups)\n",
        "    if self.n_splits > n_groups:\n",
        "      raise ValueError(\"Cannot have number of splits n_splits=%d greater\"\n",
        "                        \" than the number of groups: %d.\"\n",
        "                        % (self.n_splits, n_groups))\n",
        "    # Distribute groups\n",
        "    indices = np.arange(n_groups)\n",
        "    if self.shuffle:\n",
        "      for i in range(n_groups//self.n_splits):\n",
        "        if self.random_state is None:\n",
        "          indices[self.n_splits*i:self.n_splits*(i+1)] = shuffle(\n",
        "              indices[self.n_splits*i:self.n_splits*(i+1)])\n",
        "        else:\n",
        "          indices[self.n_splits*i:self.n_splits*(i+1)] = shuffle(\n",
        "              indices[self.n_splits*i:self.n_splits*(i+1)],\n",
        "              random_state=self.random_state+i)\n",
        "    #print(unique_groups[indices]) #Debug purpose\n",
        "    # Total weight of each fold\n",
        "    n_samples_per_fold = np.zeros(self.n_splits)\n",
        "    # Mapping from group index to fold index\n",
        "    group_to_fold = np.zeros(len(unique_groups))\n",
        "    # Distribute samples \n",
        "    for group_index in indices:\n",
        "      group_to_fold[indices[group_index]] = group_index%(self.n_splits)\n",
        "    indices = group_to_fold[groups]\n",
        "    for f in range(self.n_splits):\n",
        "      yield np.where(indices == f)[0]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Frmm3FVivQvg",
        "colab_type": "text"
      },
      "source": [
        "## BySeverity Splitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFDWy6zqvGTF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.utils.validation import check_array\n",
        "import numpy as np\n",
        "\n",
        "class BySeverityKFold(KFold):\n",
        "  '''\n",
        "  Splits the CWRU dataset in severities.\n",
        "  '''\n",
        "  # Compatibility constructor\n",
        "  def __init__(self, n_splits=4, shuffle=False, random_state=None):\n",
        "    super().__init__(n_splits=4, shuffle=False, random_state=None)\n",
        "    self.nround = random_state\n",
        "  def _iter_test_indices(self, X=None, y=None, groups=None):\n",
        "    if groups is None:\n",
        "      raise ValueError(\"The 'groups' parameter should not be None.\")\n",
        "    groups = check_array(groups, ensure_2d=False, dtype=None)\n",
        "    unique_groups, groups = np.unique(groups, return_inverse=True)\n",
        "    n_groups = len(unique_groups)\n",
        "    if self.n_splits > n_groups:\n",
        "      raise ValueError(\"Cannot have number of splits n_splits=%d greater\"\n",
        "                        \" than the number of groups: %d.\"\n",
        "                        % (self.n_splits, n_groups))\n",
        "    # Distribute groups\n",
        "    indices = np.arange(n_groups)\n",
        "    nround = self.nround - random_state\n",
        "    for i in range(nround//4):\n",
        "      indices[i],indices[i+1] = indices[i+1],indices[i]\n",
        "    for i in range(self.n_splits):      \n",
        "      indices[i+self.n_splits] = (i+nround)%self.n_splits+self.n_splits\n",
        "    #print(unique_groups[indices]) #Debug purpose\n",
        "    # Total weight of each fold\n",
        "    n_samples_per_fold = np.zeros(self.n_splits)\n",
        "    # Mapping from group index to fold index\n",
        "    group_to_fold = np.zeros(len(unique_groups))\n",
        "    # Distribute samples \n",
        "    for group_index in indices:\n",
        "      group_to_fold[indices[group_index]] = group_index%(self.n_splits)\n",
        "    print(group_to_fold)\n",
        "    indices = group_to_fold[groups]\n",
        "    for f in range(self.n_splits):\n",
        "      yield np.where(indices == f)[0]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e48W6KkIhesw",
        "colab_type": "text"
      },
      "source": [
        "##Experiment setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9dImVH3hh_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import namedtuple\n",
        "\n",
        "ExperimentSetup = namedtuple('ExperimentSetup', \n",
        "                             'groups, splitter_name, shuffle, rounds')\n",
        "\n",
        "validations = {\n",
        "    # Samples with the same load cannot be in the trainning fold and\n",
        "    # the test folds simultaneously. \n",
        "    \"By Load\": ExperimentSetup(groups = get_groups('_\\d',y), \n",
        "                               splitter_name = 'GroupShuffleKFold',\n",
        "                               shuffle = False,\n",
        "                               rounds=1,\n",
        "                               ),\n",
        "    # Samples with the same severity cannot be in the trainning folds and\n",
        "    # the test folds simultaneously.\n",
        "    \"By Severity\": ExperimentSetup(groups = get_groups('(\\.\\d{3})|(Normal_\\d)',y),\n",
        "                                   splitter_name = 'BySeverityKFold',\n",
        "                                   shuffle = False,\n",
        "                                   rounds=8),\n",
        "    # Validation usually seen in publications with CWRU bearing dataset.\n",
        "    \"Usual K-Fold\": ExperimentSetup(groups = None, \n",
        "                                    splitter_name = 'KFold',\n",
        "                                    shuffle = True,\n",
        "                                    rounds=8), \n",
        "}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9yn44VAoRFo",
        "colab_type": "text"
      },
      "source": [
        "##Common Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpdDde4oTsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Only four conditions are considered: Normal, Ball, Inner Race and Outer Race.\n",
        "selected_y = join_labels('_\\d|@\\d{1,3}|(de)|(fe)|\\.\\d{3}|(DE)|(FE)',y)\n",
        "verbose = 0 #if not debug else 3\n",
        "random_state = 42\n",
        "scoring = ['accuracy', 'f1_macro']#, 'precision_macro', 'recall_macro']"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq30RtWYToeu",
        "colab_type": "text"
      },
      "source": [
        "#Classification Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IstS2gTeY7pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLeArq-uThHW",
        "colab_type": "text"
      },
      "source": [
        "##Feature Extraction Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuSNj6YIEhu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm95T4CsDxaN",
        "colab_type": "text"
      },
      "source": [
        "###Statistical functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWCPUON8D1A8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "def rms(x):\n",
        "  '''\n",
        "  root mean square\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.sqrt(np.mean(np.square(x)))\n",
        "\n",
        "def sra(x):\n",
        "  '''\n",
        "  square root amplitude\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.mean(np.sqrt(np.absolute(x)))**2\n",
        "\n",
        "def ppv(x):\n",
        "  '''\n",
        "  peak to peak value\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(x)-np.min(x)\n",
        "\n",
        "def cf(x):\n",
        "  '''\n",
        "  crest factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/rms(x)\n",
        "\n",
        "def ifa(x):\n",
        "  '''\n",
        "  impact factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/np.mean(np.absolute(x))\n",
        "\n",
        "def mf(x):\n",
        "  '''\n",
        "  margin factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/sra(x)\n",
        "\n",
        "def sf(x):\n",
        "  '''\n",
        "  shape factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return rms(x)/np.mean(np.absolute(x))\n",
        "\n",
        "def kf(x):\n",
        "  '''\n",
        "  kurtosis factor\n",
        "  '''\n",
        "  x = np.array(x)\n",
        "  return stats.kurtosis(x)/(np.mean(x**2)**2)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njMb9HtUEBrI",
        "colab_type": "text"
      },
      "source": [
        "### Statistical Features from Time Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSN2_c28D_Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StatisticalTime(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from the time domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    return np.array([\n",
        "                     [\n",
        "                      rms(x), # root mean square\n",
        "                      sra(x), # square root amplitude\n",
        "                      stats.kurtosis(x), # kurtosis\n",
        "                      stats.skew(x), # skewness\n",
        "                      ppv(x), # peak to peak value\n",
        "                      cf(x), # crest factor\n",
        "                      ifa(x), # impact factor\n",
        "                      mf(x), # margin factor\n",
        "                      sf(x), # shape factor\n",
        "                      kf(x), # kurtosis factor\n",
        "                      ] for x in X[:,:,0]\n",
        "                     ])\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXDWD3JZEnep",
        "colab_type": "text"
      },
      "source": [
        "### Statistical Features from Frequency Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj3XTpVTEvAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StatisticalFrequency(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from the frequency domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    sig = []\n",
        "    for x in X[:,:,0]:\n",
        "      fx = np.absolute(np.fft.fft(x)) # transform x from time to frequency domain\n",
        "      fc = np.mean(fx) # frequency center\n",
        "      sig.append([\n",
        "                  fc, # frequency center\n",
        "                  rms(fx), # RMS from the frequency domain\n",
        "                  rms(fx-fc), # Root Variance Frequency\n",
        "                  ])\n",
        "    return np.array(sig)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0YBmzTb6ARb",
        "colab_type": "text"
      },
      "source": [
        "###Statistical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kep4ubkR6DR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Statistical(TransformerMixin):\n",
        "  '''\n",
        "  Extracts statistical features from both time and frequency domain.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats),axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuiVsHNzFORr",
        "colab_type": "text"
      },
      "source": [
        "###Wavelet Package Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPd92xtJhaH3",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pywt\n",
        "\n",
        "class WaveletPackage(TransformerMixin):\n",
        "  '''\n",
        "  Extracts Wavelet Package features.\n",
        "  The features are calculated by the energy of the recomposed signal\n",
        "  of the leaf nodes coeficients.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    def Energy(coeffs, k):\n",
        "      return np.sqrt(np.sum(np.array(coeffs[-k]) ** 2)) / len(coeffs[-k])\n",
        "    def getEnergy(wp):\n",
        "      coefs = np.asarray([n.data for n in wp.get_leaf_nodes(True)])\n",
        "      return np.asarray([Energy(coefs,i) for i in range(2**wp.maxlevel)])\n",
        "    return np.array([getEnergy(pywt.WaveletPacket(data=x, wavelet='db4', \n",
        "                                                  mode='symmetric', maxlevel=4)\n",
        "                                                  ) for x in X[:,:,0]])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_sonHkjFYbB",
        "colab_type": "text"
      },
      "source": [
        "###Heterogeneus Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZsZhuVfFZsQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Heterogeneous(TransformerMixin):\n",
        "  '''\n",
        "  Mixes Statistical and Wavelet Package features.\n",
        "  '''\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    wp = WaveletPackage()\n",
        "    wpfeats = wp.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats,wpfeats),axis=1)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bnyL67EUcxV",
        "colab_type": "text"
      },
      "source": [
        "##K-NN with Heterogeneous Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F--sjKZRUh5G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c212990a-d021-482d-8878-c28515248287"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "knn = Pipeline([\n",
        "                ('FeatureExtraction', Heterogeneous()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('knn', KNeighborsClassifier()),\n",
        "                ])\n",
        "\n",
        "parameters = {'knn__n_neighbors': list(range(1,16,2))}\n",
        "if not debug:\n",
        "  knn = GridSearchCV(knn, parameters, verbose=verbose)\n",
        "else:\n",
        "  knn = GridSearchCV(knn, {'knn__n_neighbors': list(range(1,4,2))}, verbose=verbose)\n",
        "knn"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('FeatureExtraction',\n",
              "                                        <__main__.Heterogeneous object at 0x7f918295e100>),\n",
              "                                       ('scaler', StandardScaler()),\n",
              "                                       ('knn', KNeighborsClassifier())]),\n",
              "             param_grid={'knn__n_neighbors': [1, 3, 5, 7, 9, 11, 13, 15]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7DfMTS_ujeE",
        "colab_type": "text"
      },
      "source": [
        "##SVM with Heterogeneous Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v_wXxiDupvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b2c9762a-16a2-467f-923c-c0307c2c68fc"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "svm = Pipeline([\n",
        "                ('FeatureExtraction', Heterogeneous()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('svc', SVC()),\n",
        "                ])\n",
        "\n",
        "parameters = {\n",
        "    'svc__C': [10**x for x in range(-3,2)],\n",
        "    'svc__gamma': [10**x for x in range(-3,1)],\n",
        "    }\n",
        "if not debug:\n",
        "  svm = GridSearchCV(svm, parameters, verbose=verbose)\n",
        "svm"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('FeatureExtraction',\n",
              "                                        <__main__.Heterogeneous object at 0x7f9182f79820>),\n",
              "                                       ('scaler', StandardScaler()),\n",
              "                                       ('svc', SVC())]),\n",
              "             param_grid={'svc__C': [0.001, 0.01, 0.1, 1, 10],\n",
              "                         'svc__gamma': [0.001, 0.01, 0.1, 1]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU36xsi4JGZv",
        "colab_type": "text"
      },
      "source": [
        "##Random Forest with Heterogeneous Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXABo6HpJJY_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "48476bad-bfcd-483c-ccd6-f29f87453e5f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rf = Pipeline([\n",
        "               ('FeatureExtraction', Heterogeneous()),\n",
        "               ('scaler', StandardScaler()),\n",
        "               ('rf', RandomForestClassifier()),\n",
        "               ])\n",
        "\n",
        "parameters = {\n",
        "    \"rf__n_estimators\": [10, 20, 50, 100, 200, 500],\n",
        "    \"rf__max_features\": list(range(1,21)),\n",
        "    }\n",
        "if not debug:\n",
        "  rf = GridSearchCV(rf, parameters, verbose=verbose)\n",
        "rf"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=Pipeline(steps=[('FeatureExtraction',\n",
              "                                        <__main__.Heterogeneous object at 0x7f9182f79850>),\n",
              "                                       ('scaler', StandardScaler()),\n",
              "                                       ('rf', RandomForestClassifier())]),\n",
              "             param_grid={'rf__max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
              "                                              12, 13, 14, 15, 16, 17, 18, 19,\n",
              "                                              20],\n",
              "                         'rf__n_estimators': [10, 20, 50, 100, 200, 500]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REy6ykvWSbJc",
        "colab_type": "text"
      },
      "source": [
        "##Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpHSjvNcEx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "33dcecef-1730-43d3-b70f-75b7d70667b8"
      },
      "source": [
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except:\n",
        "  print(\"Out of Colab\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Out of Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF1hCxJ9b5h0",
        "colab_type": "text"
      },
      "source": [
        "###F1-score macro averaged implemented for Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJErrQIcIZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def f1_score_macro(y_true,y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeLXSU7-cLfk",
        "colab_type": "text"
      },
      "source": [
        "###ANN wrapped in a scikit-learn estimator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ny7otiW6Siz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
        "\n",
        "class ANN(BaseEstimator, ClassifierMixin):\n",
        "  def __init__(self, \n",
        "               dense_layer_sizes=[64], \n",
        "               kernel_size=32, \n",
        "               filters=32, \n",
        "               n_conv_layers=2,\n",
        "               pool_size=8,\n",
        "               dropout=0.25,\n",
        "               epochs=50,\n",
        "               validation_split=0.05,\n",
        "               optimizer='sgd'#'nadam'#'rmsprop'#\n",
        "               ):\n",
        "    self.dense_layer_sizes = dense_layer_sizes\n",
        "    self.kernel_size = kernel_size\n",
        "    self.filters = filters\n",
        "    self.n_conv_layers = n_conv_layers\n",
        "    self.pool_size = pool_size\n",
        "    self.dropout = dropout\n",
        "    self.epochs = epochs\n",
        "    self.validation_split = validation_split\n",
        "    self.optimizer = optimizer\n",
        "  \n",
        "  def fit(self, X, y=None):\n",
        "    dense_layer_sizes = self.dense_layer_sizes\n",
        "    kernel_size = self.kernel_size\n",
        "    filters = self.filters\n",
        "    n_conv_layers = self.n_conv_layers\n",
        "    pool_size = self.pool_size\n",
        "    dropout = self.dropout\n",
        "    epochs = self.epochs\n",
        "    optimizer = self.optimizer\n",
        "    validation_split = self.validation_split\n",
        "\n",
        "    self.labels, ids = np.unique(y, return_inverse=True)\n",
        "    y_cat = to_categorical(ids)\n",
        "    num_classes = y_cat.shape[1]\n",
        "    \n",
        "    self.model = Sequential()\n",
        "    self.model.add(layers.InputLayer(input_shape=(X.shape[1],X.shape[-1])))\n",
        "    for _ in range(n_conv_layers):\n",
        "      self.model.add(layers.Conv1D(filters, kernel_size))#, padding='valid'))\n",
        "      self.model.add(layers.Activation('relu'))\n",
        "      if pool_size>1:\n",
        "        self.model.add(layers.MaxPooling1D(pool_size=pool_size))\n",
        "    #self.model.add(layers.Dropout(0.25))\n",
        "    self.model.add(layers.Flatten())\n",
        "    for layer_size in dense_layer_sizes:\n",
        "        self.model.add(layers.Dense(layer_size))\n",
        "        self.model.add(layers.Activation('relu'))\n",
        "    if dropout>0 and dropout<1:\n",
        "      self.model.add(layers.Dropout(dropout))\n",
        "    self.model.add(layers.Dense(num_classes))\n",
        "    self.model.add(layers.Activation('softmax'))\n",
        "    self.model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer=optimizer,\n",
        "                       metrics=[f1_score_macro])\n",
        "    if validation_split>0 and validation_split<1:\n",
        "      prop = int(1/validation_split)\n",
        "      mask = np.array([i%prop==0 for i in range(len(y))])\n",
        "      self.history = self.model.fit(X[~mask], y_cat[~mask], epochs=epochs, \n",
        "                                    validation_data=(X[mask],y_cat[mask]),\n",
        "                                    callbacks=[EarlyStopping(patience=3), ReduceLROnPlateau()],\n",
        "                                    verbose=False\n",
        "                                    )  \n",
        "    else:\n",
        "      self.history = self.model.fit(X, y_cat, epochs=epochs, verbose=False)  \n",
        "  \n",
        "  def predict_proba(self, X, y=None):\n",
        "    return self.model.predict(X)\n",
        "\n",
        "  def predict(self, X, y=None):\n",
        "    predictions = self.model.predict(X)\n",
        "    return self.labels[np.argmax(predictions,axis=1)]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UL5Zv2-xcgEG",
        "colab_type": "text"
      },
      "source": [
        "###ANN instantiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmQe7jeRcb6F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0dcc1c8c-efcb-48d0-ecd7-6ea3edda28cb"
      },
      "source": [
        "parameters = {\n",
        "    'filters': [16, 32],\n",
        "    'kernel_size': [16, 32],\n",
        "    'n_conv_layers': [1, 2],\n",
        "    #'pool_size': [2, 4, 6, 8],\n",
        "    }\n",
        "ann = ANN()\n",
        "if not debug:\n",
        "  ann = GridSearchCV(ann, parameters, verbose=verbose)\n",
        "ann"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=ANN(),\n",
              "             param_grid={'filters': [16, 32], 'kernel_size': [16, 32],\n",
              "                         'n_conv_layers': [1, 2]})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SQenKxoSkME",
        "colab_type": "text"
      },
      "source": [
        "##List of Estimators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb6AGKFJJqvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clfs = [\n",
        "        ('KNN - KNeighborsClassifier, Heterogeneous Features', knn),\n",
        "        # ('SVM - SVC with Heterogeneous Features', svm),\n",
        "        # ('ANN - Artificial Neural Network with Convolutional Layers', ann),\n",
        "        # ('RF - RandomForestClassifier with Heterogeneous Features', rf),\n",
        "        ]\n",
        "if not debug:\n",
        "  dirres = 'cwru_knn'\n",
        "  # dirres = 'cwru_res'\n",
        "else:\n",
        "  dirres = 'debugres'"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dEl_vSYaq-s2"
      },
      "source": [
        "#Performing Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH4LVC3Zj3jC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c248bbf3-13ce-4c12-b7d4-7879f4cfabd6"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "scores = {}\n",
        "trtime = {}\n",
        "tetime = {}\n",
        "# Estimators\n",
        "for clf_name, estimator in clfs:\n",
        "  if clf_name not in scores:\n",
        "    scores[clf_name] = {}\n",
        "    trtime[clf_name] = {}\n",
        "    tetime[clf_name] = {}\n",
        "  print(\"*\"*(len(clf_name)+8),'\\n***',clf_name,'***\\n'+\"*\"*(len(clf_name)+8))\n",
        "  # Validation forms\n",
        "  for val_name in validations.keys():\n",
        "    print(\"#\"*(len(val_name)+8),'\\n###',val_name,'###\\n'+\"#\"*(len(val_name)+8))\n",
        "    # Number of repetitions\n",
        "    for r in range(validations[val_name].rounds):\n",
        "      round_str = \"Round {}\".format(r+1)\n",
        "      print(\"@\"*(len(round_str)+8),'\\n@@@',round_str,'@@@\\n'+\"@\"*(len(round_str)+8))\n",
        "      groups = validations[val_name].groups\n",
        "      if val_name not in scores[clf_name]:\n",
        "        scores[clf_name][val_name] = {}\n",
        "      validation = eval(validations[val_name].splitter_name\n",
        "                        +'(4,shuffle='+str(validations[val_name].shuffle)\n",
        "                        +',random_state='+str(random_state+r)+')')\n",
        "      score = experimenter(estimator, X, selected_y, groups, \n",
        "                           scoring, validation, verbose)\n",
        "      for metric,s in score.items():\n",
        "        print(metric, ' \\t', s)\n",
        "        if metric not in scores[clf_name][val_name]:\n",
        "          scores[clf_name][val_name][metric] = []\n",
        "        scores[clf_name][val_name][metric].append(s)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********************************************************** \n",
            "*** KNN - KNeighborsClassifier, Heterogeneous Features ***\n",
            "**********************************************************\n",
            "############### \n",
            "### By Load ###\n",
            "###############\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 1 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [659.5190086364746, 705.9330987930298, 700.7828290462494, 708.4717094898224]\n",
            "score_time  \t [10.357920408248901, 10.940906763076782, 10.930191040039062, 10.941886901855469]\n",
            "test_accuracy  \t [0.9399836690255852, 0.9613856468835361, 0.9440168818272096, 0.9431973210963661]\n",
            "test_f1_macro  \t [0.9459365719549166, 0.9599772834892515, 0.9428645854817683, 0.9414931800564585]\n",
            "################### \n",
            "### By Severity ###\n",
            "###################\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 1 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[0. 1. 2. 3. 0. 1. 2. 3.]\n",
            "fit_time  \t [622.1331112384796, 713.1196811199188, 655.9671769142151, 874.1445345878601]\n",
            "score_time  \t [14.744359731674194, 10.464348554611206, 14.578272342681885, 5.233000040054321]\n",
            "test_accuracy  \t [0.5546934865900384, 0.4828556806550665, 0.5265323346344551, 0.5007923930269413]\n",
            "test_f1_macro  \t [0.6163016996962689, 0.4336768206032479, 0.5543308593096117, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 2 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[0. 1. 2. 3. 3. 0. 1. 2.]\n",
            "fit_time  \t [602.9509010314941, 711.846010684967, 687.6024491786957, 976.9688551425934]\n",
            "score_time  \t [15.71648097038269, 10.89102053642273, 15.30472731590271, 4.147334814071655]\n",
            "test_accuracy  \t [0.592019687115486, 0.4828556806550665, 0.5247232472324723, 0.33497536945812806]\n",
            "test_f1_macro  \t [0.6179135041535164, 0.4336768206032479, 0.5525837013131806, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 3 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[0. 1. 2. 3. 2. 3. 0. 1.]\n",
            "fit_time  \t [629.6763322353363, 727.3733189105988, 705.8832745552063, 911.996399641037]\n",
            "score_time  \t [16.763240575790405, 10.987282514572144, 13.675462484359741, 5.271104097366333]\n",
            "test_accuracy  \t [0.592019687115486, 0.48580925594477115, 0.46832923545252314, 0.5]\n",
            "test_f1_macro  \t [0.6179135041535164, 0.4389838997220735, 0.5473398170756133, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 4 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[0. 1. 2. 3. 1. 2. 3. 0.]\n",
            "fit_time  \t [626.6706945896149, 766.9733066558838, 677.3449251651764, 903.830872297287]\n",
            "score_time  \t [16.346885919570923, 9.561249732971191, 14.702006578445435, 5.393165588378906]\n",
            "test_accuracy  \t [0.5914441321152495, 0.41232916545507414, 0.5265323346344551, 0.5]\n",
            "test_f1_macro  \t [0.6169760723162696, 0.425629330041274, 0.5543308593096117, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 5 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[1. 0. 2. 3. 0. 1. 2. 3.]\n",
            "fit_time  \t [764.0089955329895, 622.0816934108734, 670.3908445835114, 926.4546639919281]\n",
            "score_time  \t [9.846307754516602, 16.16274094581604, 14.770983457565308, 5.744349002838135]\n",
            "test_accuracy  \t [0.41232916545507414, 0.592019687115486, 0.5265323346344551, 0.5007923930269413]\n",
            "test_f1_macro  \t [0.425629330041274, 0.6179135041535164, 0.5543308593096117, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 6 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[1. 0. 2. 3. 3. 0. 1. 2.]\n",
            "fit_time  \t [765.5893552303314, 617.773841381073, 682.2999284267426, 927.5779535770416]\n",
            "score_time  \t [10.695679903030396, 16.541457176208496, 14.313755750656128, 4.174077033996582]\n",
            "test_accuracy  \t [0.4828556806550665, 0.592019687115486, 0.5247232472324723, 0.33497536945812806]\n",
            "test_f1_macro  \t [0.4336768206032479, 0.6179135041535164, 0.5525837013131806, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 7 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[1. 0. 2. 3. 2. 3. 0. 1.]\n",
            "fit_time  \t [759.9251763820648, 613.416412115097, 710.8822493553162, 894.4576001167297]\n",
            "score_time  \t [11.57257628440857, 16.142223596572876, 13.160264015197754, 5.32556414604187]\n",
            "test_accuracy  \t [0.4828556806550665, 0.5914441321152495, 0.46832923545252314, 0.5]\n",
            "test_f1_macro  \t [0.4336768206032479, 0.6169760723162696, 0.5473398170756133, 0.25]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 8 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "[1. 0. 2. 3. 1. 2. 3. 0.]\n",
            "fit_time  \t [735.4236149787903, 651.9803974628448, 678.8447127342224, 942.6151835918427]\n",
            "score_time  \t [11.215379238128662, 15.461270332336426, 15.181412935256958, 5.349697828292847]\n",
            "test_accuracy  \t [0.48580925594477115, 0.5546934865900384, 0.5265323346344551, 0.5]\n",
            "test_f1_macro  \t [0.4389838997220735, 0.6163016996962689, 0.5543308593096117, 0.25]\n",
            "#################### \n",
            "### Usual K-Fold ###\n",
            "####################\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 1 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [728.3688604831696, 728.5484855175018, 725.0896894931793, 733.7354202270508]\n",
            "score_time  \t [10.756197690963745, 10.76442575454712, 11.0405592918396, 10.629786491394043]\n",
            "test_accuracy  \t [0.9755107219895952, 0.9769035532994924, 0.9761421319796955, 0.9758883248730964]\n",
            "test_f1_macro  \t [0.9750100163098502, 0.9766312932169634, 0.9759002868957865, 0.975402551870152]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 2 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [719.8538820743561, 728.5595037937164, 738.5116610527039, 727.8740484714508]\n",
            "score_time  \t [11.218624114990234, 10.740236520767212, 10.610978841781616, 10.845949411392212]\n",
            "test_accuracy  \t [0.9781753584570486, 0.9757614213197969, 0.973730964467005, 0.9766497461928934]\n",
            "test_f1_macro  \t [0.9776391215259277, 0.9754716632613727, 0.973217862741773, 0.9759400089588204]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 3 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [726.5790066719055, 720.216379404068, 732.2647426128387, 725.2691900730133]\n",
            "score_time  \t [10.496066331863403, 11.02214765548706, 11.272179126739502, 10.697142362594604]\n",
            "test_accuracy  \t [0.9770333713995686, 0.9781725888324873, 0.9743654822335025, 0.975253807106599]\n",
            "test_f1_macro  \t [0.9765222066583543, 0.9773908469203578, 0.9743195125411902, 0.9749169631152503]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 4 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [733.8941993713379, 721.0124404430389, 727.4297304153442, 735.7344233989716]\n",
            "score_time  \t [10.200430393218994, 11.02916407585144, 10.681716442108154, 11.214634895324707]\n",
            "test_accuracy  \t [0.9734805227762974, 0.9791878172588833, 0.974746192893401, 0.976015228426396]\n",
            "test_f1_macro  \t [0.9732238867832388, 0.9790692931727137, 0.9742445488167008, 0.9755607644306017]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 5 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [725.9787788391113, 726.9188942909241, 727.3137345314026, 729.080418586731]\n",
            "score_time  \t [11.041015386581421, 11.307126760482788, 11.15855598449707, 10.988754749298096]\n",
            "test_accuracy  \t [0.978556020809542, 0.975507614213198, 0.9739847715736041, 0.9774111675126903]\n",
            "test_f1_macro  \t [0.9780400141255576, 0.9750136068227571, 0.973424634602544, 0.977345159941363]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 6 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [723.6206300258636, 731.6461451053619, 726.1255886554718, 724.8016262054443]\n",
            "score_time  \t [10.683195352554321, 11.02449631690979, 10.355152606964111, 10.874788761138916]\n",
            "test_accuracy  \t [0.9748762847354396, 0.9799492385786802, 0.9746192893401016, 0.9758883248730964]\n",
            "test_f1_macro  \t [0.9745713708052005, 0.97928563305184, 0.9739392667532908, 0.975751061538334]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 7 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [730.149176120758, 725.0473318099976, 728.8503513336182, 722.9963755607605]\n",
            "score_time  \t [11.030939817428589, 11.208160400390625, 10.965575933456421, 10.428002119064331]\n",
            "test_accuracy  \t [0.978556020809542, 0.9739847715736041, 0.9766497461928934, 0.9748730964467005]\n",
            "test_f1_macro  \t [0.9783341615638476, 0.973178315942647, 0.9763174885648577, 0.9744726021219325]\n",
            "@@@@@@@@@@@@@@@ \n",
            "@@@ Round 8 @@@\n",
            "@@@@@@@@@@@@@@@\n",
            "fit_time  \t [723.5610783100128, 724.8882298469543, 724.0802819728851, 732.528906583786]\n",
            "score_time  \t [11.598265171051025, 10.598701238632202, 10.86284852027893, 10.77733564376831]\n",
            "test_accuracy  \t [0.9751300596371019, 0.9771573604060914, 0.9771573604060914, 0.9727157360406091]\n",
            "test_f1_macro  \t [0.9742024251293476, 0.9767661039657415, 0.9768056728608541, 0.9724520800503828]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJ-qe0MIhM-z",
        "colab_type": "text"
      },
      "source": [
        "##Save results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrp8uvOonKpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed6a2436-5af7-41d5-ccca-7682baeab2b1"
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "clf = {}\n",
        "val = {}\n",
        "src = {}\n",
        "for c, clf_name in enumerate(scores.keys()):\n",
        "  if c not in clf:\n",
        "    clf[c] = clf_name\n",
        "  for v, val_name in enumerate(scores[clf_name].keys()):\n",
        "    if v not in val:\n",
        "      val[v] = val_name\n",
        "    for s, scr_name in enumerate(scores[clf_name][val_name].keys()):\n",
        "      scores[clf_name][val_name][scr_name] = np.array(scores[clf_name][val_name][scr_name])\n",
        "      if s not in src:\n",
        "        src[s] = scr_name\n",
        "      Path(dirres).mkdir(parents=True, exist_ok=True)\n",
        "      np.savetxt('{}/{}-{}-{}.txt'.format(dirres,clf_name,val_name,scr_name), \n",
        "                 scores[clf_name][val_name][scr_name], delimiter=',')\n",
        "      print('{}/{} - {} - {}\\n'.format(dirres,clf_name.split('-')[0],val_name,scr_name),\n",
        "            scores[clf_name][val_name][scr_name])\n"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cwru_knn/KNN  - By Load - fit_time\n",
            " [[659.51900864 705.93309879 700.78282905 708.47170949]]\n",
            "cwru_knn/KNN  - By Load - score_time\n",
            " [[10.35792041 10.94090676 10.93019104 10.9418869 ]]\n",
            "cwru_knn/KNN  - By Load - test_accuracy\n",
            " [[0.93998367 0.96138565 0.94401688 0.94319732]]\n",
            "cwru_knn/KNN  - By Load - test_f1_macro\n",
            " [[0.94593657 0.95997728 0.94286459 0.94149318]]\n",
            "cwru_knn/KNN  - By Severity - fit_time\n",
            " [[622.13311124 713.11968112 655.96717691 874.14453459]\n",
            " [602.95090103 711.84601068 687.60244918 976.96885514]\n",
            " [629.67633224 727.37331891 705.88327456 911.99639964]\n",
            " [626.67069459 766.97330666 677.34492517 903.8308723 ]\n",
            " [764.00899553 622.08169341 670.39084458 926.45466399]\n",
            " [765.58935523 617.77384138 682.29992843 927.57795358]\n",
            " [759.92517638 613.41641212 710.88224936 894.45760012]\n",
            " [735.42361498 651.98039746 678.84471273 942.61518359]]\n",
            "cwru_knn/KNN  - By Severity - score_time\n",
            " [[14.74435973 10.46434855 14.57827234  5.23300004]\n",
            " [15.71648097 10.89102054 15.30472732  4.14733481]\n",
            " [16.76324058 10.98728251 13.67546248  5.2711041 ]\n",
            " [16.34688592  9.56124973 14.70200658  5.39316559]\n",
            " [ 9.84630775 16.16274095 14.77098346  5.744349  ]\n",
            " [10.6956799  16.54145718 14.31375575  4.17407703]\n",
            " [11.57257628 16.1422236  13.16026402  5.32556415]\n",
            " [11.21537924 15.46127033 15.18141294  5.34969783]]\n",
            "cwru_knn/KNN  - By Severity - test_accuracy\n",
            " [[0.55469349 0.48285568 0.52653233 0.50079239]\n",
            " [0.59201969 0.48285568 0.52472325 0.33497537]\n",
            " [0.59201969 0.48580926 0.46832924 0.5       ]\n",
            " [0.59144413 0.41232917 0.52653233 0.5       ]\n",
            " [0.41232917 0.59201969 0.52653233 0.50079239]\n",
            " [0.48285568 0.59201969 0.52472325 0.33497537]\n",
            " [0.48285568 0.59144413 0.46832924 0.5       ]\n",
            " [0.48580926 0.55469349 0.52653233 0.5       ]]\n",
            "cwru_knn/KNN  - By Severity - test_f1_macro\n",
            " [[0.6163017  0.43367682 0.55433086 0.25      ]\n",
            " [0.6179135  0.43367682 0.5525837  0.25      ]\n",
            " [0.6179135  0.4389839  0.54733982 0.25      ]\n",
            " [0.61697607 0.42562933 0.55433086 0.25      ]\n",
            " [0.42562933 0.6179135  0.55433086 0.25      ]\n",
            " [0.43367682 0.6179135  0.5525837  0.25      ]\n",
            " [0.43367682 0.61697607 0.54733982 0.25      ]\n",
            " [0.4389839  0.6163017  0.55433086 0.25      ]]\n",
            "cwru_knn/KNN  - Usual K-Fold - fit_time\n",
            " [[728.36886048 728.54848552 725.08968949 733.73542023]\n",
            " [719.85388207 728.55950379 738.51166105 727.87404847]\n",
            " [726.57900667 720.2163794  732.26474261 725.26919007]\n",
            " [733.89419937 721.01244044 727.42973042 735.7344234 ]\n",
            " [725.97877884 726.91889429 727.31373453 729.08041859]\n",
            " [723.62063003 731.64614511 726.12558866 724.80162621]\n",
            " [730.14917612 725.04733181 728.85035133 722.99637556]\n",
            " [723.56107831 724.88822985 724.08028197 732.52890658]]\n",
            "cwru_knn/KNN  - Usual K-Fold - score_time\n",
            " [[10.75619769 10.76442575 11.04055929 10.62978649]\n",
            " [11.21862411 10.74023652 10.61097884 10.84594941]\n",
            " [10.49606633 11.02214766 11.27217913 10.69714236]\n",
            " [10.20043039 11.02916408 10.68171644 11.2146349 ]\n",
            " [11.04101539 11.30712676 11.15855598 10.98875475]\n",
            " [10.68319535 11.02449632 10.35515261 10.87478876]\n",
            " [11.03093982 11.2081604  10.96557593 10.42800212]\n",
            " [11.59826517 10.59870124 10.86284852 10.77733564]]\n",
            "cwru_knn/KNN  - Usual K-Fold - test_accuracy\n",
            " [[0.97551072 0.97690355 0.97614213 0.97588832]\n",
            " [0.97817536 0.97576142 0.97373096 0.97664975]\n",
            " [0.97703337 0.97817259 0.97436548 0.97525381]\n",
            " [0.97348052 0.97918782 0.97474619 0.97601523]\n",
            " [0.97855602 0.97550761 0.97398477 0.97741117]\n",
            " [0.97487628 0.97994924 0.97461929 0.97588832]\n",
            " [0.97855602 0.97398477 0.97664975 0.9748731 ]\n",
            " [0.97513006 0.97715736 0.97715736 0.97271574]]\n",
            "cwru_knn/KNN  - Usual K-Fold - test_f1_macro\n",
            " [[0.97501002 0.97663129 0.97590029 0.97540255]\n",
            " [0.97763912 0.97547166 0.97321786 0.97594001]\n",
            " [0.97652221 0.97739085 0.97431951 0.97491696]\n",
            " [0.97322389 0.97906929 0.97424455 0.97556076]\n",
            " [0.97804001 0.97501361 0.97342463 0.97734516]\n",
            " [0.97457137 0.97928563 0.97393927 0.97575106]\n",
            " [0.97833416 0.97317832 0.97631749 0.9744726 ]\n",
            " [0.97420243 0.9767661  0.97680567 0.97245208]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkb8XMN-Ht58",
        "colab_type": "text"
      },
      "source": [
        "##Average & Standard Deviation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJxdjboqtuNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "dc0e8bb8-5829-42ce-8ebf-43d5106aff17"
      },
      "source": [
        "c,v,s = len(clf),len(val),len(src)\n",
        "for i in range(s):\n",
        "  print(src[i])\n",
        "  for k in range(v):\n",
        "    print('\\t'+val[k]+' ', end='')\n",
        "  print()\n",
        "  for j in range(c):\n",
        "    print(clf[j].split('-')[0], end='\\t')\n",
        "    for k in range(v):\n",
        "      print(\"{0:.3f} ({1:.3f})\".format(\n",
        "          scores[clf[j]][val[k]][src[i]].mean(),\n",
        "          scores[clf[j]][val[k]][src[i]].std()), end='\\t')\n",
        "    print()\n",
        "  print()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fit_time\n",
            "\tBy Load \tBy Severity \tUsual K-Fold \n",
            "KNN \t693.677 (19.915)\t742.444 (112.813)\t727.517 (4.334)\t\n",
            "\n",
            "score_time\n",
            "\tBy Load \tBy Severity \tUsual K-Fold \n",
            "KNN \t10.793 (0.251)\t11.545 (4.253)\t10.879 (0.301)\t\n",
            "\n",
            "test_accuracy\n",
            "\tBy Load \tBy Severity \tUsual K-Fold \n",
            "KNN \t0.947 (0.008)\t0.505 (0.065)\t0.976 (0.002)\t\n",
            "\n",
            "test_f1_macro\n",
            "\tBy Load \tBy Severity \tUsual K-Fold \n",
            "KNN \t0.948 (0.007)\t0.463 (0.140)\t0.976 (0.002)\t\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZG2ZnLQAeJL",
        "colab_type": "text"
      },
      "source": [
        "## Experiment results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "manFfTfh_9Ta",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "********************************************************** \n",
        "*** KNN - KNeighborsClassifier, Heterogeneous Features ***\n",
        "**********************************************************\n",
        "############### \n",
        "### By Load ###\n",
        "###############\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 1 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [659.5190086364746, 705.9330987930298, 700.7828290462494, 708.4717094898224]\n",
        "score_time  \t [10.357920408248901, 10.940906763076782, 10.930191040039062, 10.941886901855469]\n",
        "test_accuracy  \t [0.9399836690255852, 0.9613856468835361, 0.9440168818272096, 0.9431973210963661]\n",
        "test_f1_macro  \t [0.9459365719549166, 0.9599772834892515, 0.9428645854817683, 0.9414931800564585]\n",
        "################### \n",
        "### By Severity ###\n",
        "###################\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 1 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[0. 1. 2. 3. 0. 1. 2. 3.]\n",
        "fit_time  \t [622.1331112384796, 713.1196811199188, 655.9671769142151, 874.1445345878601]\n",
        "score_time  \t [14.744359731674194, 10.464348554611206, 14.578272342681885, 5.233000040054321]\n",
        "test_accuracy  \t [0.5546934865900384, 0.4828556806550665, 0.5265323346344551, 0.5007923930269413]\n",
        "test_f1_macro  \t [0.6163016996962689, 0.4336768206032479, 0.5543308593096117, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 2 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[0. 1. 2. 3. 3. 0. 1. 2.]\n",
        "fit_time  \t [602.9509010314941, 711.846010684967, 687.6024491786957, 976.9688551425934]\n",
        "score_time  \t [15.71648097038269, 10.89102053642273, 15.30472731590271, 4.147334814071655]\n",
        "test_accuracy  \t [0.592019687115486, 0.4828556806550665, 0.5247232472324723, 0.33497536945812806]\n",
        "test_f1_macro  \t [0.6179135041535164, 0.4336768206032479, 0.5525837013131806, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 3 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[0. 1. 2. 3. 2. 3. 0. 1.]\n",
        "fit_time  \t [629.6763322353363, 727.3733189105988, 705.8832745552063, 911.996399641037]\n",
        "score_time  \t [16.763240575790405, 10.987282514572144, 13.675462484359741, 5.271104097366333]\n",
        "test_accuracy  \t [0.592019687115486, 0.48580925594477115, 0.46832923545252314, 0.5]\n",
        "test_f1_macro  \t [0.6179135041535164, 0.4389838997220735, 0.5473398170756133, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 4 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[0. 1. 2. 3. 1. 2. 3. 0.]\n",
        "fit_time  \t [626.6706945896149, 766.9733066558838, 677.3449251651764, 903.830872297287]\n",
        "score_time  \t [16.346885919570923, 9.561249732971191, 14.702006578445435, 5.393165588378906]\n",
        "test_accuracy  \t [0.5914441321152495, 0.41232916545507414, 0.5265323346344551, 0.5]\n",
        "test_f1_macro  \t [0.6169760723162696, 0.425629330041274, 0.5543308593096117, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 5 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[1. 0. 2. 3. 0. 1. 2. 3.]\n",
        "fit_time  \t [764.0089955329895, 622.0816934108734, 670.3908445835114, 926.4546639919281]\n",
        "score_time  \t [9.846307754516602, 16.16274094581604, 14.770983457565308, 5.744349002838135]\n",
        "test_accuracy  \t [0.41232916545507414, 0.592019687115486, 0.5265323346344551, 0.5007923930269413]\n",
        "test_f1_macro  \t [0.425629330041274, 0.6179135041535164, 0.5543308593096117, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 6 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[1. 0. 2. 3. 3. 0. 1. 2.]\n",
        "fit_time  \t [765.5893552303314, 617.773841381073, 682.2999284267426, 927.5779535770416]\n",
        "score_time  \t [10.695679903030396, 16.541457176208496, 14.313755750656128, 4.174077033996582]\n",
        "test_accuracy  \t [0.4828556806550665, 0.592019687115486, 0.5247232472324723, 0.33497536945812806]\n",
        "test_f1_macro  \t [0.4336768206032479, 0.6179135041535164, 0.5525837013131806, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 7 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[1. 0. 2. 3. 2. 3. 0. 1.]\n",
        "fit_time  \t [759.9251763820648, 613.416412115097, 710.8822493553162, 894.4576001167297]\n",
        "score_time  \t [11.57257628440857, 16.142223596572876, 13.160264015197754, 5.32556414604187]\n",
        "test_accuracy  \t [0.4828556806550665, 0.5914441321152495, 0.46832923545252314, 0.5]\n",
        "test_f1_macro  \t [0.4336768206032479, 0.6169760723162696, 0.5473398170756133, 0.25]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 8 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "[1. 0. 2. 3. 1. 2. 3. 0.]\n",
        "fit_time  \t [735.4236149787903, 651.9803974628448, 678.8447127342224, 942.6151835918427]\n",
        "score_time  \t [11.215379238128662, 15.461270332336426, 15.181412935256958, 5.349697828292847]\n",
        "test_accuracy  \t [0.48580925594477115, 0.5546934865900384, 0.5265323346344551, 0.5]\n",
        "test_f1_macro  \t [0.4389838997220735, 0.6163016996962689, 0.5543308593096117, 0.25]\n",
        "#################### \n",
        "### Usual K-Fold ###\n",
        "####################\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 1 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [728.3688604831696, 728.5484855175018, 725.0896894931793, 733.7354202270508]\n",
        "score_time  \t [10.756197690963745, 10.76442575454712, 11.0405592918396, 10.629786491394043]\n",
        "test_accuracy  \t [0.9755107219895952, 0.9769035532994924, 0.9761421319796955, 0.9758883248730964]\n",
        "test_f1_macro  \t [0.9750100163098502, 0.9766312932169634, 0.9759002868957865, 0.975402551870152]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 2 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [719.8538820743561, 728.5595037937164, 738.5116610527039, 727.8740484714508]\n",
        "score_time  \t [11.218624114990234, 10.740236520767212, 10.610978841781616, 10.845949411392212]\n",
        "test_accuracy  \t [0.9781753584570486, 0.9757614213197969, 0.973730964467005, 0.9766497461928934]\n",
        "test_f1_macro  \t [0.9776391215259277, 0.9754716632613727, 0.973217862741773, 0.9759400089588204]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 3 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [726.5790066719055, 720.216379404068, 732.2647426128387, 725.2691900730133]\n",
        "score_time  \t [10.496066331863403, 11.02214765548706, 11.272179126739502, 10.697142362594604]\n",
        "test_accuracy  \t [0.9770333713995686, 0.9781725888324873, 0.9743654822335025, 0.975253807106599]\n",
        "test_f1_macro  \t [0.9765222066583543, 0.9773908469203578, 0.9743195125411902, 0.9749169631152503]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 4 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [733.8941993713379, 721.0124404430389, 727.4297304153442, 735.7344233989716]\n",
        "score_time  \t [10.200430393218994, 11.02916407585144, 10.681716442108154, 11.214634895324707]\n",
        "test_accuracy  \t [0.9734805227762974, 0.9791878172588833, 0.974746192893401, 0.976015228426396]\n",
        "test_f1_macro  \t [0.9732238867832388, 0.9790692931727137, 0.9742445488167008, 0.9755607644306017]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 5 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [725.9787788391113, 726.9188942909241, 727.3137345314026, 729.080418586731]\n",
        "score_time  \t [11.041015386581421, 11.307126760482788, 11.15855598449707, 10.988754749298096]\n",
        "test_accuracy  \t [0.978556020809542, 0.975507614213198, 0.9739847715736041, 0.9774111675126903]\n",
        "test_f1_macro  \t [0.9780400141255576, 0.9750136068227571, 0.973424634602544, 0.977345159941363]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 6 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [723.6206300258636, 731.6461451053619, 726.1255886554718, 724.8016262054443]\n",
        "score_time  \t [10.683195352554321, 11.02449631690979, 10.355152606964111, 10.874788761138916]\n",
        "test_accuracy  \t [0.9748762847354396, 0.9799492385786802, 0.9746192893401016, 0.9758883248730964]\n",
        "test_f1_macro  \t [0.9745713708052005, 0.97928563305184, 0.9739392667532908, 0.975751061538334]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 7 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [730.149176120758, 725.0473318099976, 728.8503513336182, 722.9963755607605]\n",
        "score_time  \t [11.030939817428589, 11.208160400390625, 10.965575933456421, 10.428002119064331]\n",
        "test_accuracy  \t [0.978556020809542, 0.9739847715736041, 0.9766497461928934, 0.9748730964467005]\n",
        "test_f1_macro  \t [0.9783341615638476, 0.973178315942647, 0.9763174885648577, 0.9744726021219325]\n",
        "@@@@@@@@@@@@@@@ \n",
        "@@@ Round 8 @@@\n",
        "@@@@@@@@@@@@@@@\n",
        "fit_time  \t [723.5610783100128, 724.8882298469543, 724.0802819728851, 732.528906583786]\n",
        "score_time  \t [11.598265171051025, 10.598701238632202, 10.86284852027893, 10.77733564376831]\n",
        "test_accuracy  \t [0.9751300596371019, 0.9771573604060914, 0.9771573604060914, 0.9727157360406091]\n",
        "test_f1_macro  \t [0.9742024251293476, 0.9767661039657415, 0.9768056728608541, 0.9724520800503828]\n",
        "```\n",
        "\n"
      ]
    }
  ]
}