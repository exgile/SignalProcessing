{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cwru-evaluation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fboldt/cwru-conv1d/blob/master/cwru_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Con6WhcSFxxm",
        "colab_type": "text"
      },
      "source": [
        "# CWRU files.\n",
        "\n",
        "Associate each Matlab file name to a bearing condition in a Python dictionary.\n",
        "The dictionary keys identify the conditions.\n",
        "\n",
        "There are only four normal conditions, with loads of 0, 1, 2 and 3 hp.\n",
        "All conditions end with an underscore character followed by an algarism representing the load applied during the acquisitions.\n",
        "The remaining conditions follow the pattern:\n",
        "\n",
        "\n",
        "* First two characters represent the bearing location, i.e. drive end (DE) and fan end (FE).\n",
        "* The following two characters represent the failure location in the bearing, i.e. ball (BA), Inner Race (IR) and Outer Race (OR).\n",
        "* The next three algarisms indicate the severity of the failure, where 007 stands for 0.007 inches and 0021 for 0.021 inches.\n",
        "* For Outer Race failures, the character @ is followed by a number that indicates different load zones. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSt7Dc1-nzQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "debug = False\n",
        "aquisitions = {}\n",
        "# Normal\n",
        "aquisitions[\"Normal_0\"] = \"97.mat\"\n",
        "aquisitions[\"Normal_1\"] = \"98.mat\"\n",
        "aquisitions[\"Normal_2\"] = \"99.mat\"\n",
        "aquisitions[\"Normal_3\"] = \"100.mat\"\n",
        "# DE Inner Race 0.007 inches\n",
        "aquisitions[\"DEIR007_0\"] = \"105.mat\"\n",
        "aquisitions[\"DEIR007_1\"] = \"106.mat\"\n",
        "aquisitions[\"DEIR007_2\"] = \"107.mat\"\n",
        "aquisitions[\"DEIR007_3\"] = \"108.mat\"\n",
        "# DE Inner Race 0.014 inches\n",
        "aquisitions[\"DEIR014_0\"] = \"169.mat\"\n",
        "aquisitions[\"DEIR014_1\"] = \"170.mat\"\n",
        "aquisitions[\"DEIR014_2\"] = \"171.mat\"\n",
        "aquisitions[\"DEIR014_3\"] = \"172.mat\"\n",
        "if not debug:\n",
        "  # DE Inner Race 0.021 inches\n",
        "  aquisitions[\"DEIR021_0\"] = \"209.mat\"\n",
        "  aquisitions[\"DEIR021_1\"] = \"210.mat\"\n",
        "  aquisitions[\"DEIR021_2\"] = \"211.mat\"\n",
        "  aquisitions[\"DEIR021_3\"] = \"212.mat\"\n",
        "  # DE Ball 0.007 inches\n",
        "  aquisitions[\"DEB007_0\"] = \"118.mat\"\n",
        "  aquisitions[\"DEB007_1\"] = \"119.mat\"\n",
        "  aquisitions[\"DEB007_2\"] = \"120.mat\"\n",
        "  aquisitions[\"DEB007_3\"] = \"121.mat\"\n",
        "  # DE Ball 0.014 inches\n",
        "  aquisitions[\"DEB014_0\"] = \"185.mat\"\n",
        "  aquisitions[\"DEB014_1\"] = \"186.mat\"\n",
        "  aquisitions[\"DEB014_2\"] = \"187.mat\"\n",
        "  aquisitions[\"DEB014_3\"] = \"188.mat\"\n",
        "  # DE Ball 0.021 inches\n",
        "  aquisitions[\"DEB021_0\"] = \"222.mat\"\n",
        "  aquisitions[\"DEB021_1\"] = \"223.mat\"\n",
        "  aquisitions[\"DEB021_2\"] = \"224.mat\"\n",
        "  aquisitions[\"DEB021_3\"] = \"225.mat\"\n",
        "  # DE Outer race 0.007 inches centered @6:00\n",
        "  aquisitions[\"DEOR007@6_0\"] = \"130.mat\"\n",
        "  aquisitions[\"DEOR007@6_1\"] = \"131.mat\"\n",
        "  aquisitions[\"DEOR007@6_2\"] = \"132.mat\"\n",
        "  aquisitions[\"DEOR007@6_3\"] = \"133.mat\"\n",
        "  # DE Outer race 0.014 inches centered @6:00\n",
        "  aquisitions[\"DEOR014@6_0\"] = \"197.mat\"\n",
        "  aquisitions[\"DEOR014@6_1\"] = \"198.mat\"\n",
        "  aquisitions[\"DEOR014@6_2\"] = \"199.mat\"\n",
        "  aquisitions[\"DEOR014@6_3\"] = \"200.mat\"\n",
        "  # DE Outer race 0.021 inches centered @6:00\n",
        "  aquisitions[\"DEOR021@6_0\"] = \"234.mat\"\n",
        "  aquisitions[\"DEOR021@6_1\"] = \"235.mat\"\n",
        "  aquisitions[\"DEOR021@6_2\"] = \"236.mat\"\n",
        "  aquisitions[\"DEOR021@6_3\"] = \"237.mat\"\n",
        "  # DE Outer race 0.007 inches centered @3:00\n",
        "  aquisitions[\"DEOR007@3_0\"] = \"144.mat\"\n",
        "  aquisitions[\"DEOR007@3_1\"] = \"145.mat\"\n",
        "  aquisitions[\"DEOR007@3_2\"] = \"146.mat\"\n",
        "  aquisitions[\"DEOR007@3_3\"] = \"147.mat\"\n",
        "  # DE Outer race 0.021 inches centered @3:00\n",
        "  aquisitions[\"DEOR021@3_0\"] = \"246.mat\"\n",
        "  aquisitions[\"DEOR021@3_1\"] = \"247.mat\"\n",
        "  aquisitions[\"DEOR021@3_2\"] = \"248.mat\"\n",
        "  aquisitions[\"DEOR021@3_3\"] = \"249.mat\"\n",
        "  # DE Outer race 0.007 inches centered @12:00\n",
        "  aquisitions[\"DEOR007@12_0\"] = \"156.mat\"\n",
        "  aquisitions[\"DEOR007@12_1\"] = \"158.mat\"\n",
        "  aquisitions[\"DEOR007@12_2\"] = \"159.mat\"\n",
        "  aquisitions[\"DEOR007@12_3\"] = \"160.mat\"\n",
        "  # DE Outer race 0.021 inches centered @12:00\n",
        "  aquisitions[\"DEOR021@12_0\"] = \"258.mat\"\n",
        "  aquisitions[\"DEOR021@12_1\"] = \"259.mat\"\n",
        "  aquisitions[\"DEOR021@12_2\"] = \"260.mat\"\n",
        "  aquisitions[\"DEOR021@12_3\"] = \"261.mat\"\n",
        "  # FE Inner Race 0.007 inches\n",
        "  aquisitions[\"FEIR007_0\"] = \"278.mat\"\n",
        "  aquisitions[\"FEIR007_1\"] = \"279.mat\"\n",
        "  aquisitions[\"FEIR007_2\"] = \"280.mat\"\n",
        "  aquisitions[\"FEIR007_3\"] = \"281.mat\"\n",
        "  # FE Inner Race 0.014 inches\n",
        "  aquisitions[\"FEIR014_0\"] = \"274.mat\"\n",
        "  aquisitions[\"FEIR014_1\"] = \"275.mat\"\n",
        "  aquisitions[\"FEIR014_2\"] = \"276.mat\"\n",
        "  aquisitions[\"FEIR014_3\"] = \"277.mat\"\n",
        "  # FE Inner Race 0.021 inches\n",
        "  aquisitions[\"FEIR021_0\"] = \"270.mat\"\n",
        "  aquisitions[\"FEIR021_1\"] = \"271.mat\"\n",
        "  aquisitions[\"FEIR021_2\"] = \"272.mat\"\n",
        "  aquisitions[\"FEIR021_3\"] = \"273.mat\"\n",
        "  # FE Ball 0.007 inches\n",
        "  aquisitions[\"FEB007_0\"] = \"282.mat\"\n",
        "  aquisitions[\"FEB007_1\"] = \"283.mat\"\n",
        "  aquisitions[\"FEB007_2\"] = \"284.mat\"\n",
        "  aquisitions[\"FEB007_3\"] = \"285.mat\"\n",
        "  # FE Ball 0.014 inches\n",
        "  aquisitions[\"FEB014_0\"] = \"286.mat\"\n",
        "  aquisitions[\"FEB014_1\"] = \"287.mat\"\n",
        "  aquisitions[\"FEB014_2\"] = \"288.mat\"\n",
        "  aquisitions[\"FEB014_3\"] = \"289.mat\"\n",
        "  # FE Ball 0.021 inches\n",
        "  aquisitions[\"FEB021_0\"] = \"290.mat\"\n",
        "  aquisitions[\"FEB021_1\"] = \"291.mat\"\n",
        "  aquisitions[\"FEB021_2\"] = \"292.mat\"\n",
        "  aquisitions[\"FEB021_3\"] = \"293.mat\"\n",
        "  # FE Outer race 0.007 inches centered @6:00\n",
        "  aquisitions[\"FEOR007@6_0\"] = \"294.mat\"\n",
        "  aquisitions[\"FEOR007@6_1\"] = \"295.mat\"\n",
        "  aquisitions[\"FEOR007@6_2\"] = \"296.mat\"\n",
        "  aquisitions[\"FEOR007@6_3\"] = \"297.mat\"\n",
        "  # FE Outer race 0.007 inches centered @3:00\n",
        "  aquisitions[\"FEOR007@3_0\"] = \"298.mat\"\n",
        "  aquisitions[\"FEOR007@3_1\"] = \"299.mat\"\n",
        "  aquisitions[\"FEOR007@3_2\"] = \"300.mat\"\n",
        "  aquisitions[\"FEOR007@3_3\"] = \"301.mat\"\n",
        "  # FE Outer race 0.014 inches centered @3:00\n",
        "  aquisitions[\"FEOR014@3_0\"] = \"310.mat\"\n",
        "  aquisitions[\"FEOR014@3_1\"] = \"309.mat\"\n",
        "  aquisitions[\"FEOR014@3_2\"] = \"311.mat\"\n",
        "  aquisitions[\"FEOR014@3_3\"] = \"312.mat\"\n",
        "  # FE Outer race 0.007 inches centered @12:00\n",
        "  aquisitions[\"FEOR007@12_0\"] = \"302.mat\"\n",
        "  aquisitions[\"FEOR007@12_1\"] = \"305.mat\"\n",
        "  aquisitions[\"FEOR007@12_2\"] = \"306.mat\"\n",
        "  aquisitions[\"FEOR007@12_3\"] = \"307.mat\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_4WiLNSyrMB",
        "colab_type": "text"
      },
      "source": [
        "#Functions definitions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHDI4LWbyoP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_labels_dict(aquisitions):\n",
        "  \"\"\"Generate a dictionary linking the labels with values to keep consistence.\"\"\"\n",
        "  labels_dict = {}\n",
        "  value = 0\n",
        "  for key in aquisitions.keys():\n",
        "    label = key.split('_')[0]\n",
        "    if not label in labels_dict:\n",
        "      labels_dict[label] = value\n",
        "      value += 1\n",
        "  return labels_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Rz0cKigF7q6",
        "colab_type": "text"
      },
      "source": [
        "Convert Matlab file into tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tn5IFqkCHQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "import numpy as np\n",
        "# size of each segment\n",
        "sample_size = 1024 #512\n",
        "def aquisition2tensor(file_name, sample_size=sample_size):\n",
        "  \"\"\"\n",
        "  Convert Matlab file into tensors.\n",
        "  The file is divided in segments of sample_size values.\n",
        "  \"\"\"\n",
        "  print(file_name, end=' ')\n",
        "  matlab_file = scipy.io.loadmat(file_name)\n",
        "  DE_time = [key for key in matlab_file if key.endswith(\"DE_time\")][0] #Find the DRIVE END aquisition key name\n",
        "  FE_time = [key for key in matlab_file if key.endswith(\"FE_time\")][0] #Find the FAN END aquisition key name\n",
        "  signal_begin = 0\n",
        "  aquisition_size = max(len(matlab_file[DE_time]),len(matlab_file[FE_time]))\n",
        "  DE_samples = []\n",
        "  FE_samples = []\n",
        "  #signal segmentation\n",
        "  while signal_begin + sample_size < aquisition_size:\n",
        "    DE_samples.append([item for sublist in matlab_file[DE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    FE_samples.append([item for sublist in matlab_file[FE_time][signal_begin:signal_begin+sample_size] for item in sublist])\n",
        "    signal_begin += sample_size\n",
        "  sample_tensor = np.stack([DE_samples,FE_samples],axis=2).astype('float32')\n",
        "  return sample_tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-G4gjyuvA7a",
        "colab_type": "text"
      },
      "source": [
        "Extract datasets from aquisitions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC4rhGwWMKT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concatenate_datasets(xd,yd,xo,yo):\n",
        "  \"\"\"\n",
        "  xd: destination patterns tensor\n",
        "  yd: destination labels tensor\n",
        "  xo: origin patterns tensor to be concateneted \n",
        "  yo: origin labels tensor to be concateneted \n",
        "  \"\"\"\n",
        "  if xd is None or yd is None:\n",
        "    xd = xo\n",
        "    yd = yo\n",
        "  else:\n",
        "    xd = np.concatenate((xd,xo))\n",
        "    yd = np.concatenate((yd,yo))\n",
        "  return xd,yd\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def aquisitions_from_load(load, aquisitions, labels_dict,\n",
        "                          url=\"http://csegroups.case.edu/sites/default/files/bearingdatacenter/files/Datafiles/\"\n",
        "                         ):\n",
        "  \"\"\"\n",
        "  Extract samples from all files with some load.\n",
        "  \"\"\"\n",
        "  samples = None\n",
        "  labels = None\n",
        "  for key in aquisitions:\n",
        "    if key.endswith(\"_\"+str(load)):\n",
        "      file_name = aquisitions[key]\n",
        "      urllib.request.urlretrieve(url+file_name, file_name)\n",
        "      aquisition_samples = aquisition2tensor(file_name)\n",
        "      aquisition_labels = np.ones(aquisition_samples.shape[0])*labels_dict[key.split('_')[0]]\n",
        "      samples,labels = concatenate_datasets(samples,labels,aquisition_samples,aquisition_labels)\n",
        "  print(load)\n",
        "  return samples,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0xe9oYrW1lv",
        "colab_type": "text"
      },
      "source": [
        "Define function to plot the confusion matrices."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ut28C6NjT8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab import files\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Greys):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    #plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfwmQa0RJMvb",
        "colab_type": "text"
      },
      "source": [
        "#Downloading and Matlab files\n",
        "Extract samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSASqQsHcgtj",
        "colab_type": "code",
        "outputId": "dc892e49-10ce-4f86-8b11-7722de83c8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "labels_dict = get_labels_dict(aquisitions)\n",
        "print(labels_dict)\n",
        "x0,y0 = aquisitions_from_load(0,aquisitions,labels_dict)\n",
        "x1,y1 = aquisitions_from_load(1,aquisitions,labels_dict)\n",
        "x2,y2 = aquisitions_from_load(2,aquisitions,labels_dict)\n",
        "x3,y3 = aquisitions_from_load(3,aquisitions,labels_dict)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Normal': 0, 'DEIR007': 1, 'DEIR014': 2, 'DEIR021': 3, 'DEB007': 4, 'DEB014': 5, 'DEB021': 6, 'DEOR007@6': 7, 'DEOR014@6': 8, 'DEOR021@6': 9, 'DEOR007@3': 10, 'DEOR021@3': 11, 'DEOR007@12': 12, 'DEOR021@12': 13, 'FEIR007': 14, 'FEIR014': 15, 'FEIR021': 16, 'FEB007': 17, 'FEB014': 18, 'FEB021': 19, 'FEOR007@6': 20, 'FEOR007@3': 21, 'FEOR014@3': 22, 'FEOR007@12': 23}\n",
            "97.mat 105.mat 169.mat 209.mat 118.mat 185.mat 222.mat 130.mat 197.mat 234.mat 144.mat 246.mat 156.mat 258.mat 278.mat 274.mat 270.mat 282.mat 286.mat 290.mat 294.mat 298.mat 310.mat 302.mat 0\n",
            "98.mat 106.mat 170.mat 210.mat 119.mat 186.mat 223.mat 131.mat 198.mat 235.mat 145.mat 247.mat 158.mat 259.mat 279.mat 275.mat 271.mat 283.mat 287.mat 291.mat 295.mat 299.mat 309.mat 305.mat 1\n",
            "99.mat 107.mat 171.mat 211.mat 120.mat 187.mat 224.mat 132.mat 199.mat 236.mat 146.mat 248.mat 159.mat 260.mat 280.mat 276.mat 272.mat 284.mat 288.mat 292.mat 296.mat 300.mat 311.mat 306.mat 2\n",
            "100.mat 108.mat 172.mat 212.mat 121.mat 188.mat 225.mat 133.mat 200.mat 237.mat 147.mat 249.mat 160.mat 261.mat 281.mat 277.mat 273.mat 285.mat 289.mat 293.mat 297.mat 301.mat 312.mat 307.mat 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOmONx8MmJHw",
        "colab_type": "text"
      },
      "source": [
        "#Feature Extraction Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Huvg2IdrcfuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import TransformerMixin\n",
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# roor mean square\n",
        "def rms(x):\n",
        "  x = np.array(x)\n",
        "  return np.sqrt(np.mean(np.square(x)))\n",
        "# square root amplitude\n",
        "def sra(x):\n",
        "  x = np.array(x)\n",
        "  return np.mean(np.sqrt(np.absolute(x)))**2\n",
        "# peak to peak value\n",
        "def ppv(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(x)-np.min(x)\n",
        "# crest factor\n",
        "def cf(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/rms(x)\n",
        "# impact factor\n",
        "def ifa(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/np.mean(np.absolute(x))\n",
        "# margin factor\n",
        "def mf(x):\n",
        "  x = np.array(x)\n",
        "  return np.max(np.absolute(x))/sra(x)\n",
        "# shape factor\n",
        "def sf(x):\n",
        "  x = np.array(x)\n",
        "  return rms(x)/np.mean(np.absolute(x))\n",
        "# kurtosis factor\n",
        "def kf(x):\n",
        "  x = np.array(x)\n",
        "  return stats.kurtosis(x)/(np.mean(x**2)**2)\n",
        "\n",
        "class StatisticalTime(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    de = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,0]])\n",
        "    fe = np.array([[rms(x), sra(x), stats.kurtosis(x), stats.skew(x), ppv(x), cf(x), ifa(x), mf(x), sf(x), kf(x)] for x in X[:,:,1]])\n",
        "    return np.concatenate((de,fe),axis=1)\n",
        "  \n",
        "class StatisticalFrequency(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    de = []\n",
        "    for x in X[:,:,0]:\n",
        "      fx = np.absolute(np.fft.fft(x))\n",
        "      fc = np.mean(fx)\n",
        "      de.append([fc, rms(fx), rms(fx-fc)])\n",
        "    de = np.array(de)\n",
        "    fe = []\n",
        "    for x in X[:,:,1]:\n",
        "      fx = np.absolute(np.fft.fft(x))\n",
        "      fc = np.mean(fx)\n",
        "      fe.append([fc, rms(fx), rms(fx-fc)])\n",
        "    fe = np.array(fe)\n",
        "    return np.concatenate((de,fe),axis=1)\n",
        "\n",
        "class Statistical(TransformerMixin):\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    st = StatisticalTime()\n",
        "    stfeats = st.transform(X)\n",
        "    sf = StatisticalFrequency()\n",
        "    sffeats = sf.transform(X)\n",
        "    return np.concatenate((stfeats,sffeats),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPLjBiao2GIK",
        "colab_type": "text"
      },
      "source": [
        "Define model architecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zp9rCYLc3Yq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn import metrics, svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "svm = Pipeline([('FeatureExtraction', Statistical()),\n",
        "                ('scaler', StandardScaler()),\n",
        "                ('SVM', svm.LinearSVC())])\n",
        "rf = Pipeline([('FeatureExtraction', Statistical()),\n",
        "               ('scaler', StandardScaler()),\n",
        "               ('RF', RandomForestClassifier())])\n",
        "\n",
        "clfs = [(\"LinearSVM\", svm),\n",
        "        (\"RandomForest\", rf)]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AA7KLli30vu_",
        "colab_type": "text"
      },
      "source": [
        "#Perform experiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTUqvMfR53OX",
        "colab_type": "text"
      },
      "source": [
        "##Permissive Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU0B-KF-W0eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "2cccce40-31e3-441d-fb16-6c932bba53ec"
      },
      "source": [
        "from sklearn.metrics import f1_score,accuracy_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.simplefilter(action='ignore', category=ConvergenceWarning)\n",
        "\n",
        "nrounds = 1 if debug else 3\n",
        "results = {}\n",
        "models = {}\n",
        "\n",
        "X,y = None,None\n",
        "for load in range(4):\n",
        "  X,y = concatenate_datasets(X,y,eval('x'+str(load)),eval('y'+str(load)))\n",
        "rskf = RepeatedStratifiedKFold(n_splits=4, n_repeats=nrounds, random_state=36851234)\n",
        "fold = 0\n",
        "count_round = 0\n",
        "\n",
        "results['permissive'] = {}\n",
        "models['permissive'] = {}\n",
        "\n",
        "print(\"Permissive Method\")\n",
        "for train_index, test_index in rskf.split(X, y):\n",
        "  print(\"{}/{}\".format(fold+1,rskf.get_n_splits()//nrounds), end=\" x \")\n",
        "  x_train, x_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  j = count_round//4\n",
        "  count_round += 1\n",
        "  print(\"{}/{}\".format(j+1,nrounds))\n",
        "  for clfname,model in clfs:\n",
        "    print(clfname, end=\":\\t\")\n",
        "    if not clfname in results['permissive']:\n",
        "      results['permissive'][clfname] = []\n",
        "    history = model.fit(x_train ,y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    if not clfname+str(fold) in models['permissive']:\n",
        "      models['permissive'][clfname+str(fold)] = model\n",
        "    results['permissive'][clfname].append([accuracy_score(y_test,y_pred),f1_score(y_test,y_pred,average='macro')])\n",
        "    print(results['permissive'][clfname][-1])\n",
        "  if fold >= 3:\n",
        "    fold = 0\n",
        "  else:\n",
        "    fold += 1\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Permissive Method\n",
            "1/4 x 1/3\n",
            "LinearSVM:\t[0.8911867642379891, 0.876937806062827]\n",
            "RandomForest:\t[0.9392300349984092, 0.9320528737828093]\n",
            "2/4 x 1/3\n",
            "LinearSVM:\t[0.8939490445859872, 0.879297313118346]\n",
            "RandomForest:\t[0.9404458598726114, 0.9341522939650299]\n",
            "3/4 x 1/3\n",
            "LinearSVM:\t[0.8940988835725678, 0.879535522655396]\n",
            "RandomForest:\t[0.9460925039872409, 0.9398596967016962]\n",
            "4/4 x 1/3\n",
            "LinearSVM:\t[0.8970917225950783, 0.881993804687132]\n",
            "RandomForest:\t[0.9344838606583573, 0.9269745672437933]\n",
            "1/4 x 2/3\n",
            "LinearSVM:\t[0.8997772828507795, 0.8870773586404747]\n",
            "RandomForest:\t[0.9433662106267897, 0.93700051237014]\n",
            "2/4 x 2/3\n",
            "LinearSVM:\t[0.8974522292993631, 0.8824352849930209]\n",
            "RandomForest:\t[0.9337579617834395, 0.9264816103543687]\n",
            "3/4 x 2/3\n",
            "LinearSVM:\t[0.8883572567783095, 0.8729013067403288]\n",
            "RandomForest:\t[0.9403508771929825, 0.9336504151739443]\n",
            "4/4 x 2/3\n",
            "LinearSVM:\t[0.8935762224352828, 0.8787220565575761]\n",
            "RandomForest:\t[0.941834451901566, 0.9354079633820888]\n",
            "1/4 x 3/3\n",
            "LinearSVM:\t[0.8962774419344576, 0.8822700893590291]\n",
            "RandomForest:\t[0.9395482023544385, 0.9325068524596061]\n",
            "2/4 x 3/3\n",
            "LinearSVM:\t[0.8977707006369426, 0.8849072429632493]\n",
            "RandomForest:\t[0.9385350318471337, 0.9317070261490858]\n",
            "3/4 x 3/3\n",
            "LinearSVM:\t[0.8982456140350877, 0.8843863397336605]\n",
            "RandomForest:\t[0.9438596491228071, 0.9375183048678567]\n",
            "4/4 x 3/3\n",
            "LinearSVM:\t[0.8894215404282518, 0.8737616693818705]\n",
            "RandomForest:\t[0.936401406200064, 0.9291263884972426]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhzqFADC9JoN",
        "colab_type": "text"
      },
      "source": [
        "##Restritive Experiments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUiqjOvP9Myl",
        "colab_type": "code",
        "outputId": "2ca89d2b-2eac-4857-dc05-3bc89103a36a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "loads = list(range(4))\n",
        "\n",
        "results['restritive'] = {}\n",
        "models['restritive'] = {}\n",
        "\n",
        "print(\"Restritive Method\")\n",
        "for i,fold in enumerate(loads):\n",
        "  print(\"{}/{}\".format(fold+1,len(loads)), end=\" x \")\n",
        "  x_test, y_test = eval('x'+str(fold)),eval('y'+str(fold))\n",
        "  x_train,y_train = None,None\n",
        "  for tfold in loads[:i]+loads[i+1:]:\n",
        "    x_train,y_train = concatenate_datasets(x_train,y_train,eval('x'+str(tfold)),eval('y'+str(tfold)))\n",
        "  for j in range(nrounds):\n",
        "    print(\"{}/{}\".format(j+1,nrounds))\n",
        "    for clfname,model in clfs:\n",
        "      print(clfname, end=\":\\t\")\n",
        "      if not clfname in results['restritive']:\n",
        "        results['restritive'][clfname] = []\n",
        "      history = model.fit(x_train ,y_train)\n",
        "      y_pred = model.predict(x_test)\n",
        "      if not clfname+str(fold) in models['restritive']:\n",
        "        models['restritive'][clfname+str(fold)] = model\n",
        "      results['restritive'][clfname].append([accuracy_score(y_test,y_pred),f1_score(y_test,y_pred,average='macro')])\n",
        "      print(results['restritive'][clfname][-1])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Restritive Method\n",
            "1/4 x 1/3\n",
            "LinearSVM:\t[0.7331081081081081, 0.697105274447531]\n",
            "RandomForest:\t[0.683445945945946, 0.6310073606995873]\n",
            "2/3\n",
            "LinearSVM:\t[0.7327702702702703, 0.6965698160912118]\n",
            "RandomForest:\t[0.6652027027027027, 0.6113432168035535]\n",
            "3/3\n",
            "LinearSVM:\t[0.7327702702702703, 0.6965698160912118]\n",
            "RandomForest:\t[0.6844594594594594, 0.6349101820206241]\n",
            "2/4 x 1/3\n",
            "LinearSVM:\t[0.8791105543376135, 0.8486432309244739]\n",
            "RandomForest:\t[0.8662699655496399, 0.8330222773431345]\n",
            "2/3\n",
            "LinearSVM:\t[0.8791105543376135, 0.8486432309244739]\n",
            "RandomForest:\t[0.8675227059191982, 0.8361089213527264]\n",
            "3/3\n",
            "LinearSVM:\t[0.8791105543376135, 0.8486432309244739]\n",
            "RandomForest:\t[0.8634512997181334, 0.8319558792583113]\n",
            "3/4 x 1/3\n",
            "LinearSVM:\t[0.9161189358372457, 0.9049067907389409]\n",
            "RandomForest:\t[0.9007824726134586, 0.887109745225886]\n",
            "2/3\n",
            "LinearSVM:\t[0.9161189358372457, 0.9049067907389409]\n",
            "RandomForest:\t[0.9104851330203443, 0.8980162785349828]\n",
            "3/3\n",
            "LinearSVM:\t[0.9161189358372457, 0.9049067907389409]\n",
            "RandomForest:\t[0.907981220657277, 0.8954007766707069]\n",
            "4/4 x 1/3\n",
            "LinearSVM:\t[0.8290090653329165, 0.788940000861959]\n",
            "RandomForest:\t[0.8383869959362301, 0.8017640341481035]\n",
            "2/3\n",
            "LinearSVM:\t[0.8280712722725851, 0.7879170609422018]\n",
            "RandomForest:\t[0.8455767427321038, 0.8097947214275396]\n",
            "3/3\n",
            "LinearSVM:\t[0.8290090653329165, 0.788940000861959]\n",
            "RandomForest:\t[0.8365114098155674, 0.7983001019438284]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dpUZ9Q0S4Nl",
        "colab_type": "text"
      },
      "source": [
        "#Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-05LJK0S4wk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b7d8d9f8-9e9e-4cfb-97d0-4f0cf584e487"
      },
      "source": [
        "for evaluation in results.keys():\n",
        "  print(\"\\n\"+30*\"#\"+\"\\n\"+evaluation+\"\\n\"+30*\"#\")\n",
        "  for clfname,model in clfs:\n",
        "    print(\"\\n\\t\"+clfname+\" Results\\nFold\\tAccuracy\\tF1-Score\")\n",
        "    for i,r in enumerate(results[evaluation][clfname]):\n",
        "      print(\"{}\\t\".format(i+1),end=\"\")\n",
        "      print(r)\n",
        "    print(\"Average\\tAccuracy\\tF1-Score\\n\\t\",end=\"\")\n",
        "    print(np.mean(results[evaluation][clfname],axis=0))\n",
        "    print(\"StdDev\\tAccuracy\\tF1-Score\\n\\t\",end=\"\")\n",
        "    print(np.std(results[evaluation][clfname],axis=0))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "##############################\n",
            "permissive\n",
            "##############################\n",
            "\n",
            "\tLinearSVM Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.8911867642379891, 0.876937806062827]\n",
            "2\t[0.8939490445859872, 0.879297313118346]\n",
            "3\t[0.8940988835725678, 0.879535522655396]\n",
            "4\t[0.8970917225950783, 0.881993804687132]\n",
            "5\t[0.8997772828507795, 0.8870773586404747]\n",
            "6\t[0.8974522292993631, 0.8824352849930209]\n",
            "7\t[0.8883572567783095, 0.8729013067403288]\n",
            "8\t[0.8935762224352828, 0.8787220565575761]\n",
            "9\t[0.8962774419344576, 0.8822700893590291]\n",
            "10\t[0.8977707006369426, 0.8849072429632493]\n",
            "11\t[0.8982456140350877, 0.8843863397336605]\n",
            "12\t[0.8894215404282518, 0.8737616693818705]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.89476706 0.88035215]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.00348966 0.00416342]\n",
            "\n",
            "\tRandomForest Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.9392300349984092, 0.9320528737828093]\n",
            "2\t[0.9404458598726114, 0.9341522939650299]\n",
            "3\t[0.9460925039872409, 0.9398596967016962]\n",
            "4\t[0.9344838606583573, 0.9269745672437933]\n",
            "5\t[0.9433662106267897, 0.93700051237014]\n",
            "6\t[0.9337579617834395, 0.9264816103543687]\n",
            "7\t[0.9403508771929825, 0.9336504151739443]\n",
            "8\t[0.941834451901566, 0.9354079633820888]\n",
            "9\t[0.9395482023544385, 0.9325068524596061]\n",
            "10\t[0.9385350318471337, 0.9317070261490858]\n",
            "11\t[0.9438596491228071, 0.9375183048678567]\n",
            "12\t[0.936401406200064, 0.9291263884972426]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.9398255  0.93303654]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.00355847 0.00395411]\n",
            "\n",
            "##############################\n",
            "restritive\n",
            "##############################\n",
            "\n",
            "\tLinearSVM Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.7331081081081081, 0.697105274447531]\n",
            "2\t[0.7327702702702703, 0.6965698160912118]\n",
            "3\t[0.7327702702702703, 0.6965698160912118]\n",
            "4\t[0.8791105543376135, 0.8486432309244739]\n",
            "5\t[0.8791105543376135, 0.8486432309244739]\n",
            "6\t[0.8791105543376135, 0.8486432309244739]\n",
            "7\t[0.9161189358372457, 0.9049067907389409]\n",
            "8\t[0.9161189358372457, 0.9049067907389409]\n",
            "9\t[0.9161189358372457, 0.9049067907389409]\n",
            "10\t[0.8290090653329165, 0.788940000861959]\n",
            "11\t[0.8280712722725851, 0.7879170609422018]\n",
            "12\t[0.8290090653329165, 0.788940000861959]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.83920221 0.80972434]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.0687809  0.07711119]\n",
            "\n",
            "\tRandomForest Results\n",
            "Fold\tAccuracy\tF1-Score\n",
            "1\t[0.683445945945946, 0.6310073606995873]\n",
            "2\t[0.6652027027027027, 0.6113432168035535]\n",
            "3\t[0.6844594594594594, 0.6349101820206241]\n",
            "4\t[0.8662699655496399, 0.8330222773431345]\n",
            "5\t[0.8675227059191982, 0.8361089213527264]\n",
            "6\t[0.8634512997181334, 0.8319558792583113]\n",
            "7\t[0.9007824726134586, 0.887109745225886]\n",
            "8\t[0.9104851330203443, 0.8980162785349828]\n",
            "9\t[0.907981220657277, 0.8954007766707069]\n",
            "10\t[0.8383869959362301, 0.8017640341481035]\n",
            "11\t[0.8455767427321038, 0.8097947214275396]\n",
            "12\t[0.8365114098155674, 0.7983001019438284]\n",
            "Average\tAccuracy\tF1-Score\n",
            "\t[0.82250634 0.78906112]\n",
            "StdDev\tAccuracy\tF1-Score\n",
            "\t[0.08703991 0.09990941]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}